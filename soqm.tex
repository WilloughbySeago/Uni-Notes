\documentclass[fleqn]{NotesClass}

\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{csquotes}
\usepackage{tikz-cd}
\usepackage{enumitem}
\usepackage{colortbl}
\usepackage[polutonikogreek, english]{babel}
\usepackage{multicol}
\usepackage{siunitx}
\usepackage[version=4]{mhchem}
\usepackage{chemfig}
\usepackage{tensor}

% Tikz stuff
\usepackage{tikz}
\tikzset{>=latex}
% external
\usetikzlibrary{external}
\tikzexternalize[prefix=tikz-external/]
%\tikzexternaldisable
% other libraries
\usetikzlibrary{calc}
\usetikzlibrary{3d}
\usetikzlibrary{hobby}
\usetikzlibrary{decorations.markings}

% Young Tableau
\usepackage{ytableau}
\ytableausetup{smalltableaux}

% References, should be last things loaded
\usepackage{hyperref}  % Should be loaded second last (cleveref last)
\colorlet{hyperrefcolor}{blue!60!black}
\hypersetup{colorlinks=true, linkcolor=hyperrefcolor, urlcolor=hyperrefcolor}
\usepackage[
capitalize,
nameinlink,
noabbrev
]{cleveref} % Should be loaded last

% My packages
\usepackage{NotesBoxes}
\usepackage{NotesMaths}

% Title page info
\title{Symmetries of Quantum Mechanics}
\author{Willoughby Seago}
\date{February 17, 2022}
% \subtitle{}
% \subsubtitle{}

% Highlight colour
\definecolor{highlight}{HTML}{710D78}
\definecolor{my blue}{HTML}{2A0D77}
\definecolor{my red}{HTML}{770D38}
\definecolor{my green}{HTML}{14770D}
\definecolor{my yellow}{HTML}{E7BB41}

% Commands
% Maths
\NewDocumentCommand{\presentation}{ s o m m }{
    \IfNoValueTF{#2}{
        \IfBooleanTF{#1}{
            \left\langle #3 \, \middle\vert \, #4 \right\rangle
        }{
            \langle #3 \, \vert \, #4 \rangle
        }
    }{
        #2\langle #3 \, #2\vert \, #4 #2\rangle
    }
}
\DeclarePairedDelimiterX{\groupindex}[2]{[}{]}{#1 : #2}
\newcommand*{\union}{\cup}
\newcommand*{\bigunion}{\bigcup}
\newcommand*{\intersection}{\cap}
\newcommand*{\bigintersection}{\bigcap}
\newcommand{\subgroup}{\subset}
\newcommand{\subgroupeq}{\subseteq}
\newcommand{\supgroup}{\supset}
\newcommand{\supgroupeq}{\supseteq}
\renewcommand{\emptyset}{\emptysetAlt}
\newcommand*{\action}{\mathbin{.}}
\newcommand*{\isomorphic}{\cong}
\DeclareMathOperator{\image}{Im}
\DeclarePairedDelimiterX{\innerprod}[2]{\langle}{\rangle}{#1, #2}
\newcommand*{\trans}{\top}
\newcommand*{\hermit}{\dagger}
\newcommand*{\positiveintegers}{\integers_{>0}}
\newcommand*{\hilbert}{\mathcal{H}}
\newcommand*{\ident}{\mathbb{1}}
\DeclareMathOperator{\tr}{tr}
\newcommand*{\directsum}{\oplus}
\newcommand*{\directproduct}{\otimes}
\DeclareMathOperator{\Hom}{Hom}
\newcommand*{\e}{\mathrm{e}}
\ExplSyntaxOn
% Create LaTeX interface command
\NewDocumentCommand{\cycle}{ O{\,} m }{  % optional arg is separator, mandatory
    %arg is comma separated list
    (
    \willoughby_cycle:nn { #1 } { #2 }
    )
}

\clist_new:N \l_willougbhy_cycle_clist  % Create new clist variable
\cs_new_protected:Npn \willoughby_cycle:nn #1 #2 {  % create LaTeX3 function
    \clist_set:Nn \l_willougbhy_cycle_clist { #2 }  % set clist variable with
    %clist #2 passed by user
    \clist_use:Nn \l_willougbhy_cycle_clist { #1 }  % print list separated by #1
}
\ExplSyntaxOff
\DeclareMathOperator{\isometry}{ISO}
\newcommand{\orbit}{\mathit{g}}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\End}{End}
\newcommand*{\category}[1]{\mathbf{#1}}
\newcommand*{\normalsubgroup}{\vartriangleleft}
\newcommand*{\normalsubgroupeq}{\trianglelefteq}
\newcommand*{\longsim}{\scalebox{2.5}[1.1]{\(\sim\)}}
\DeclareMathOperator{\ISO}{ISO}
\newcommand*{\triangleDthree}[3]{%
    \begin{tikzpicture}[baseline=(current bounding box), scale=0.5, font=\tiny]
        \draw[highlight, very thick, rounded corners=0.1, fill=highlight!20]
        (-30:1) -- (90:1) -- (210:1) -- cycle;
        \node at (210:1.3) {#1};
        \node at (90:1.3) {#2};
        \node at (-30:1.3) {#3};
    \end{tikzpicture}%
}
\newcommand*{\tetrahedron}[4]{%
    \begin{tikzpicture}[highlight, ultra thick, rounded corners=0.01,
        baseline=(current bounding box)]
        \pgfmathsetmacro{\r}{1}
        \coordinate (A) at (0, 0, \r);
        \coordinate (B) at ({\r*sqrt(2)/2}, 0, 0);
        \coordinate (C) at ({-\r*sqrt(2)}, 0, 0);
        \coordinate (D) at (0, \r*2, {\r*sqrt(2)});
        \draw (B) -- (A) -- (C);
        \draw[dashed] (B) -- (C);
        \draw (A) -- (B) -- (D) -- cycle;
        \draw (C) -- (D) -- (A) -- cycle;
        \fill[#1] (A) circle[radius=0.1];
        \fill[#2] (B) circle[radius=0.1];
        \fill[#3] (C) circle[radius=0.1];
        \fill[#4] (D) circle[radius=0.1];
    \end{tikzpicture}
}
\newcommand*{\invertedtetrahedron}[4]{%
    \begin{tikzpicture}[highlight, ultra thick, rounded corners=0.01,
        baseline=(current bounding box)]
        \pgfmathsetmacro{\r}{1}
        \coordinate (A) at (0, 0, \r);
        \coordinate (B) at ({\r*sqrt(2)/2}, 0, 0);
        \coordinate (C) at ({-\r*sqrt(2)}, 0, 0);
        \coordinate (D) at (0, -\r*1.2, {\r*sqrt(2)});
        \draw (B) -- (A) -- (C);
        \draw (B) -- (C);
        \draw (A) -- (B) -- (D) -- cycle;
        \draw (C) -- (D) -- (A) -- cycle;
        \fill[#1] (A) circle[radius=0.1];
        \fill[#2] (B) circle[radius=0.1];
        \fill[#3] (C) circle[radius=0.1];
        \fill[#4] (D) circle[radius=0.1];
    \end{tikzpicture}
}
\makeatletter
\newcommand{\Spin}{\@lineargroup{Spin}}
\newcommand*{\USp}{\@lineargroup{USp}}
\newcommand*{\Sp}{\@lineargroup{Sp}}
\makeatother
\DeclarePairedDelimiterX{\commutator}[2]{[}{]}{#1, #2}
\newcommand*{\rep}[1]{\mathbf{#1}}
\DeclarePairedDelimiterX{\liebracket}[2]{[}{]}{#1, #2}
\newcommand*{\order}{\mathcal{O}}

% Include
\includeonly{parts/group-theory, parts/representation-theory, parts/math-prelim-appendix,
    parts/groups-appendix, parts/manifolds-appendix, parts/algebras-appendix}

\begin{document}
    \frontmatter
    \titlepage
    \innertitlepage{tikz-external/cube-octahedron-dual} 
    \tableofcontents
    \listoffigures
    \mainmatter
    \include{parts/group-theory}
    \include{parts/representation-theory}
    
    \part{Continuous Groups}
    \chapter{Lie Groups}
    \section{Background}
    Finite groups were first utilised by mathematicians, particularly Galois, who wanted to classify the solutions to polynomials.
    Groups were used to show that, in general, polynomials of degree 5 or greater don't admit an exact solution in terms of elementary functions.
    That is, there is no \enquote{quintic formula} equivalent to the quadratic formula.
    There are linear, cubic, and quartic versions of the quadratic formula, but the linear formula is trivial and the cubic and quartic formulae contain too many terms to be useful for human computations.
    The main focus was on the symmetric groups, since permuting variables in equations played a big part in classifying the solutions, and it was soon noticed that the basic symmetry operations of a group applied to a far more general class of algebraic objects.
    
    Sophus Lie introduced Lie groups, to be defined shortly, for similar reasons, he was attempting to classify solutions to differential equations.
    These have continuous solutions and so unsurprisingly Lie groups are continuous.
    
    All simple finite groups have been classified.
    Likewise all simple and compact Lie groups have been classified, we will see the classification later.
    
    \section{Basics}
    \begin{dfn}{Continuous Group}{}
        A \defineindex{continuous group} is a group, \(G\), with an uncountable number of elements which can be continuously parametrised by some set of parameters, \(\{\alpha\}\).
        We call the number of parameters the \define{dimension}\index{dimension!of a group} of \(G\), \(\dim G\).
    \end{dfn}
    Notice that it doesn't make sense to discus the order of a continuous group since it is infinite.
    
    \begin{dfn}{Lie Group}{}
        A \define{Lie group}\index{Lie!group} is a continuous group which admits an analytic structure in the parameters \(\{a\}\).
        
        Alternatively, a \define{Lie group} is a manifold equipped with a binary operation satisfying the group axioms.
    \end{dfn}
    For our purposes a manifold is a space which can be parametrised locally by a fixed number Euclidean coordinates.
    The number of coordinates is the dimension of the manifold.
    A fuller definition of a manifold is given in \cref{app:manifold}.

    All of the groups in the following definition are Lie groups.
    Technically, we are only defining a representation of these groups here but this is fine.
    
    \begin{dfn}{Specific Lie Groups}{}
        \begin{itemize}
            \item The \defineindex{general linear group}, \(\generalLinear(n, \field)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\field\), which is usually \(\reals\) or \(\complex\).
            It has the representation
            \begin{equation}
                \generalLinear(n, \field) \coloneqq \{M \in \matrices{n}{\field} \mid \det M \ne 0\}.
            \end{equation}
            The requirement of non-zero determinant is so that the matrices are invertible.
            
            \item The \defineindex{special linear group}, \(\specialLinear(n, \field)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\field\) which preserve volumes.
            It has the representation
            \begin{equation}
                \specialLinear(n, \field) \coloneqq \{M \in \matrices{n}{\field} \mid \det M \ne 1\} \subgroup \generalLinear(n, \field).
            \end{equation}
            
            \item The \defineindex{orthogonal group}, \(\orthogonal(n)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\reals\) which preserves lengths.
            It has the representation
            \begin{equation}
                \orthogonal(n) \coloneqq \{O \in \matrices{n}{\reals} \mid O^\trans O = \ident_n\} \subgroup \generalLinear(n, \reals).
            \end{equation}
            
            \item The \defineindex{special orthogonal group}, \(\specialOrthogonal(n)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\reals\) which preserves lengths and orientations.
            It has the representation
            \begin{equation}
                \specialOrthogonal(n) \coloneqq \{O \in \matrices{n}{\reals} \mid O^\trans O = \ident_n \text{ and } \det O = 1\}.
            \end{equation}
            It is a subgroup of both \(\orthogonal(n)\) and \(\specialLinear(n, \reals)\).
            
            \item The \defineindex{unitary group}, \(\unitary(n)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\complex\) which preserves inner products.
            It has the representation
            \begin{equation}
                \unitary(n) = \{U\in\matrices{n}{\complex} \mid U^\hermit U = \ident_n\} \subgroup \generalLinear(n, \complex).
            \end{equation}
            
            \item The \defineindex{special unitary group}, \(\specialUnitary(n)\), is defined as the group of transformations of an \(n\)-dimensional vector space over \(\complex\) which preserves inner products and orientations.
            It has the representation
            \begin{equation}
                \specialUnitary(n) \coloneqq \{U \in \matrices{n}{\complex} \mid U^\hermit U = \ident_n \text{ and } \det U = 1\}.
            \end{equation}
            It is a subgroup of both \(\unitary(n)\) and \(\specialLinear(n, \complex)\).
            
            \item The \defineindex{symplectic group}\index{USp(2n)@\(\USp(2n)\), symplectic group of rank \(n\)}\index{SP(n)@\(\Sp(n)\), symplectic group of rank \(n\)}, \(\USp(2n) = \Sp(n)\), is defined as the group of transformations of an \(2n\)-dimensional vector space over \(\field\) which preserves symplectic bilinear forms\footnote{A \defineindex{symplectic bilinear form} is a map \(\omega\colon V\times V \to \field\) which is linear in both arguments, alternating, so \(\omega(x, y) = -\omega(y, x)\),  and non-degenerate, so \(\omega(u, v) = 0\) for all \(v \in V\) only if \(u = 0\). We can view \(\reals^{2n}\) as a symplectic space by endowing it with the map \(J\) defined above such that \(\omega(x, y) = x^{\hermit}Jy\).}.
            It has the representation
            \begin{equation}
                \USp(2n) = \Sp(n) \coloneqq \{S \in \matrices{2n}{\field} \mid S^{\hermit} J S = J\}
            \end{equation}
            where
            \begin{equation}
                J \coloneqq
                \begin{pmatrix}
                    0 & -\ident_n\\
                    -\ident_n & 0
                \end{pmatrix}
                .
            \end{equation}
            Note that \(J^2 = -\ident_{2n}\), so we can think of \(J\) as a generalisation of \(i\) which has \(i^2 = -1\).
        \end{itemize}
    \end{dfn}
    
    \begin{exm}{}{}
        The following are group actions of some Lie group on \(\reals^3\).
        \begin{itemize}
            \item \(\reals^3\) with vector addition as the group operation is an \(3\)-dimensional continuous group.
            The parameters can be seen as the components of the vectors.
            
            \item \(\specialOrthogonal(3)\) with matrix multiplication as the group operation is a \(3\)-dimensional continuous group.
            The parameters can be seen as the three Euler angles defining a rotation.
        \end{itemize}
    \end{exm}
    
    It should be noted that the dimension of \(\specialOrthogonal(n)\) is not, in general, \(n\).
    For example, \(\specialOrthogonal(2)\) has dimension 1, since there is only one parameter defining rotations in the plane, the angle of the rotation.
    \(\specialOrthogonal(4)\) has dimension 6, since there are initially \(4^2 = 16\) degrees of freedom for the individual components of the matrix.
    It then turns out that orthogonality fixes one component in each row and column, since these must form unit vectors, and the requirement that the determinant is 1 fixes another three degrees of freedom.
    
    \section{Properties of Lie Groups}
    There are various properties which manifolds, and hence Lie groups, may or may not posses.
    In this section we cover some of these properties.
    
    \subsection{Basic Properties}
    \begin{dfn}{Finite or Infinite}{}
        A manifold is finite dimensional if it is parametrised by a finite number of coordinates.
        If this is not the case then the manifold is infinite dimensional.
        A Lie group is \define{finite}\index{finite dimensional Lie group} or \define{infinite dimensional}\index{infinite dimensional Lie group} if it is a finite or infinite dimensional manifold respectively.
    \end{dfn}
    \begin{exm}{}{}
        The Lie groups \(\unitary(1)\), \(\specialOrthogonal(2)\), \(\specialUnitary(2)\), and \(\specialOrthogonal(3)\) are all finite dimensional.
        
        The Lie group \(\unitary(\hilbert)\) for an infinite dimensional Hilbert space is an infinite dimensional Lie group under the topology induced by the operator norm,
        \begin{equation}
            \norm{A}_{\mathrm{op}} \coloneqq \inf \{c \ge 0 \mid \norm{Av} \le c\norm{v} \text{ for all } v \in \hilbert\}
        \end{equation}
        where \(\norm{-}\) is the norm on \(\hilbert\).
        This norm can be thought of as the smallest number, \(c\), such that \(A\) doesn't scale the \enquote{length} of a vector by more than a factor of \(c\).
        For example, this Lie group might represent all unitary transformations on the state of a particle with a continuous parameter.
    \end{exm}
    
    \begin{dfn}{Real or Complex}{}
        A manifold is real if it is parametrised by real numbers with smooth maps, and complex if it is parametrised by complex numbers with holomorphic maps.
        A Lie group is \define{real}\index{real Lie group} or \define{complex}\index{complex Lie group} if it is a real or complex manifold, respectively.
    \end{dfn}
    
    \begin{dfn}{}{}
        The Lie groups \(\unitary(1)\), \(\specialOrthogonal(2)\), \(\specialUnitary(2)\), and \(\specialOrthogonal(3)\) are real Lie groups, although we will later see that \(\specialUnitary(2)\) is pseudo-real.
    \end{dfn}

    \subsection{Compactness}    
    The following definition assumes the existence of a metric on the manifold.
    \begin{dfn}{Compact}{}
        A manifold, \(M\), is compact if it is closed and bounded.
        \define{Bounded}\index{bounded} means that \(d(x, y) < r\) for all \(x, y\) in the manifold and \(r \in \reals\) being some finite number with \(d\) being a metric.
        \define{Closed}\index{closed} means that when viewing \(M\) as a submanifold of some larger manifold \(M\) contains its boundary.
        A Lie group is \define{compact}\index{compact Lie group} if it is compact as a manifold and \define{non-compact}\index{non-compact Lie group} otherwise.
    \end{dfn}
    
    As an example consider \(\reals\) with the standard metric \(d(x, y) = \abs{x - y}\).
    Then \([0, 1] \coloneqq \{x \in \reals \mid 0 \le x \le 1\}\) is closed and bounded, and hence compact.
    The intervals
    \begin{align}
        [0, 1) &\coloneqq \{x \in \reals \mid 0 \le x < 1\},\\
        (0, 1] &\coloneqq \{x \in \reals \mid 0 < x \le 1\}, \qand\\
        (0, 1) &\coloneqq \{x \in \reals \mid 0 < x < 1\}
    \end{align}
    are not closed, but are bounded.
    The interval \([0, \infty) \coloneqq \{x \in \reals \mid x > 0\}\) is not bounded since the distance between points can become arbitrarily large.
    
    The circle, \(S^1\), is compact but \(\reals\) isn't.
    
    \begin{exm}{}{}
        The Lie groups \(\unitary(1)\), \(\specialOrthogonal(2)\), \(\specialUnitary(2)\), and \(\specialOrthogonal(3)\) are compact Lie groups.
    \end{exm}
    
    For a compact group all of the theorems of \cref{chap:basics of representation theory}, such as Maschke's theorem (\cref{thm:maschke's theorem}), Schur's lemma (\cref{thm:schurs lemma}), and the decomposability theorem (\cref{thm:decomposability}), can be modified to hold for compact continuous groups.
    To do so we replace the sum over group elements, \(\sum_{g\in G}\), with the \defineindex{Haar measure}, \(\int \dl{\{\alpha\}}\), we won't go into detail here on this though.
    For this reason we will restrict ourselves to compact groups, although here we give a few examples of non-compact groups.
    
    \begin{exm}{Non-Compact Lie Group}{}
        Consider the translation group on \(\reals\).
        That is \(\reals\) acting on \(\reals\) by \(a \action x = x + a\).
        This has a representation, \(\rho \coloneqq \reals \to \generalLinear(V)\), given by the following:
        \begin{equation}
            \rho(a) =
            \begin{pmatrix}
                1 & a\\ 0 & 1
            \end{pmatrix}
            .
        \end{equation}
        However, this doesn't decompose since the subspace defined by the span \(\ve{x} = (1, 0)\) is an invariant subspace but its orthogonal complement, defined by the span of \(\ve{y} = (0, 1)\), is not invariant, since \(\rho(a)\ve{y} = (a, 1) \notin \spn \{\ve{y}\}\).
        Hence we cannot write \(\rho = \rho_1 \directsum \rho_2\) with \(\rho_1 \colon \reals \to \generalLinear(W)\) and \(\rho_2 \colon \reals \to \generalLinear(W^{\bot})\) with \(W \directsum W^{\bot} = V\), despite the fact that \(\rho\) is not irreducible.
        This is a failure of the decomposability theorem (\cref{thm:decomposability}) which holds only for compact groups.
    \end{exm}
    
    \begin{exm}{}{}
        The Lorentz group, \(\orthogonal(1, 3)\), is not compact.
        This is because it is parametrised in part by the relative velocity of the frames and this is restricted to the non-compact interval \([0, c)\).
        
        Maschke's theorem (\cref{thm:maschke's theorem}) doesn't hold for the Lorentz group as it has no finite dimensional unitary representations.
        This is why we need to define an invariant of the form \(\bar{\psi}\psi\) for spinors \(\psi\) with \(\bar{\psi} \coloneqq \psi^\hermit \gamma_0\) and \(\gamma_0 \coloneqq \ident_2 \directsum (-\ident_2) = \sigma_3 \directproduct \ident_2\).
        If \(\psi\) instead transformed under a finite dimensional unitary representation, which is guaranteed to exist for a compact group by Maschke's theorem (\cref{thm:maschke's theorem}) then this would not be necessary as \(\psi^\hermit \psi\) would be invariant without the need for \(\gamma_0\).
    \end{exm}
    
    \subsection{Connectedness}
    \begin{dfn}{}{}
        A manifold is connected if there exists a continuous path between any two points in the manifold.
        A manifold is simply connected if any loop can be contracted continuously to a point.
        A manifold is disconnected if it is not connected.
        A Lie group is \define{disconnected}\index{disconnected Lie group}, \define{connected}\index{connected Lie group}, or \define{simply connected}\defineindex{simply connected Lie group} if it is disconnected, connected, or simply connected as a manifold respectively.
    \end{dfn}
    
    Intuitively a space is simply connected if there are no holes.
    
    \begin{figure}
        \tikzsetnextfilename{connected}
        \begin{tikzpicture}
            \node at (0.45, -0.5) {Simply Connected};
            \draw[use Hobby shortcut, closed, highlight, fill=highlight!10] (0, 0) .. (0.5, 0.25) .. (1, 1) .. (1.5, 2) .. (1, 2.5) .. (0.5, 2) .. (-0.5, 1.5) .. (-0.5, 0.75);
            \begin{scope}[xshift=3cm]
                \draw[use Hobby shortcut, closed, highlight, fill=highlight!10] (0, 0) .. (0.5, 0.25) .. (1, 1) .. (1.5, 2) .. (1, 2.5) .. (0.5, 2) .. (-0.5, 1.5) .. (-0.5, 0.75);
                \draw[use Hobby shortcut, closed, highlight, fill=white] (0.2, 0.4) .. (0.4, 0.8) .. (0.5, 1) .. (0.5, 1.5) .. (0.3, 1) .. (0, 0.5);
                \draw[dashed, my blue, rotate around={70:(0.315, 0.9)}] (0.315, 0.9) circle [x radius = 0.7, y radius = 0.28];
                \node at (0.45, -0.5) {Connected};
            \end{scope}
            \begin{scope}[xshift=6cm]
                \draw[use Hobby shortcut, closed, highlight, fill=highlight!10] (1.3, 1.3) .. (1.5, 2) .. (1, 2.5) .. (0.6, 2);
                \draw[use Hobby shortcut, closed, highlight, fill=highlight!10] (0, 0) .. (0.5, 0.25) .. (0.7, 0.7) .. (0.5, 1.5) .. (-0.5, 1.5) .. (-0.5, 0.75);
                \fill[my blue] (0, 0.5) circle [radius = 0.05];
                \fill[my blue] (1, 1.5) circle [radius = 0.05];
                \begin{scope}
                    \clip[use Hobby shortcut, closed] (1.3, 1.3) .. (1.5, 2) .. (1, 2.5) .. (0.6, 2);
                    \draw[my blue] (0, 0.5) to[bend left] (1, 1.5);
                \end{scope}
                \begin{scope}
                    \clip[use Hobby shortcut, closed] (0, 0) .. (0.5, 0.25) .. (0.7, 0.7) .. (0.5, 1.5) .. (-0.5, 1.5) .. (-0.5, 0.75);
                    \draw[my blue] (0, 0.5) to[bend left] (1, 1.5);
                \end{scope}
                \node at (0.45, -0.5) {Disconnected};
            \end{scope}
        \end{tikzpicture}
        \caption[Connectedness]{Examples of simply connected, connected, and disconnected spaces. The loop (\tikz[baseline=-2.5pt]{\draw[dashed, my blue] (0, 0) -- ++ (0.5, 0);}) in the connected example cannot be continuously contracted to a point without leaving the space. Similarly the two points (\tikz[baseline=-2.5pt]{\fill[my blue] (0, 0) circle [radius = 0.05];}) in the disconnected example cannot be connected by a continuous path. The path connecting them (\tikz[baseline=-2.5pt]{\draw[my blue] (0, 0) -- ++ (0.5, 0);}) has a jump.}
    \end{figure}
    
    \begin{exm}{}{}
        The Lie groups \(\unitary(1)\), \(\specialOrthogonal(2)\), and \(\specialOrthogonal(3)\) are connected.
        The Lie group \(\specialUnitary(2)\) is simply connected.
        The Lie group \(\orthogonal(2)\) is disconnected since there is no continuous path from \(O \in \orthogonal(2)\) with \(\det O = -1\) to \(O' \in \orthogonal\) with \(\det O' = +1\) since \(\det\) is a continuous function and must jump from \(-1\) to \(+1\) along this path somewhere since all orthogonal matrices have \(\abs{\det O} = 1\).
    \end{exm}
    
    \subsection{Simplicity}
    Recall that a finite group is simple if it has no non-trivial proper normal subgroups, and that a normal subgroup is one which is invariant under conjugation.
    That is, \(N \normalsubgroup G\) if \(gng^{-1} \in N\) for all \(n \in n\) and \(g \in G\).
    We define simple Lie groups in a similar way but we explicitly disallow a few cases.
    
    \begin{dfn}{Simple Lie Group}{}
        A Lie group is \define{simple}\index{simple group} if it is connected, non-Abelian, and has no non-trivial connected normal subgroups.
        
        A \defineindex{semi-simple Lie group} is a Lie group which can be written as a direct product of simple Lie groups.
        
        A \defineindex{composite Lie group} is a Lie group which can be written as a semi-direct product of simple Lie groups.
    \end{dfn}
    
    The reason we exclude more cases than for the definition for any group is motivated by the fact that it is not possible to define a quotient group from a simple group, apart from the trivial group and the simple group itself.
    We want this to hold replacing all groups with Lie groups.
    Importantly this means that we want a simple Lie group to be one where it is not possible to define a non-trivial quotient \emph{Lie} group.
    If we expand upon what this requires we get the definition above.
    
    We will only concern ourselves with simple Lie groups in this course.
    
    \begin{exm}{}{}
        The Lie groups \(\specialLinear(n)\), \(\specialUnitary(n)\), and \(\USp(2n) = \Sp(n)\) are simple.
    \end{exm}
    
    \subsubsection{Classification of Simple Compact Lie Groups}
    All simple compact Lie groups have been classified.
    It turns out there are four families of simple compact Lie groups, \(A_n\), \(B_n\), \(C_n\), and \(D_n\), and five exceptional groups, \(E_6\), \(E_7\), \(E_8\), \(F_4\), and \(G_2\) which don't fall into any of these categories.
    We won't define the exceptional groups here, we just note that they exist.
    The families consist of familiar groups, \(A_n = \specialUnitary(n + 1)\), \(B_n = \specialOrthogonal(2n + 1)\), \(C_n = \USp(2n)\), and \(D_n = \specialOrthogonal(2n)\).
    These are sorted by their rank, which is given by the subscript.
    Rank is a concept related to the Lie algebras of these groups, which we shall meet later.
    
    \begin{table}
        \begin{tabular}{lcc}\toprule
            Group & Dimension & Rank \\ \midrule
            \(A_n\) & \((n + 1)^2 - 1\) & \(n\)\\
            \(B_n\) & \(n(2n + 1)\) & \(n\)\\
            \(C_n\) & \(n(2n + 1)\) & \(n\)\\
            \(D_n\) & \(n(2n - 1)\) & \(n\)\\ \midrule
            \(E_6\) & 78 & 6\\
            \(E_7\) & 133 & 7\\
            \(E_8\) & 248 & 8\\
            \(F_4\) & 52 & 4\\
            \(G_2\) & 14 & 2\\ \bottomrule
        \end{tabular}
        \caption{Classification of simple compact Lie groups}
    \end{table}
    
    \tikzset{dynkin node/.style = {fill = white}}
    \tikzset{->-/.style = {decoration={markings, mark=at position #1 with {\arrow{>}}}, postaction={decorate}}}
    \tikzset{-<-/.style = {decoration={markings, mark=at position #1 with {\arrow{<}}}, postaction={decorate}}}
    The Lie groups can be depicted by \define{Dynkin diagrams}\index{Dynkin diagram}, which are graphs with as many nodes as the rank\footnote{to be defined in \cref{sec:lie algebra generalities}} of the group.
    For example, \(A_1\) corresponds to
    \tikzsetnextfilename{dynkin-A1}
    \tikz[baseline=-2.5pt]{ \draw[dynkin node] (0, 0) circle [radius = 0.075]; }
    , \(A_2\) corresponds to
    \tikzsetnextfilename{dynkin-A2}
    \tikz[baseline=-2.5pt]{ \draw (0, 0) -- (1, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    , and \(A_3\) corresponds to
    \tikzsetnextfilename{dynkin-A3}
    \tikz[baseline=-2.5pt]{ \draw (0, 0) -- (2, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; \draw[dynkin node] (2, 0) circle [radius =0.075]; }
    .
    In general \(A_n\) corresponds to
    \tikzsetnextfilename{dynkin-An}
    \tikz[baseline=-2.5pt]{ \draw (0, 0) -- (1.3, 0); \draw (1.7, 0) -- (3, 0); \draw[dotted] (1.3, 0) -- (1.7, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; \draw[dynkin node] (2, 0) circle [radius =0.075]; \draw[dynkin node] (3, 0) circle [radius =0.075]; }
    with \(n\) nodes.
    
    The Dynkin  diagram for \(B_n\) is similar but the final connection is doubled and directed, so \(B_2\) corresponds to
    \tikzsetnextfilename{dynkin-B2}
    \tikz[baseline=-2.5pt]{ \draw[double, ->-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    , and \(B_3\) corresponds to
    \tikzsetnextfilename{dynkin-B3}
    \tikz[baseline=-2.5pt]{ \draw (-1, 0) -- (0, 0); \draw[double, ->-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    .
    In general \(B_n\) corresponds to
    \tikzsetnextfilename{dynkin-Bn}
    \tikz[baseline=-2.5pt]{ \draw (-2, 0) -- (-0.7, 0); \draw (-0.3, 0) -- (0, 0); \draw[dotted] (-0.7, 0) -- (-0.3, 0); \draw[double, ->-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (-2, 0) circle [radius = 0.075]; \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    with \(n\) nodes.
    
    The Dynkin diagrams for \(C_n\) are almost identical to those of \(B_n\) but with the direction reversed, so \(C_2\) corresponds to
    \tikzsetnextfilename{dynkin-C2}
    \tikz[baseline=-2.5pt]{ \draw[double, -<-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    , and \(C_3\) corresponds to
    \tikzsetnextfilename{dynkin-C3}
    \tikz[baseline=-2.5pt]{ \draw (-1, 0) -- (0, 0); \draw[double, -<-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    .
    In general \(C_n\) corresponds to
    \tikzsetnextfilename{dynkin-Cn}
    \tikz[baseline=-2.5pt]{ \draw (-2, 0) -- (-0.7, 0); \draw (-0.3, 0) -- (0, 0); \draw[dotted] (-0.7, 0) -- (-0.3, 0); \draw[double, -<-=0.65, >=To] (0, 0) -- (1, 0); \draw[dynkin node] (-2, 0) circle [radius = 0.075]; \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius =0.075]; }
    with \(n\) nodes.
    
    The Dynkin diagrams for \(D_n\) branch at the end into two.
    So \(D_4\) corresponds to 
    \begin{equation}
        \tikzsetnextfilename{dynkin-D4}
        \tikz[baseline=(current bounding box.east)]{ \draw (0, 0) -- (1, 0); \draw (1, 0) -- ++ (30:1); \draw (1, 0) -- ++ (-30:1); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (30:1)$) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (-30:1)$) circle [radius = 0.075]; }
    \end{equation}
    and \(D_5\) corresponds to
    \begin{equation}
        \tikzsetnextfilename{dynkin-D5}
        \tikz[baseline=(current bounding box.east)]{ \draw (-1, 0) -- (1, 0); \draw (1, 0) -- ++ (30:1); \draw (1, 0) -- ++ (-30:1); \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (30:1)$) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (-30:1)$) circle [radius = 0.075]; }
    \end{equation}
    In general, \(D_n\) corresponds to
    \begin{equation}
        \tikzsetnextfilename{dynkin-Dn}
        \tikz[baseline=-2.5pt]{ \draw (-1, 0) -- (0.3, 0); \draw (0.7, 0) -- (1, 0); \draw[dotted] (0.3, 0) -- (0.7, 0); \draw (1, 0) -- ++ (30:1); \draw (1, 0) -- ++ (-30:1); \draw[dynkin node] (-1, 0) circle [radius = 0.075]; \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (30:1)$) circle [radius = 0.075]; \draw[dynkin node] ($(1, 0) + (-30:1)$) circle [radius = 0.075]; }
    \end{equation}
    
    The exceptional groups also have Dynkin diagrams.
    For \(E_n\) (\(n = 6, 7, 8\)) the Dynkin diagram consists of a chain of \(n - 1\) nodes with an extra node branching off three from the end, so \(E_6\) corresponds to
    \begin{equation}
        \tikzsetnextfilename{dynkin-E6}
        \begin{tikzpicture}[baseline=(current bounding box.east)]
            \draw (0, 0) -- (4, 0);
            \draw (2, 0) -- (2, 1);
            \foreach \x in {0, ..., 4} {
                \draw[dynkin node] (\x, 0) circle [radius = 0.075];
            }
            \draw[dynkin node] (2, 1) circle [radius = 0.075];
        \end{tikzpicture}
    \end{equation}
    \(E_7\) corresponds to
    \begin{equation}
        \tikzsetnextfilename{dynkin-E7}
        \begin{tikzpicture}[baseline=(current bounding box.east)]
            \draw (0, 0) -- (5, 0);
            \draw (3, 0) -- (3, 1);
            \foreach \x in {0, ..., 5} {
                \draw[dynkin node] (\x, 0) circle [radius = 0.075];
            }
            \draw[dynkin node] (3, 1) circle [radius = 0.075];
        \end{tikzpicture}
    \end{equation}
    and \(E_8\) to
    \begin{equation}
        \tikzsetnextfilename{dynkin-E8}
        \begin{tikzpicture}[baseline=(current bounding box.east)]
            \draw (0, 0) -- (6, 0);
            \draw (4, 0) -- (4, 1);
            \foreach \x in {0, ..., 6} {
                \draw[dynkin node] (\x, 0) circle [radius = 0.075];
            }
            \draw[dynkin node] (4, 1) circle [radius = 0.075];
        \end{tikzpicture}
    \end{equation}
    
    The Dynkin diagram for \(F_4\) is
    \tikzsetnextfilename{dynkin-F4}
    \tikz[baseline=-2.5pt]{ \draw (0, 0) -- (1, 0); \draw[double, ->-=0.65, >=To] (1, 0) -- (2, 0); \draw (2, 0) -- (3, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius = 0.075]; \draw[dynkin node] (2, 0) circle [radius = 0.075]; \draw[dynkin node] (3, 0) circle [radius = 0.075];}
    .
    
    The Dynkin diagram for \(G_2\) is
    \tikzsetnextfilename{dynkin-G2}
    \tikz[baseline=-2.5pt]{ \draw[->-=0.65, >={To[width=0.3cm, length=0.14cm]}] (0, 0) -- (1, 0); \draw[yshift=0.035cm] (0, 0) -- (1, 0); \draw[yshift=-0.035cm] (0, 0) -- (1, 0); \draw[dynkin node] (0, 0) circle [radius = 0.075]; \draw[dynkin node] (1, 0) circle [radius = 0.075]; }
    .
    
    Notice that for some low-rank cases the Dynkin diagrams are degenerate, for example \(A_1\) and \(B_1\) both correspond to
    \tikzsetnextfilename{dynkin-B1}
    \tikz[baseline=-2.5pt]{ \draw[dynkin node] (0, 0) circle [radius = 0.075]; }
    which reflects the fact that \(A_1 \cong B_1\), which is to say \(SU(2) \cong SO(3)\), a fact that will be important later.
    It also explains why the \(E_n\) exceptional groups start at \(E_6\), since the Dynkin diagram for \(E_5\) is the same as for \(D_5\), and the Dynkin diagram for \(E_4\) is the same as for \(A_4\).
    
    \chapter{Lie Algebras}
    A lot of the uses of Lie groups make use of the underlying analytic structure to expand the group elements in the parameters, \(\{\alpha\}\), and then keep only the first order terms, linearising the group.
    Mathematically this is what we do if we move to the tangent space of the manifold and we call the resulting linear space the \defineindex{Lie algebra} associated with the Lie group.
    We will start with a simple example which we will then generalise.
    
    \section{The Abelian Group \texorpdfstring{\(\unitary(1) \isomorphic \specialOrthogonal(2)\)}{U(1) isomorphic to SO(2)}}
    We can define the unitary group \(\unitary(1)\) as
    \begin{equation}
        \unitary(1) \coloneqq \{ U \in \matrices{1}{\complex} \mid U^\hermit U = \ident \}.
    \end{equation}
    This is obviously the same as the circle group
    \begin{equation}
        \mathbb{T} \coloneqq \{ z \in \complex \mid \abs{z} = 1 \}
    \end{equation}
    under the obvious isomorphism associating \((z) \in \unitary(1)\) with \(z \in \mathbb{T}\).
    We therefore don't distinguish between \(\unitary(1)\) and \(\mathbb{T}\) and will say things like \(z \in \unitary(1)\), when it may be more proper to say \((z) \in \unitary(1)\).
    As the name suggests \(\mathbb{T}\) is a Lie group with the circle, \(S^1\), as its underlying manifold.
    This is a one-dimensional real manifold parametrised by \(\alpha \in [0, 2\pi)\).
    
    We can define the two dimensional rotation group, \(\specialOrthogonal(2)\), as
    \begin{equation}
        \specialOrthogonal(2) \coloneqq \{ R \in \matrices{2}{\reals} \mid R^\trans R = \ident \text{ and } \det R = 1 \}.
    \end{equation}
    This acts on the plane, \(\reals^2\), through rotations, which are given by normal matrix multiplication, \(R \action \vv{x} = R\vv{x}\).
    This is a one dimensional real manifold parametrised by the rotation angle, \(\alpha \in [0, 2\pi)\).
    
    The unitary group \(\unitary(1)\) has an infinite family of representations labelled by \(n \in \integers\) given by
    \begin{equation}
        \rho_n^{\unitary(1)}(\alpha) = \e^{in\alpha}.
    \end{equation}
    Here we are implicitly associating complex numbers with \(1\times 1\) complex matrices.
    The two-dimensional rotation group, \(\specialOrthogonal(2)\), has an infinite family of representations labelled by \(n \in \integers\) given by
    \begin{equation}
        \rho_n^{\specialOrthogonal(2)}(\alpha) =
        \begin{pmatrix}
            \cos(n\alpha) & \sin(n\alpha)\\
            -\sin(n\alpha) & \cos(n\alpha)
        \end{pmatrix}
        .
    \end{equation}
    It should be clear that \(\unitary(1)\) and \(\specialOrthogonal(2)\) are isomorphic.
    One isomorphism between them being \(\e^{i\alpha} \mapsto \rho_{1}^{\specialOrthogonal(2)}(\alpha)\).
    Since this is the case we will move between them as needed choosing which ever is most appropriate for the task at hand.
    
    The Kronecker product of representation is particularly simple for this case with
    \begin{equation}
        \rho_{n} \directproduct \rho_{m} = \rho_{n + m}.
    \end{equation}
    
    In order to linearise \(\specialOrthogonal(2)\) we make use of the fact that elements of \(\unitary(1)\) can be expressed as \(\e^{i\alpha}\) and we suggest that \(O \in \specialOrthogonal(2)\) can be expressed as
    \begin{equation}
        O = \exp[i\alpha T]
    \end{equation}
    for \(T \in \matrices{2}{\reals}\).
    As usual the exponential of a matrix is to be understood either  through its power series,
    \begin{equation}
        \exp(A) = \sum_{n = 0}^{\infty} \frac{A^n}{n!},
    \end{equation}
    or a limit,
    \begin{equation}
        \exp(A) = \lim_{n \to \infty} \left( 1 + \frac{A}{n} \right)^{n}.
    \end{equation}
    
    \begin{lma}{}{}
        Let \(A \in \matrices{m}{\complex}\) be diagonalisable.
        Then \(\det(\exp(A)) = \exp(\tr(A))\).
        \begin{proof}
            Let \(A \in \matrices{m}{\complex}\) be diagonalisable.
            We work in the basis in which \(A\) is diagonal since both \(\det\) and \(\tr\) are basis independent.
            In this basis the diagonal of \(A\) consists of its eigenvalues, \(\lambda_i\).
            We then have
            \begin{equation}
                \det A = \prod_{i = 1}^{m} \lambda_i,
            \end{equation}
            and
            \begin{equation}
                \tr A = \sum_{i = 1}^{m} \lambda_i.
            \end{equation}
            Further in this basis \(\exp(A)\) is diagonal and its diagonal components are \(\exp(\lambda_i)\).
            This follows since the \(n\)th power of a diagonal matrix just raises the elements on the diagonal to the \(n\)th power, that is
            \begin{equation}
                \begin{pmatrix}
                    \lambda_1 &&\\
                    &\ddots &\\
                    && \lambda_m
                \end{pmatrix}
                ^n = 
                \begin{pmatrix}
                    \lambda_1^n &&\\
                    &\ddots &\\
                    && \lambda_m^n
                \end{pmatrix}
                .
            \end{equation}
            It follows that
            \begingroup
            \allowdisplaybreaks
            \begin{align}
                \exp(A) &= \sum_{n = 0}^{\infty} \frac{A^n}{n!}\\
                &= \sum_{n = 0}^{\infty} \frac{1}{n!} 
                \begin{pmatrix}
                    \lambda_1 && \\
                    & \ddots & \\
                    && \lambda_m
                \end{pmatrix}
                ^n\\
                &= \sum_{n = 0}^{\infty} \frac{1}{n!}
                \begin{pmatrix}
                    \lambda_1^n && \\
                    & \ddots & \\
                    && \lambda_m^n
                \end{pmatrix}
                \\
                &= 
                \begin{pmatrix}
                    \sum_{n = 0}^{\infty} \frac{\lambda_1^n}{n!} && \\
                    & \ddots & \\
                    && \sum_{n = 0}^{\infty} \frac{\lambda_m^n}{n!}
                \end{pmatrix}
                \\
                &= 
                \begin{pmatrix}
                    \exp(\lambda_1) && \\
                    & \ddots & \\
                    && \exp(\lambda_m)
                \end{pmatrix}
            \end{align}
            \endgroup
            Hence
            \begin{align}
                \exp(\tr(A)) &= \exp\left( \sum_{i} \lambda_i \right)\\
                &= \prod_{i} \exp(\lambda_i)\\
                &= \det(\exp(\lambda_i)).
            \end{align}
        \end{proof}
    \end{lma}
    
    The definition of \(O \in \specialOrthogonal(2)\) is that \(O^\trans O = \ident\), which can be expressed as
    \begin{align}
        \ident &= O^\trans O\\
        &= \exp(i\alpha T)^{\trans} \exp(i\alpha T)\\
        &= \exp(i\alpha T^{\trans}) \exp(i\alpha T)\\
        &= (\ident + i\alpha T^{\trans} + \order(\alpha^2))(\ident + i\alpha T + \order(\alpha^2))\\
        &= \ident + i\alpha(T^\trans + T) + \order(\alpha^2).
    \end{align}
    Therefore if we take \(\alpha\) to be small we have that \(T^{\trans} = -T\), which is to say that \(T\) must be antisymmetric.
    This in fact generalises to \(\specialOrthogonal(n)\), we can write any element as \(\exp(i\alpha T)\) where \(T \in \matrices{n}{\reals}\) is antisymmetric.
    
    One particular solution is
    \begin{equation}
        T = i
        \begin{pmatrix}
            0 & 1\\
            -1 & 0
        \end{pmatrix}
        ,
    \end{equation}
    which leads to the previous representation since \(T^2 = \ident\) and so
    \begin{equation}
        \exp(i\alpha T) = \ident \cos(\alpha) + iT\sin(\alpha) = \rho_1^{\specialOrthogonal(2)}(\alpha).
    \end{equation}
    This follows by expanding the exponential and collecting even and odd terms.
    
    We define the Lie algebra of \(\specialOrthogonal(2)\) to be all (real) scalar multiples of \(T\), \(\specialOrthogonalLie(2) \coloneqq \{\lambda T \mid \lambda \in \reals\}\).
    This is fairly boring since there is only one dimension, but it is useful to demonstrate the tangent space notion of the Lie algebra.
    
    As previously mentioned the underlying manifold for \(\unitary(1)\), and hence \(\specialOrthogonal(2)\), is the circle, \(S^1 = \{(x, y) \in \reals^2 \mid x^2 + y^2 = 1\}\), strictly this is an embedding of \(S^1\) in two-dimensions, on its own \(S^1\) is a one-dimensional manifold.
    We can cover \(S^1\) with two charts, two are needed to avoid a discontinuity at the join, we simply use whichever hasn't got the join at that point.
    For example, one chart could be \(f_1(\vartheta) = (\cos\vartheta, \sin\vartheta)\) and another \(f_2(\vartheta) = (\cos(\vartheta - \pi/1), \sin(\vartheta - \pi/2))\), which is just \(f_1\) rotated around by \(\pi/2\).
    Both of these maps have the codomain \([0, 2\pi)\).
    
    Now consider the point \((x, y)\) on \(S^1\).
    We have \(T(x, y) = (-y, x)\).
    For example, if \(T(-1, 0) = (0, -1)\).
    This vector will be tangent to \(S^1\) as embedded in \(\reals^2\).
    
    \begin{figure}
        \begin{tikzpicture}
            \draw[thick, ->] (-3, 0) -- (3, 0) node[below] {\(x\)};
            \draw[thick, ->] (0, -3) -- (0, 3) node[left] {\(y\)};
            \draw (0, 0) circle [radius = 2];
            \draw[ultra thick, highlight] (1.95, 0) arc (0:355:1.95);
            \draw[ultra thick, my blue, rotate=-90] (2.05, 0) arc (0:355:2.05);
            \draw[ultra thick, highlight] (-3, 3) -- ++ (1, 0) coordinate (A);
            \draw[->] (A) to[bend left] (100:1.95);
            \node at (-0.6, 2.7) {\(f_1\)};
            \draw[ultra thick, my blue] (-3, 2.5) -- ++ (1, 0) coordinate (B);
            \draw[->] (B) to[bend left] (135:2.05);
            \node at (-1.35, 2.15) {\(f_2\)};
            \draw[my red, very thick, ->] (-2, 0) -- ++ (0, -2) node[left, black] {\(T(-1, 0) = (0, -1)\)};
            \node at (-3, 2.75) {0};
            \node at (-2, 2.75) {\(2\pi\)};
        \end{tikzpicture}
        \caption[The manifold \(S^1\)]{The manifold \(S^1\) covered by two charts, \(f_1\) and \(f_2\). \(T(x, y)\) gives a tangent vector as demonstrated by the case of \((x, y) = (-1, 0)\). The slight gaps in the two charts represent the discontinuity in \(\alpha\) going from 0 to \(2\pi\). Either chart is valid away from these discontinuities and at a discontinuity simply use the continuous chart.}
    \end{figure}
    
    The manifold \(\specialOrthogonal(2)\) is connected, since \(S^1\) is clearly connected.
    On the other hand the manifold \(\orthogonal(2)\) is \emph{not} connected.
    It is formed from two disconnected pieces, one, which has \(\det O = 1\), is essentially a copy of \(\specialOrthogonal(2)\), and one where \(\det O = -1\).
    These two pieces are disconnected since \(\det\) is a continuous function of the parameters yet makes a sudden jump from \(-1\) to \(+1\), which can only happen if there is a corresponding sudden jump in the parameters, meaning that \(\orthogonal(2)\) is not connected.
    
    Consider the parity operator
    \begin{equation}
        P = 
        \begin{pmatrix}
            1 & 0\\
            0 & -1
        \end{pmatrix}
        .
    \end{equation}
    This is an element of \(\orthogonal(2)\), but not \(\specialOrthogonal(2)\).
    Since \(P^2 = \ident\) we can view \(P\) as generating \(\integers_2 = \presentation{P}{P^2 = \ident}\) and we can then identify
    \begin{equation}
        \specialOrthogonal(2) \isomorphic \orthogonal(2) / \integers_2.
    \end{equation}
    In fact, this generalises to
    \begin{equation}
        \specialOrthogonal(n) \isomorphic \orthogonal(n) / \integers_2.
    \end{equation}
    Further we have
    \begin{equation}
        \specialUnitary(n) \isomorphic \unitary(n) / \unitary(1)
    \end{equation}
    since we can think of \(\unitary(1)\) as the complex version of \(\integers_2\).
    
    For \(\specialOrthogonal(2)\) the Haar measure is
    \begin{equation}
        \int_0^{2\pi} \frac{\dl{\alpha}}{2\pi}
    \end{equation}
    and so we can define an inner product on the character space as
    \begin{align}
        \innerprod{\chi_{\rho_n}}{\chi_{\rho_m}}_{\unitary(1)} &= \frac{1}{2\pi}\int_{0}^{2\pi} \chi_{\rho_n}(\alpha)^* \chi_{\rho_m}(\alpha) \dd{\alpha}\\
        &= \frac{1}{2\pi} \int_{0}^{2\pi} (\e^{in\alpha})^*\e^{im\alpha} \dd{\alpha}\\
        &= \frac{1}{2\pi} \int_{0}^{2\pi} \e^{i(n - m)\alpha} \dd{\alpha}\\
        &= \delta_{nm}.
    \end{align}
    We see that the character are orthonormal with respect to this inner product.
    The characters turn out to be less important for Lie groups than finite groups and we won't consider them much more.
    
    \section{Lie Algebra Generalities}\label{sec:lie algebra generalities}
    \begin{thm}{Exponential Map}{}
        Every one-parameter subgroup of \(\generalLinear(n, \complex)\) is given by a matrix exponential, \(\rho_T(t) = \exp(tT)\) where \(T \in \matrices{n}{\complex}\) and \(T\) is not the zero matrix.
        \begin{rmk}
            We call \(T\) the \defineindex{generator} of the one-parameter subgroup.
        \end{rmk}
        \begin{proof}
            Consider the single parameter homomorphism \(\rho_T \colon \reals \to \generalLinear(n, \complex)\) defined by
            \begin{equation}
                \diff*{\rho_T(t)}{t}[t = 0] = T
            \end{equation}
            with the boundary condition \(\rho_T(0) = \ident\).
            Since \(\rho_T\) is a group homomorphism we require
            \begin{equation}
                \rho_T(s + t) = \rho_T(s)\rho_T(t).
            \end{equation}
            Differentiating this with respect to \(s\) and evaluating at \(s = 0\) gives
            \begin{equation}
                \diff*{\rho_T(s + t)}{s}[s = 0] = \diff*{\rho_T(s)}{s}[s = 0]\rho_T(t) = T\rho_T(t) = \diff*{\rho_T(t + s)}{s}[s = 0] = \diff*{\rho_T(t)}{t}
            \end{equation}
            where in the last step we set \(s + t = t\).
            This gives us a differential equation
            \begin{equation}
                \diff*{\rho_T(t)}{t} = T\rho_T(t)
            \end{equation}
            which has the unique solution
            \begin{equation}
                \rho_T(t) = \exp(t T).
            \end{equation}
            This proves the theorem.
        \end{proof}
    \end{thm}
    
    This theorem generalises to multi-parameter subgroups of \(\generalLinear(n, \complex)\), where we can write all elements in the form
    \begin{equation}
        \exp(t^aT_a)
    \end{equation}
    with the Einstein summation convention implying \(t^aT_a = t^1T_1 + t^2T_2 + \dotsb + t^kT_k\).
    
    The possible generators depend on the group.
    We want to consider the product \(\rho_1\rho_2\rho_1^{-1}\rho_2^{-1}\), this will be \(\ident\) for an Abelian group and some \(\rho_3\) in the group by the closure of the group for a non-Abelian group.
    In order to avoid the \defineindex{Baker--Campbell--Hausdorff formula},
    \begin{equation}
        \e^{A}\e^{B} = \exp\left( A + B + \frac{1}{2}\commutator{A}{B} + \frac{1}{2}\frac{1}{3!}\big(\commutator{A}{\commutator{A}{B}} + \commutator{\commutator{A}{B}}{B}\big) + \dotsb \right),
    \end{equation}
    we expand \(\rho_i\) as
    \begin{align}
        \rho_1 &= \ident + i\alpha^a T_a + \frac{1}{2}(i\alpha^aT_a)^2 + \order(\alpha^3),\\
        \rho_2 &= \ident + i\beta^a T_a + \frac{1}{2}(i\beta^aT_a)^2 + \order(\beta^3),\\
        \rho_3 &= \ident + i\gamma^a T_a + \frac{1}{2}(i\gamma^aT_a)^2 + \order(\gamma^3).
    \end{align}
    We call the matrices \(T_a\) the Lie algebra generators.
    Substituting this into \(\rho_1\rho_2\rho_1^{-1}\rho_2^{-1}\) we get
    \begin{equation}
        \commutator{\alpha^aT_a}{\beta^bT_b} = -i\gamma^cT_c + \order(\alpha^3, \beta^3, \gamma^3).
    \end{equation}
    All lower order terms cancel.
    We can therefore find \(\rho_3\) by finding \(\gamma^c = -\tensor{f}{_{ab}^c}\alpha^a\beta^b\) where we define the \defineindex{structure constants}, \(\tensor{f}{_{ab}^c}\), through the Lie algebra
    \begin{equation}
        \liebracket{T_a}{T_b} = i\tensor{f}{_{ab}^c} T_c.
    \end{equation}
    This is the bare minimum amount of structure that the generators have to have in order to be compatible with the group structure.
    Notice that \(\tensor{f}{_{ab}^c} = -\tensor{f}{_{ba}^c}\), since \(\commutator{A}{B} = -\commutator{B}{A}\).
    Importantly the structure constants depend only on the commutator, and not on the anti-commutator.
    This is required since the commutator is independent of the representation but the anti-commutator is not.
    
    The number of generators is equal to the dimension of the Lie group.
    Not all generators commute.
    We define the \defineindex{rank} of the Lie group to be the size of the largest subset of generators such that all generators in the subset commute.
    Notice that the rank is at most equal to the dimension of the Lie group, with equality for an Abelian group where all generators, and hence all group elements, commute.
    Note that both \(\specialOrthogonal(3)\) and \(\specialUnitary(2)\) are rank one, which makes them about as simple as non-Abelian Lie groups can be.
    
    We now posit a theorem without proof, since the proof requires more details about manifolds which are beyond the scope of this course.
    \begin{thm}{}{}
        To any Lie algebra there corresponds a unique Lie group which is simply connected.
        This group is called the \defineindex{universal covering group}.
    \end{thm}
    In particular we find the universal covering group by exponentiating the Lie algebra.
    The important thing here is the simply connected part.
    This means that if we linearise a Lie group to get its Lie algebra the exponential map won't necessarily give back the same group, but it will give back a subgroup which is simply connected.
    As a subgroup this must contain the identity, and so we call this the component of the Lie group connected to the identity.
    
    It turns out that compactness puts some restrictions on what the generators can be.
    \begin{thm}{}{}
        For a compact group the associated Lie algebra is generated by Hermitian generators.
        \begin{proof}
            Given some \(\rho \in G\) such that \(\rho\) is connected to the identity we can write \(\rho = \exp(\iota\alpha^aT_a)\).
            Compact groups admit finite dimensional unitary representations, and so we have
            \begin{align}
                \ident &= \exp(i\alpha^aT_a)^\hermit \exp(i\alpha^aT_a)\\
                &= \exp(-i\alpha^aT_a^\hermit)\exp(i\alpha^aT_a)\\
                &= (\ident - i\alpha^aT_a^\hermit + \order(\alpha^2))(\ident + i\alpha^aT_a + \order(\alpha^2))\\
                &= \ident + i\alpha^a(T_a - T_a^\hermit) + \order(\alpha^2).
            \end{align}
            Hence we must have \(T_a - T_a^\hermit = 0\), and since this must hold for all \(\rho\), and hence for all \(\alpha^a\) we have \(T_a = T_a^\hermit\) meaning \(T_a\) is Hermitian individually for each \(a\).
        \end{proof}
    \end{thm}
    
    \begin{crl}{}{}
        The Hilbert--Schmidt inner product on \(\matrices{n}{\complex}\) is defined by
        \begin{equation}
            \innerprod{T_a}{T_b} \coloneqq \tr(T_a^\hermit T_b),
        \end{equation}
        and if \(T_a\) are the generators of a Lie algebra associated with a compact group, that is \(T_a\) are Hermitian, we have
        \begin{equation}
            \innerprod{T_a}{T_b} \coloneqq \tr(T_a^\hermit T_b) = \tr(T_aT_b).
        \end{equation}
    \end{crl}
    
    This leads to the following theorem,
    \begin{thm}{}{}
        For a compact, semi-simple Lie algebra there is an orthogonal basis such that
        \begin{equation}
            \innerprod{T_a}{T_b} \coloneqq \tr(T_aT_b) = 2k_{R}\delta_{ab}.
        \end{equation}
    \end{thm}
    We call \(k_R\) the \defineindex{Dynkin index} and it depends on the representation, which is what the subscript \(R\) is there to remind us of.
    In this basis the structure constants, \(\tensor{f}{_{ab}^c}\), are completely antisymmetric.
    
    We can make the above theorem slightly more precise, but this theorem is beyond the scope of the course:
    \begin{thm}{Killing Metric}{}
        We can define a unique symmetric tensor called the \defineindex{Killing metric}:
        \begin{equation}
            k_{ab} \coloneqq \frac{1}{k_R} \tr(T_aT_b)
        \end{equation}
        where \(k_R\) is some constant depending on the choice of representation.
        This tensor is invariant under the action of the Lie group, that is
        \begin{equation}
            0 = \delta_{T_c} \tr(T_aT_b) = \tr(\liebracket{T^c}{T_a}T_b) + \tr(T_a\liebracket{T^c}{T_b}) = ik_R(\tensor{f}{^c_{ab}} + \tensor{f}{^c_{ba}}).
        \end{equation}
        This implies that the structure constants are completely antisymmetric.
        
        For semi-simple Lie groups the Killing metric is non-singular.
        For semi-simple, compact Lie groups there is a basis where
        \begin{equation}
            k_{ab} = 2\delta_{ab}.
        \end{equation}
    \end{thm}

    We can use the metric, \(k_{ab}\), to raise and lower indices\footnote{see the notes for general relativity for lots on raising and lower indices}.
    Since \(k_{ab} \propto \delta_{ab}\) in this particular basis there is no numerical difference between \(\tensor{f}{_{ab}^c}\) and \(f_{abc}\) and so we won't differentiate between them.
    
    \begin{thm}{Jacobi Identity}{}
        The structure constants satisfy the \defineindex{Jacobi identity}:
        \begin{equation}
            f_{aed}f_{bce} + f_{bed}f_{cae} + f_{ced}f_{abc} = 0.
        \end{equation}
        \begin{rmk}
            Note that this is simply \(f_{aed}f_{bce}\) with a sum over cyclic permutations of \(a\), \(b\), and \(c\).
        \end{rmk}
        \begin{proof}
            For any three matrices, \(A, B, C \in \matrices{n}{\complex}\) we have
            \begin{equation}
                \commutator{A}{\commutator{B}{C}} + \commutator{B}{\commutator{C}{A}} + \commutator{C}{\commutator{A}{B}}.
            \end{equation}
            This can be shown by expanding these commutators.
            We can then interpret \(f_{abc}\) as the components of the matrix \((T_a^{\mathrm{adj}})_{bc} = -if_{abc}\) and the result follows.
        \end{proof}
    \end{thm}
    
    \begin{dfn}{Adjoint Representation}{}
        The \defineindex{adjoint representation} is given by defining the generator \(T_c^{\mathrm{adj}}\) to have components \((T_c^{\mathrm{adj}})_{bc} = -if_{abc}\).
    \end{dfn}
    
    \begin{crl}{}{}
        The structure constants are real.
        \begin{proof}
            If \(T_a\) generates a representation of the Lie algebra then so does \(-T_a^*\), this is just the negative of the complex conjugate representation.
            Taking the complex conjugate of the definition of the adjoint representation, dropping the \(\mathrm{adj}\) label, we have
            \begin{equation}
                \commutator{T_a}{T_b}^* = (if_{abc}T_c)^* \implies \commutator{T_a^*}{T_b^*} = -if_{abc}^*T_c^*
            \end{equation}
            noting that \(\commutator{-A}{-B} = \commutator{A}{B}\) since the negatives cancel when we expand the commutator we get
            \begin{equation}
                \commutator{-T_a^*}{-T_b^*} = if_{abc}^*(-T_a^*).
            \end{equation}
            Since \(f_{abc}\) are independent of the representation we must have \(f_{abc} = f_{abc}^*\), which means that \(f_{abc} \in \reals\).
        \end{proof}
    \end{crl}
    The adjoint representation acts on the Lie algebra itself via the commutator.
    In particular if \(T_a^{\mathrm{adj}}\) are the generators in the adjoint representation and \(T_d\) are the generators in some other representation then \(T_a^{\mathrm{adj}} \circ T_d = \commutator{T_a}{T_d} = if_{ade}T_e\) and \(if_{ade} = (T_a^{\mathrm{adj}})_{de}\).
    
    So far we have viewed Lie algebras as the result of linearising a Lie group.
    We can extract the important algebraic details into a more abstract object.
    This is the way a mathematician would approach the subject.
    They would first make the following definition and then derive what we have taken as the defining properties as a result of this definition.
    \begin{dfn}{Lie Algebra}{}
        A \defineindex{Lie algebra}, \(\lie{g}\), is a vector space over \(\field\) with a non-associative, alternating bilinear product satisfying the Jacobi identity.
        This product is called the \defineindex{Lie bracket}.
        Its properties are
        \begin{itemize}
            \item \define{Bilinearity}: For all \(x, y, z \in \lie{g}\) and \(a, b \in \field\)
            \begin{align}
                \liebracket{ax + by}{z} = a\liebracket{x}{z} + b\liebracket{y}{z}, \qand\\
                \liebracket{z}{ax + by} = a\liebracket{z}{x} + b\liebracket{z}{y}.
            \end{align}
            \item \define{Alternativity}: For all \(x \in \lie{g}\)
            \begin{equation}
                \liebracket{x}{x} = 0.
            \end{equation}
            \item The \defineindex{Jacobi identity}: For all \(x, y, z \in \lie{g}\)
            \begin{equation}
                \liebracket{x}{\liebracket{y}{z}} + \liebracket{y}{\liebracket{z}{x}} + \liebracket{z}{\liebracket{x}{y}} = 0.
            \end{equation}
        \end{itemize}
    \end{dfn}
    Notice that the Jacobi identity just says that sums over symmetric permutations of \(x\), \(y\), and \(z\) in \(\liebracket{x}{\liebracket{y}{z}}\) must vanish.
    Another important fact is that alternativity combined with bilinearity implies anticommutativity, so \(\liebracket{x}{y} = -\liebracket{y}{x}\) for all \(x, y \in \lie{g}\).
    
    With this definition we can define the universal enveloping algebra:
    \begin{dfn}{Universal Enveloping Algebra}{}
        Given a Lie algebra, \(\lie{g}\), we can embed it in an associative algebra, \(A\), in such a way that the abstract Lie bracket of \(\lie{g}\), corresponds to the commutator in \(A\), that is \(\liebracket{x}{y} = xy - yx\) in \(A\).
        The \defineindex{universal enveloping algebra} is defined to be the associative algebra generated by \(t_i\) which are subject only to the conditions
        \begin{equation}
            t_it_j - t_jt_i = if_{ijk}t_k.
        \end{equation}
        We denote elements of the universal enveloping algebra here by lower case to distinguish from elements of the Lie algebra.
    \end{dfn}
    Since we mostly consider matrix Lie groups which have Lie algebras where the Lie bracket can be interpreted as the commutator we often won't distinguish between the Lie algebra and its universal enveloping algebra.
    
    The reason for defining the universal enveloping algebra is to make the following definition:
    \begin{dfn}{Casimir Element}{}
        A \defineindex{Casimir element} is an element of the universal enveloping algebra of a Lie algebra which commutes with all generators of the Lie algebra.
        That is it is in the centre of the universal enveloping algebra.
    \end{dfn}
    Every Lie algebra associated with a semi-simple Lie group has at least one Casimir element, called the \defineindex{quadratic Casimir}, which is defined by
    \begin{equation}
        C = \delta^{ab}T_aT_b.
    \end{equation}
    For compact Lie groups Schur's lemma (\cref{thm:schurs lemma}) tells us that \(C\) is proportional to the identity, so \(C = C_2(R)\ident\), where the 2 stands for quadratic and the \(R\) tells us that the value of the number \(C_2(R)\) is representation dependent.
    
    It can be shown that the number of Casimir operators is equal to the number of invariant tensors, which is equal to the rank of the Lie algebra.
    
    \section{The Non--Abelian Groups \texorpdfstring{\(\specialUnitary(2)\)}{SU(2)} and \texorpdfstring{\(\specialOrthogonal(3)\)}{SO(3)}}
    \subsection{The Lie Algebras of \texorpdfstring{\(\specialUnitary(2)\)}{SU(2)} and \texorpdfstring{\(\specialOrthogonal(3)\)}{SO(3)}}
    Recall that
    \begin{equation}
        \specialOrthogonal(3) \coloneqq \{ O \in \matrices{3}{\reals} \mid O^\trans O = \ident \},
    \end{equation}
    and
    \begin{equation}
        \specialUnitary(2) \coloneqq \{ U \in \matrices{2}{\complex} \mid U^\hermit U = \ident \}.
    \end{equation}
    
    The Lie algebra of \(\specialOrthogonal(3)\), denoted \(\specialOrthogonalLie(3)\), is generated by any three linearly independent antisymmetric matrices.
    Ideally we would work in a basis where the structure constants are completely antisymmetric.
    Such a basis is guaranteed to exist since \(\specialOrthogonal(3)\) is compact and simple.
    One such basis is
    \begin{equation}
        T_1 = -i
        \begin{pmatrix}
            0 & 0 & 0\\
            0 & 0 & 1\\
            0 & -1 & 0
        \end{pmatrix}
        , \quad T_2 = -i
        \begin{pmatrix}
            0 & 0 & -1\\
            0 & 0 & 0\\
            1 & 0 & 0
        \end{pmatrix}
        , \qand T_3 = -i
        \begin{pmatrix}
            0 & 1 & 0\\
            -1 & 0 & 0\\
            0 & 0 & 0
        \end{pmatrix}
        .
    \end{equation}
    Notice that the first \(2\times 2\) submatrix of \(T_3\) corresponds to a rotation by \(\pi/2\) in \(\specialOrthogonal(2)\), which corresponds to a three-dimensional rotation about the \(z\)-axis.
    The other two matrices are just permutations of this.
    It is easy to compute the Lie algebra for these three matrices:
    \begin{equation}
        \liebracket{T_a}{T_b} = i\varepsilon_{abc}T_c
    \end{equation}
    where \(\varepsilon_{abc}\) is the Levi--Civita symbol.
    Hence the structure constants are \(f_{abc} = \varepsilon_{abc}\).
    This shouldn't be too surprising since in three dimensions any antisymmetric tensor of rank 3 must be proportional to \(\varepsilon_{abc}\).
    We can easily calculate the Dynkin index from
    \begin{equation}
        \tr(T_aT_b) = 2k_R\delta_{ab},
    \end{equation}
    since putting in \(a = b = 1\) we get \(\tr(T_1T_1) = 2\) and so \(k_R = 1\) for this representation.
    
    We know that the Lie algebra of \(\specialUnitary(2)\), denoted \(\specialUnitaryLie(2)\), is generated by traceless Hermitian matrices.
    One choice is the Pauli matrices,
    \begin{equation}
        \sigma_1 = 
        \begin{pmatrix}
            0 & 1\\
            1 & 0
        \end{pmatrix}
        , \qquad \sigma_2 = 
        \begin{pmatrix}
            0 & -i\\
            i & 0
        \end{pmatrix}
        , \qqand \sigma_3 = 
        \begin{pmatrix}
            1 & 0\\
            0 & -1
        \end{pmatrix}
        .
    \end{equation}
    The generators of \(\specialUnitaryLie(2)\) are then given by
    \begin{equation}
        T_a \coloneqq \frac{1}{2}\sigma_a.
    \end{equation}
    We can easily show that \(\tr(T_aT_b) = \delta_{ab} = 2k_R\delta_{ab}\) and so \(k_R = 1/4\) for this representation.
    The Lie algebra can be shown to satisfy
    \begin{equation}
        \liebracket{T_a}{T_b} = i\varepsilon_{abc}T_c,
    \end{equation}
    which is the same as for \(\specialOrthogonalLie(3)\).
    
    What this means is that \(\specialOrthogonal(3)\) and \(\specialUnitary(2)\) are \defineindex{locally isomorphic}, meaning they have the same Lie algebra, but globally different, meaning they have different Dynkin indices.
    
    Given that \(\specialOrthogonalLie(3) \isomorphic \specialUnitaryLie(2)\) there must be a single simply connected Lie group which this Lie algebra exponentiates to.
    We can show that this is \(\specialUnitary(2)\).
    Consider the mapping \(\varphi \colon \reals^4 \to \specialUnitary(2)\) given by
    \begin{equation}
        \varphi(x_0, x_1, x_2, x_3) = x_0\ident_2 + x_1 i\sigma_1 + x_2 i\sigma_2 + x_3 i\sigma_3 = 
        \begin{pmatrix}
            x_0 + ix_3 & ix_1 + x_2\\
            ix_1 - x_2 & x_0 - ix_3
        \end{pmatrix}
        \coloneqq U.
    \end{equation}
    The defining conditions for \(\specialUnitary(2)\) lead to
    \begin{equation}
        U^\hermit U = \ident_2 \text{ and } \det U = 1 \iff x_0^2 + x_1^2 + x_2^2 + x_3^2 = 1.
    \end{equation}
    What this means is that \(\specialUnitary(2)\) is topologically (homeomorphic to) a three-sphere, \(S^3\).
    Since three-spheres are simply connected this means \(\specialUnitary(2)\) is simply connected and so \(\specialOrthogonalLie(3) \isomorphic \specialUnitaryLie(2)\) exponentiates to \(\specialUnitary(2)\).
    
    It is worth briefly considering why \(\specialOrthogonal(3)\) is not simply connected.
    As a manifold \(\specialOrthogonal(3)\) is a three-dimensional ball of radius \(\pi\), that is \(\{(x, y, z) \in \reals^3 \mid x^2 + y^2 + z^2 \le \pi^2\}\) with opposite points associated.
    That is if two points are opposite on the 2-sphere \(\{(x, y, z) \in \reals^3 \mid x^2 + y^2 + z^2 = \pi^2\}\), we consider them to be the same point.
    The reason for this is that we can associate a line through the centre of this ball to be the axis of rotation and the distance we move along the line from the origin is the magnitude of the rotation, with the origin representing the angle 0 and one end of the line \(\pi\), and the other end \(-\pi\), however a rotation by \(\pi\) is the same as a rotation by \(-\pi\).
    This manifold is not simply connected.
    Consider a loop which goes along this line through the origin and then goes around the outside of the ball before joining up the other side of the loop.
    Moving along the line corresponds to rotating more or less and moving along the surface corresponds to changing the axis of rotation, essentially flipping the axis of rotation as we move from one side to the other.
    This is not contractible to a point and so \(\specialOrthogonal(3)\) is not simply connected.
    
    Since \(\specialOrthogonal(3)\) and \(\specialUnitary(2)\) have the same Lie algebra and \(\specialUnitary(2)\) is the simply connected universal covering group we expect there to be an \(n\)-to-1 map \(\specialUnitary(2) \to \specialOrthogonal(3)\).
    Indeed there is, for \(n = 2\), and we call \(\specialUnitary(2)\) a \defineindex{double cover} of \(\specialOrthogonal(3)\).
    One such map is given by the \defineindex{Weyl homomorphism} which defines the function \(h\) to be \(h(\vv{x}) = x_1\sigma_1 + x_2\sigma_2 + x_3\sigma_3\).
    This then satisfies
    \begin{equation}
        Uh(\vv{x})U^\hermit = h(O\vv{x})
    \end{equation}
    where \(U\) is any unitary \(2\times 2\) matrix and this equation defines \(O\) as some orthogonal \(3\times 3\) matrix.
    We can use this to define a map \(U \mapsto O\), which is a map \(\specialUnitary(2) \to \specialOrthogonal(3)\).
    The kernel of this map is \(\{\pm \ident\} \isomorphic \integers_2\), and so
    \begin{equation}
        \specialOrthogonal(3) \isomorphic \specialUnitary(2) / \integers_2
    \end{equation}
    by the first isomorphism theorem (\cref{thm:first isomorphism}).
    
    %   Appdendix
    \appendixpage
    \begin{appendices}
        \include{parts/math-prelim-appendix}
        \include{parts/groups-appendix}
        \include{parts/manifolds-appendix}
        \include{parts/algebras-appendix}
    \end{appendices}
    
    \backmatter
    \renewcommand{\glossaryname}{Acronyms}
    \printglossary[acronym]
    \printindex
\end{document}

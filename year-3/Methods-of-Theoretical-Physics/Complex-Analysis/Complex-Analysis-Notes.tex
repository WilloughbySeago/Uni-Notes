\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{NotesPackage2}
\usepackage{subcaption}
\usepackage{pgfplots}
\usepackage{tcolorbox}
\usepackage{hyperref}

\usetikzlibrary{calc}
\usetikzlibrary{external}
\usetikzlibrary{hobby}

\tcbuselibrary{theorems}
\tcbuselibrary{breakable}


\tikzexternalize[prefix=tikz-external/]
\tikzexternaldisable

\author{Willoughby Seago}
\date{January 11, 2021}
\title{
    Methods of Theoretical Physics\\
    {\Large Complex Analysis}
}

\makeglossaries
% Add glossary entries here
\newacronym{mvt}{MVT}{mean value theorem}  % this is an example

\newcommand{\notesVersion}{1.2}
\newcommand{\notesDate}{04/07/2021}

\DeclareMathOperator{\Arg}{Arg}
\newcommand{\st}{\mid}
\DeclareMathOperator{\arcosh}{arcosh}
\DeclareMathOperator{\arsinh}{arsinh}
\DeclareMathOperator{\cosec}{cosec}
\DeclareMathOperator{\sinc}{sinc}
\newcommand{\pvint}{{-\mkern-19mu}\int}

% Discs
\newcommand{\disc}[2]{D\left({#1}; {#2}\right)}
\newcommand{\discOpen}[2]{D\left({#1}; {#2}\right)}
\newcommand{\discClosed}[2]{\bar{D}\left({#1}; {#2}\right)}
\newcommand{\discPunctured}[2]{D'\left({#1}; {#2}\right)}

% Union/Intersection
\newcommand{\intersection}{\cap}
\newcommand{\union}{\cup}

% Environments
%\declaretheorem[name=Notation, numbered=no, style=remark]{notation}
\newenvironment{question}{\itshape}{~\\}


\begin{document}
    \pagenumbering{roman}  % Number contents pages and glossaries with roman numerals
    \maketitle
    These are my notes for the \textit{complex analysis} part of the \textit{methods of theoretical physics} course from the University of Edinburgh as part of the third year of the theoretical physics degree.
    When I took this course in the 2020/21 academic year it was taught by Dr Miguel Mart\`inez-Canales\footnote{\url{https://www.ph.ed.ac.uk/people/miguel-martinez-canales}}.
    These notes are based on the lectures delivered as part of this course and the notes provided as part of this course.
    The content within is correct to the best of my knowledge but if you find a mistake or just disagree with something or think it could be improved please let me know.
    
    These notes were produced using \LaTeX\footnote{\url{https://www.latex-project.org/}}.
    Graphs where plotted using Matplotlib\footnote{\url{https://matplotlib.org/}}, NumPy\footnote{\url{https://numpy.org/}}, and SciPy\footnote{\url{https://scipy.org/scipylib/}}.
    As well as Mathematica\footnote{\url{https://www.wolfram.com/mathematica/?source=nav}}.
    Diagrams were drawn with tikz\footnote{\url{https://www.ctan.org/pkg/pgf}}.
    
    This is version \notesVersion~of these notes, which is up to date as of \notesDate.
    \begin{flushright}
        Willoughby Seago
        
        s1824487@ed.ac.uk
    \end{flushright}
    \clearpage
    \tableofcontents
    \listoffigures
%    \listoftheorems[ignoreall, show={theorem,corollary,lemma}]
%    \renewcommand{\listtheoremname}{List of Definitions}
%    \listoftheorems[ignoreall, show=definition]
    \printglossary[type=\acronymtype, title=Acronyms]
    \clearpage
    \begingroup
    \let\clearpage\relax  % "\begingroup, \let\clearpage\relax, \endgroup" stops automatic pagebreaks after each include
    % \include sections here
    \endgroup
    \pagenumbering{arabic}  % Number rest of document with numbers
    \part{Complex Numbers}
    \section{Complex Numbers}
    \subsection{Complex Numbers Definition}
    The complex numbers, \(\complex\), are an algebraic extension to the real numbers, \(\reals\).
    That is the complex numbers are such that all complex numbers are the root of some complex polynomial with complex coefficients.
    Note that this is not true for real numbers, for example, \(-1\) is not the root of some real polynomial with real coefficients.
    \begin{definition}{Complex numbers}{}
        A \define{complex number}, \(z\), is defined as an ordered pair of real numbers, \((x, y)\in\reals^2\).
        
    \end{definition}
    The set of all complex numbers is denoted \(\complex\).
    For all \(x, y\in\reals\) \(z = (x, y) \in\complex\).
    Two complex numbers, \(z_1, z_2 \in\complex\), such that \(z_1 = (x_1, y_1)\) and \(z_2 = (x_1, y_2)\), are equal if and only if \(x_1 = x_2\) and \(y_1 = y_2\).
    That is
    \[z_1 = z_2 \iff [x_1 = x_2 \wedge y_1 = y_2].\]
    If \(z = (x, y)\in\complex\) then we say that \(x\) is the \define{real part} of \(z\) and \(y\) is the \define{imaginary part} of \(z\).
    We denote this
    \[\Re z = \real z = x, \qquad\text{and}\qquad \Im z = \imaginary z = y\]
    respectively.
    \begin{definition}{Addition and multiplication}{}
        Let \(z_1, z_2\in\complex\) such that \(z_1 = (x_1, y_1)\) and \(z_2 = (x_2, y_2)\).
        Then we define \define{addition} as
        \[z_1 + z_2 = (x_1 + x_2, y_1 + y_2)\]
        and \define{multiplication} as
        \[z_1z_2 = (x_1x_2 - y_1y_2, x_1y_2 + x_2y_1).\]
    \end{definition}
    \begin{lemma}{Addition and multiplication properties}{}
        Addition and multiplication in \(\complex\) are \define{associative}, that is
        \[z_1 + (z_2 + z_3) = (z_1 + z_2) + z_3, \qquad\text{and}\qquad z_1(z_2z_3) = (z_1z_2)z_3\]
        for all \(z_1, z_2, z_3\in\complex\).
        Addition and multiplication in \(\complex\) are \define{commutative}, that is
        \[z_1 + z_2 = z_2 + z_1, \qquad\text{and}\qquad z_1z_2 = z_2z_1\]
        for all \(z_1, z_2 \in \complex\).
        Multiplication is \define{distributive} over addition, that is
        \[z_1(z_1 + z_2) = z_1z_2 + z_1z_3.\]
    \end{lemma}
    \begin{proof}
        Let \(z_i \in \complex\) be given by \(z_i = (x_i, y_i)\) for arbitrary \(x_i, y_i\in\reals\).
        First we will show that addition is associative:
        \begin{align*}
            z_1 + (z_2 + z_3) &= (x_1, y_1) + (x_2 + x_3, y_1 + y_3)\\
            &= (x_1 + (x_2 + x_3), y_1 + (y_2 + y_3))\\
            &= ((x_1 + x_2) + x_3, (y_1 + y_2) + y_3)\\
            &= (x_1 + x_2, y_1 + y_2) + (x_3, y_3)\\
            &= (z_1 + z_2) + z_3
        \end{align*}
        assuming associativity of addition in \(\reals\).
        Next we will show that addition is commutative.
        \[z_1 + z_2 = (x_1 + x_2, y_1 + y_2) = (x_2 + x_1, y_2 + y_1) = z_2 + z_1\]
        assuming commutativity of addition in \(\reals\).
        
        Next we will show that multiplication is associative:
        \begin{align*}
            z_1(z_2z_3) &= (x_1, y_1)(x_2x_3 - y_2y_3, x_2y_3 + x_3y_2)\\
            &= (x_1(x_2x_3 - y_2y_3) - y_1(x_2y_3 + x_3y_2), x_1(x_2y_3 + x_3y_2) + y_1(x_2x_3 - y_2y_3))\\
            &= ((x_1x_2 - y_1y_2)x_3 - (x_1y_2 + x_2y_1)y_3, (x_1x_2 - y_1y_2)y_3 + (x_1y_2 + x_2y_1)x_3)\\
            &= (x_1x_2 - y_1y_2, x_1y_2 + x_2y_1)(x_3, y_3)\\
            &= (z_1z_2)z_3
        \end{align*}
        assuming associativity and commutativity of multiplication in \(\reals\) and distributivity of multiplication over addition in \(\reals\).
        Next we will show that multiplication is commutative:
        \[z_1z_2 = (x_1x_2 - y_1y_2, x_1y_2 + x_2y_1) = (x_2x_1 - y_2y_1, x_2y_1 + x_1y_2) = z_2z_1\]
        assuming commutativity of addition and multiplication in \(\reals\).
        
        Finally we will show that multiplication distributes over addition:
        \begin{align*}
            z_1(z_2 + z_3) &= (x_1, y_1)(x_2 + x_3, y_2 + y_3)\\
            &= (x_1(x_2 + x_3) - y_1(y_2 + y_3), x_1(y_2 + y_3) + (x_2 + x_3)y_1)\\
            &= (x_1x_2 - y_1y_2 + x_1x_3 - y_1y_3, x_1y_2 + x_2y_1 + x_1y_3 + x_3y_1)\\
            &= z_1z_2 + z_1z_3
        \end{align*}
        assuming distributivity of multiplication over addition in \(\reals\).
    \end{proof}
    The element \(0 = (0, 0)\in\complex\) acts as an \define{additive identity} in that
    \[0 + z = (x + 0, y + 0) = (x, y) = z = (0 + x, 0 + y) = (0, 0) + (x, y) = z + 0\]
    for all \(z\in\complex\).
    Similarly \(1 = (1, 0)\in\complex\) acts as a \define{multiplicative identity} in that
    \[1z = (1, 0)(x, y) = (1x - 0y, 1y + 0x) = (x, y) = z = (x1 - y0, y0 + x1) = z1\]
    for all \(z\in\complex\).
    
    For \(z = (x, y)\in\complex\) the element \(-z = (-x, -y)\) acts as an \define{additive inverse} in that
    \[z + (-z) = (x + (-x), y + (-y)) = (0, 0).\]
    Similarly for \(z\in\complex\setminus\{0\}\) the element 
    \[z^{-1} = \frac{1}{z} = \left( \frac{x}{x^2 + y^2}, \frac{-y}{x^2 + y^2} \right)\]
    acts as a \define{multiplicative inverse} in that
    \begin{align*}
        zz^{-1} &= (x, y)\left( \frac{x}{x^2 + y^2}, \frac{-y}{x^2 + y^2} \right)\\
        &= \left( \frac{x^2}{x^2 + y^2} + \frac{y^2}{x^2 + y^2}, \frac{xy}{x^2 + y^2} - \frac{xy}{x^2 + y^2} \right)\\
        &= (1, 0).
    \end{align*}
    This allows us to define subtraction and division as follows
    \begin{definition}{Subtraction and division}{}
        Let \(z_1, z_2\in\complex\) such that \(z_1 = (x_1, y_1)\) and \(z_2 = (x_2, y_2)\).
        Then \define{subtraction} is defined as
        \[z_1 - z_2 = z_1 + (-z_2) = (x_1, y_1) - (x_2, y_2) = (x_1, y_1) + (-x_2, y_2) = (x_1 - x_2, y_1 - y_2)\]
        and division is defined for \(z_2 \ne 0\) as
        \[\frac{z_1}{z_2} = z_1z_2^{-1} = (x_1, y_1)\left( \frac{x_2}{x_2^2 + y_2^2}, \frac{-y_2}{x_2^2 + y_2^2} \right) = \left( \frac{x_1x_2}{x_2^2 + y_2^2} + \frac{y_1y_2}{x_2^2 + y_2^2}, \frac{-x_1y_2}{x_2^2 + y_2^2} + \frac{x_2y_1}{x_2^2 + y_2^2} \right).\]
    \end{definition}
    With addition, multiplication, subtraction, and division defined like this the properties listed above make \(\complex\) a field.
    What this means informally is that although in some ways \(\complex\) is like \(\reals^2\) when it comes to operations they behave very similarly to operations in \(\reals\).
    
    Note that with these definitions we have
    \[(0, 1)^2 = (-1, 0).\]
    We give the element \((0, 1)\) the special name \(i\) which we define to be such that \(i^2 = -1\).
    We can then factor any generic complex number, \(z = (x, y)\) as
    \[z = (x, y) = (x, 0) + (0, 1)(y, 0) = x + iy.\]
    From now on we will use the notation \(z = x + iy\) to mean \(z = (x, y)\).
    
    \subsection{Argand Diagrams}
    Since \(\complex\) is in some ways \(\reals^2\) it is natural to represent \(\complex\) geometrically with a plane.
    Diagrams that do this are called \define{Argand diagrams}.
    For example, see figure~\ref{fig:Argand diagram}.
    \begin{figure}[ht]
        \centering
        \begin{tikzpicture}
            \draw[<->] (0, 2.5) -- (0, 0) -- (2.5, 0);
            \node[left] at (0, 2.5) {\(\Im z\)};
            \node[below] at (2.5, 0) {\(\Re z\)};
            \draw[fill=black] (1.5, 1.5) circle[radius=0.05cm];
            \node[above right] at (1.5, 1.5) {\(z\)};
            \draw[dashed] (1.5, 1.5) -- (1.5, 0);
            \draw[dashed] (1.5, 1.5) -- (0, 1.5);
            \node[below] at (1.5, 0) {\(x\)};
            \node[left] at (0, 1.5) {\(y\)};
            \draw (0, 0) -- (1.5, 1.5);
            \node[above left] at (0.75, 0.75) {\(R\)};
            \draw (0.5, 0) arc[radius=0.5, start angle=0, end angle=45];
            \node at (0.7, 0.2) {\(\vartheta\)};
        \end{tikzpicture}
        \caption{An Argand diagram showing the complex number \(z = x + iy = Re^{i\vartheta}\).}
        \label{fig:Argand diagram}
    \end{figure}
    In this Argand diagram we see the point \(z\in\complex\).
    This also gives us another natural way to represent \(z\).
    A simple bit of geometry shows us that
    \[z = x + iy = R(\cos\vartheta + i\sin\vartheta)\]
    and that
    \[R = \sqrt{x^2 + y^2}, \qquad\text{and}\qquad \vartheta = \arctan\left(\frac{y}{x}\right).\]
    \begin{definition}{Modulus and argument}{}
        We call \(R = \sqrt{x^2 + y^^2}\) the \define{modulus} of \(z\), denoted \(\abs{z}\).
        We call \(\vartheta\) \emph{an} \define{argument} of \(z\), denoted \(\arg z\).
        For each \(z\in\complex\) we have an infinite number of different values that \(\vartheta\) can take.
        In general if \(\vartheta\) is an argument of \(z\) then so is \(\vartheta + 2n\pi\) for any \(n\in\integers\).
        The set of all \(\vartheta\) which satisfy \(z = \abs{z}(\cos\vartheta + i\sin\vartheta)\) for some specific point \(z\) is called \emph{the} \define{argument} of \(z\), denoted \(\Arg z\):
        \[\Arg z = \{\vartheta \st z = \abs{z}(\cos\vartheta + i\sin\vartheta)\}.\]
        We often choose to restrict \(\vartheta\) to be in \((-\pi, \pi]\) in which case we call \(\vartheta\) the \define{principle argument} of \(z\).
    \end{definition}
    One fact that will become important later is that if we traverse around a closed curve in \(\complex\) and zero is inside that curve then after we go around the entire curve we will come back to the same spot but the argument will be \(2\pi\) greater than it was before (if we traverse in an anticlockwise direction).
    
    \subsection{Euler's Formula}
    \begin{definition}{Complex exponential}{}
        The \define{complex exponential} of a purely imaginary number, \(i\vartheta\), for some \(\vartheta\in\reals\) is defined as
        \[z = e^{i\vartheta} = \cos\vartheta + i\sin\vartheta.\]
        This is called \define{Euler's formula}.
        In addition to this we also require that
        \[e^{x + iy} = e^xe^{iy}\]
        for all \(x, y\in\reals\).
    \end{definition}
    The second requirement means that many of the expected properties of real exponentials carry over to the complex exponential.
    This is an extension of the real exponential in the sense that the real and complex exponential both give the same result when we exponentiate a real number.
    For this reason we don't usually make a distinction between the real and complex exponential.
    
    We can use this to write \(z\) as
    \[z = Re^{i\vartheta} = R(\cos\vartheta + i\sin\vartheta)\]
    where \(R = \abs{z}\) and \(\vartheta = \arg z\).
    While the complex exponential is defined in this way we can motivate the definition.
    We first assume that differentiation in \(\complex\) is the same as it is in \(\reals\) and we see that
    \[\pdv{\vartheta}[\cos\vartheta + i\sin\vartheta] = -\sin\vartheta + i\cos\vartheta\]
    and also
    \[\pdv{\vartheta}e^{i\vartheta} = ie^{i\vartheta} = i (\cos\vartheta + i\sin\vartheta) = i\cos\vartheta - \sin\vartheta.\]
    Both \(e^{i\vartheta}\) and \(\cos\vartheta + i\sin\vartheta\) have the same derivative and therefore it is reasonable to conclude that they are the same.
    
    Another way to motivate this definition is by extending the Taylor series to \(\complex\) and noting that
    \begin{align*}
        \cos\vartheta + i\sin\vartheta &= \left[1 - \frac{\vartheta^2}{2!} + \frac{\vartheta^4}{4!} + \order{\vartheta^6}\right] + i\left[\vartheta - \frac{\vartheta^3}{3!} + \frac{\vartheta^5}{5!} + \order{(\vartheta^7)}\right]\\
        &= 1 + i\vartheta + \frac{(i\vartheta)^2}{2!} + \frac{(i\vartheta)^3}{3!} + \frac{(i\vartheta)^4}{4!} + \frac{(i\vartheta)^5}{5!} + \order{\vartheta^6}\\
        &= e^{i\vartheta}.
    \end{align*}
    
    Some useful values to remember are
    \[e^0 = e^{2\pi i} = 1, \qquad e^{-\pi} = -1, \qquad e^{\pm\pi/2} = \pm i, \qquad e^{\pm i\pi/4} = \frac{\sqrt{2}}{2}(1 \pm i).\]
    Also note that
    \[e^{i\vartheta} = e^{i\vartheta + 2n\pi i}\qquad \forall\vartheta\in\reals, \forall n\in\integers.\]
    
    \begin{theorem}{De Moivre's Formula}{}
        Let \(z\in\complex\) such that \(\abs{z} = 1\), then
        \[z^n = (\cos\vartheta + i\sin\vartheta)^n = \cos(n\vartheta) + i\sin(n\vartheta)\qquad \forall n\in\integers\]
        where \(\vartheta = \arg z\).
    \end{theorem}
    \begin{proof}
        We will prove this by induction for all natural numbers and later extend the result to negative numbers.
        The base case is \(n = 0\) in which case
        \[z^0 = 1 = \cos(0 \vartheta) + i\sin(0\vartheta).\]
        Suppose that this formula holds for some \(k\in\naturals\).
        That is
        \[z^k = (\cos\vartheta + i\sin\vartheta)^k = \cos(k\vartheta) + i\sin(k\vartheta).\]
        Then
        \begin{align*}
            z^{k + 1} &= (\cos\vartheta + i\sin\vartheta)^{k+1}\\
            &= (\cos\vartheta + i\sin\vartheta)^k(\cos\vartheta + i\sin\vartheta)\\
            &= (\cos(k\vartheta) + i\sin(k(\vartheta))(\cos\vartheta + i\sin\vartheta)\\
            &= \cos(k\vartheta)\cos(\vartheta) - \sin(k\vartheta)\sin(\vartheta) + i(\cos(k\vartheta)\sin(\vartheta) + \sin(k\vartheta)\cos(\vartheta))\\
            &= \cos((k + 1)\vartheta) + i\sin((k + 1)\vartheta)
        \end{align*}
        using
        \[\cos(A + B) = \cos(A)\cos(B) - \sin(A)\sin(B), \qquad\text{and}\qquad \sin(A + B) = \sin(A)\cos(B) + \sin(B)\cos(A).\]
        Thus by mathematical induction the formula holds for all \(n\in\naturals\).
        Now consider some specific \(k\in\naturals\).
        \begin{align*}
            z^{-k} &= (\cos\vartheta + i\sin\vartheta)^{-k}\\
            &= \left[(\cos\vartheta + i\sin\vartheta)^k\right]^{-1}\\
            &= (\cos(k\vartheta) + i\sin(k\vartheta))^{-1}\\
            &= \frac{\cos(k\vartheta) - i\sin(k\vartheta)}{\cos^2(k\vartheta) + \sin^2(k\vartheta)}\\
            &= \cos(k\vartheta) - i\sin(k\vartheta)\\
            &= \cos(-k\vartheta) + i\sin(-k\vartheta)
        \end{align*}
        using the trig identity
        \[\cos^2(A) + \sin^2(A) = 1\]
        and the fact that \(\cos\) and \(\sin\) are even and odd functions respectively so
        \[\cos(-A) = \cos(A), \qquad\text{and}\qquad \sin(-A) = -\sin(A).\]
        Hence the formula holds for all \(n\in\integers\).
    \end{proof}

    \subsection{Complex Conjugate}
    \begin{definition}{Complex conjugate}{}
        The complex conjugate of \(z = x + iy = Re^{i\vartheta}\in\complex\) is
        \[z^* = \bar{z} = x - iy = Re^{-i\vartheta}.\]
    \end{definition}
    \begin{lemma}{Conjugate properties}{}
        The following hold for all \(z, z_1, z_2\in\complex\):
        \begin{enumerate}
            \item \((z_1 + z_2)^* = z_1^* + z_2^*\)
            \item \((z_1z_2)^* = z_1^*z_2^*\)
            \item \((z^*)^* = z\)
            \item \(\Re z = \frac{1}{2}(z + z^*)\)
            \item \(\Im z = \frac{1}{2i}(z - z^*)\)
            \item \(\abs{z} = \abs{z^*}\)
            \item \(\arg z = -\arg (z^*)\)
            \item \(\abs{z}^2 = zz^* = x^2 + y^2\)
        \end{enumerate}
    \end{lemma}
    \begin{proof}
        We will prove these in the order provided:
        \begin{enumerate}
            \item Let \(z_1 = x_1 + iy_1\) and \(z_2 = x_2 + iy_2\).
            Then
            \begin{multline*}
                (z_1 + z_2)^* = (x_1 + iy_1 + x_2 + iy_2)^* = ((x_1 + x_2) + i(y_1 + y_2))^* \\= (x_1 + x_2) - i(y_1 + y_2) = x_1 - iy_1 + x_2 - iy_2 = z_1^* + z_2^*.
            \end{multline*}
            
            \item Let \(z_1 = R_1e^{i\vartheta_1}\) and \(z_2 = R_2e^{i\vartheta_2}\).
            Then
            \[(z_1z_2)^* = (R_1e^{i\vartheta_1}R_2e^{i\vartheta_2})^* = (R_1R_2e^{i(\vartheta_1 + \vartheta_2)}) = R_1R_2e^{-i(\vartheta_1 + \vartheta_2)} = R_1e^{-i\vartheta_1}R_2e^{-i\vartheta_2} = z_1^*z_2^*.\]
            
            \item Let \(z = x + iy\).
            Then
            \[(z^*)^* = [(x + iy)^*]^* = [x - iy]^* = x + iy = z.\]
            
            \item Let \(z = x + iy\).
            Then
            \[\frac{1}{2}(z + z^*) = \frac{1}{2}[x + iy + (x + iy)^*] = \frac{1}{2}(x + iy + x - iy) = \frac{1}{2}2x = x = \Re z.\]
            
            \item Let \(z = x + iy\).
            Then
            \[\frac{1}{2i}(z - z^*) = \frac{1}{2i}[x + iy - (x + iy)^*] = \frac{1}{2i}(x + iy - (x - iy)) = \frac{1}{2i}(x + iy - x + iy) = \frac{1}{2i}2iy = y = \Im z.\]
            
            \item Let \(z = Re^{i\vartheta}\).
            Then
            \[\abs{z^*} = \abs{(Re^{-\vartheta})^*} = \abs{Re^{-i\vartheta}} = R = \abs{z}.\]
            
            \item Let \(z = Re^{i\vartheta}\).
            Then
            \[-\arg (z^*) = -\arg([Re^{i\vartheta}]^*) = -\arg(Re^{-i\vartheta}) = -(-\vartheta) = \vartheta = \arg z.\]
            
            \item Let \(z = Re^{i\vartheta} = x + iy\).
            Then
            \[zz^* = Re^{i\vartheta}(Re^{i\vartheta})^* = Re^{i\vartheta}Re^{-i\vartheta} = R^2e^{i(\vartheta - \vartheta)} = R^2e^0 = R^2 = \abs{z}^2.\]
            Also
            \[zz^* = (x + iy)(x + iy)^* = (x + iy)(x - iy) = x^2 - ixy + ixy - i^2y = x^2 + y^2.\]
        \end{enumerate}
    \end{proof}
    Using the complex conjugate we can see how the multiplicative inverse was found:
    \[\frac{1}{z} = \frac{z^*}{zz^*} = \frac{x - iy}{x^2 + y^2}.\]
    
    \subsection{Inequalities}
    When we move from \(\reals\) to \(\complex\) we lose the natural ordering that we have for real numbers.
    By this we mean that phrases like \(z < w\) are not defined for \(z, w\in\complex\).
    To compare two complex numbers we instead compare their moduli and arguments.
    
    \begin{lemma}{Modulus inequalities}{modulus inequalities}
        The following inequalities hold for all \(z, w\in\complex\):
        \begin{enumerate}
            \item \(\Re z \le \abs{z}\) and \(\Im z \le \abs{z}\).
            \item \(\abs{z + w} \le \abs{z} + \abs{w}\), this is known as the triangle inequality.
            \item \(\abs{z - w} \ge \abs{z} - \abs{w}\).
        \end{enumerate}
    \end{lemma}
    \begin{proof}
        First consider
        \[\abs{zw} = \sqrt{\abs{zw}^2} = \sqrt{(zw)(zw)^*} = \sqrt{zwz^*w^*} = \sqrt{zz^*ww^*} = \sqrt{\abs{z}^2\abs{w}^2} = \abs{z}\abs{w}.\]
        Let \(z = x + iy\), then
        \[x^2 + y^2 = \abs{z}^2 \implies x^2 = \abs{z}^2 - y^2 \le \abs{z}^2 \implies x \le \abs{z}.\]
        Similarly
        \[x^2 + y^2 = \abs{z}^2 \implies y^2 = \abs{z}^2 - x^2 \le \abs{z}^2 \implies y \le \abs{z}.\]
        This proves the first statement.
        
        For the triangle inequality consider
        \begin{align*}
            \abs{z + w}^2 &= (z + w)(z + w)^*\\
            &= (z + w)(z^* + w^*)\\
            &= zz^* + zw^* + z^*w + ww^*\\
            &= \abs{z}^2 + \abs{w}^2 + zw^* + z^*w.
        \end{align*}
        Notice that
        \[\Re(zw^*) = \frac{1}{2}(zw^* + (zw^*)^*) = \frac{1}{2}(zw^* + z^*w) \implies zw^* + z^*w = 2\Re (zw^*).\]
        Hence
        \[\abs{z + w}^2 = \abs{z}^2 + \abs{w}^2 + 2\Re(zw^*).\]
        We then use the first point to conclude that \(2\Re(zw^*) \le 2\abs{zw^*} = 2\abs{z}\abs{w}\) and so
        \[\abs{z + w}^2 \le \abs{z}^2 + \abs{w}^2 + 2\abs{z}\abs{w} = (\abs{z} + \abs{w})^2 \implies \abs{z + w} \le \abs{z} + \abs{w}.\]
        
        Finally note that
        \[\abs{z} = \abs{z - w + w} \le \abs{z - w} + \abs{w}\]
        using the triangle inequality on the two complex number \(z - w\) and \(w\).
        Rearranging this we get
        \[\abs{z} - \abs{w} \le \abs{z - w}.\]
    \end{proof}
    The triangle inequality is called the triangle inequality for a geometrical reason.
    If we consider a triangle in the complex plane then we can think of each side as a complex number.
    The triangle inequality then states that the longest side is shorter than, or the same length as, the sum of the two shorter sides.
    Specifically equality holds when the two sides are co-linear which corresponds to both complex numbers having the same argument.
    
    The triangle inequality generalises to the addition of \(n\) complex numbers as
    \[\abs{\sum_{i=1}^{n} z_i} \le \sum_{i=1}^{n} \abs{z_i}.\]
    
    Note that these properties make \(d\colon\complex^2 \to [0, \infty)\) defined by \(d(z, w) = \abs{z - w}\) a metric which makes \((\complex, d)\) a metric space.
    
    \subsection{Topology}
    We will regularly deal with subsets of \(\complex\).
    It will be useful to give some of them special names based on various properties.
    We start with some discs which are some combination of circles in the complex plane and the points inside them.
    \begin{definition}{Open disc}{}
        The \define{open disc} centred on \(a\in\complex\) with radius \(r\in\reals\), \(r > 0\), is
        \[\discOpen{a}{r} = \{z\in\complex \st \abs{z - a} < r\}.\]
        That is all the points contained in the circle in the complex plane that is centred on \(a\) and has a radius of \(r\) but \emph{not} the circle itself.
        This is the generalisation of an open interval, \((a, b)\), from the real line.
    \end{definition}
    \begin{definition}{Closed disc}{}
        The \define{closed disc} centred on \(a\in\complex\) with radius \(r\in\reals\), \(r > 0\), is
        \[\discClosed{a}{r} = \{z\in\complex \st \abs{z - a} \le r\}.\]
        That is all the points contained in the circle in the complex plane that is centred on \(a\) and has a radius of \(r\) \emph{and} the circle itself.
        This is the generalisation of a closed interval, \([a, b]\), from the real line.
    \end{definition}
    \begin{definition}{Punctured disc}{}
        The \define{punctured disc} centred on \(a\in\complex\) with radius \(r\in\reals\), \(r > 0\), is
        \[\discPunctured{a}{r} = \{z\in\complex \st 0 < \abs{z - a} < r\} = \discOpen{a}{r}\setminus \{a\}.\]
        That is the open disc centred on \(a\) with radius \(r\) with the centre of the disc removed.
    \end{definition}
    See figure~\ref{fig:discs}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{discs}
        \begin{tikzpicture}
            \tikzstyle{open disc} = [opacity=0.3, fill=red, draw=none]
            \tikzstyle{closed disc} = [fill opacity=0.3, color=blue, fill=blue, very thick]
            \tikzstyle{punctured disc} = [opacity=0.3, fill=green, draw=none]
            
            \draw[open disc] (0, 0) circle[radius=1cm];
            \draw[closed disc] (3, 0) circle[radius=1cm];
            \draw[punctured disc] (6, 0) circle[radius=1cm];
            \draw[fill=white, color=white] (6, 0) circle[radius=0.05cm];
            
            \node at (0, -1.5) {Open Disc};
            \node at (3, -1.5) {Closed Disc};
            \node at (6, -1.5) {Punctured Disc};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{An open, closed, and punctured disc.}
        \label{fig:discs}
    \end{figure}
    
    We now define some properties that a set can have:
    \begin{definition}{Open set}{}
        A set, \(S\subseteq\complex\), is \define{open} if for all \(z\in S\) there exists \(r > 0\) such that \(\discOpen{z}{r} \subseteq S\).
    \end{definition}
    We call \(D(z; r)\) for an arbitrarily small (but non-zero) \(r\) the \define{neighbourhood} of \(z\).
    What the definition above says is that \(S\) is open if for all points we can find sufficiently small \(r\) such that the neighbourhood of any point, \(z\in S\), is entirely inside of \(S\).
    This is a useful property as it allows us wiggle room as whatever point we pick in the set we can always get closer to the edge.
    Some examples of open sets are the open disc, \(\discOpen{a}{r}\), the complex numbers, \(\complex\), and (vacuously) the empty set, \(\emptyset\).
    
    \begin{definition}{Closed set}{}
        A set, \(S\subseteq\complex\), is \define{closed} if its \define{complement}, \(\complex\setminus S = S^\complement\), is open.
    \end{definition}
    Intuitively a closed set has an edge that we can reach.
    Examples of closed sets includes the closed disc, \(\discClosed{a}{r}\), the empty set as \(\emptyset^\complement = \complex\setminus\emptyset = \complex\) is open, and the complex numbers as \(\complex^\complement = \complex\setminus\complex = \emptyset\) is open.
    Notice how \(\complex\) and \(\emptyset\) are both open and closed.
    In fact being open and closed are not mutually exclusive properties.
    Sometimes sets that are both open and closed are called \define{clopen} sets.
    
    \begin{definition}{Isolated point}{}
        \(z\in S\subseteq\complex\) is an \define{isolated point} if the neighbourhood of \(z\) contains no points in \(S\) apart from \(z\).
        That is there exists \(r > 0\) such that \(S\intersection \discPunctured{z}{r} = \emptyset\).
    \end{definition}
    Intuitively an isolated point is not `touching' any other points in \(S\).
    For example consider the set \(S = \discOpen{0}{1}\union\{2\}\) has one isolated point, \(2\), as \(S\intersection\discPunctured{2}{0.5} = \emptyset\), see figure~\ref{fig:isolated point}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{isolated-point}
        \begin{tikzpicture}
            \tikzstyle{set1} = [opacity=0.3, color=red]
            \tikzstyle{set2} = [opacity=0.3, color=blue]
            \draw[->] (-2, 0) -- (3.5, 0);
            \draw[->] (0, -2) -- (0, 2);
            \node[left] at (0, 2) {\(\Im z\)};
            \node[below] at (3.5, 0) {\(\Re z\)};
            \fill[set2] (2, 0) circle[radius=0.5cm];
            \fill[color=white] (2, 0) circle[radius=0.05cm];
            \draw (0, 0) -- (3.5, 0);
            \fill[set1] (0, 0) circle[radius=1cm];
            \fill[set1] (2, 0) circle[radius=0.05cm];
            
            \node (key) at (current bounding box.east) {};
            \fill[set1] (key) rectangle ($(key) + (0.3, 0.3)$);
            \node[right] at ($(key) + (0.3, 0.15)$) {\(\discOpen{0}{1} \union \{2\}\)};
            \fill[set2] ($(key) - (0, 0.5)$) rectangle ($(key) - (0, 0.5) + (0.3, 0.3)$);
            \node[right] at ($(key) + (0.3, -0.5)$) {\(\discPunctured{2}{0.5}\)};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The set \(S = \discOpen{0}{1}\union \{2\}\) has 2 as an isolated point.}
        \label{fig:isolated point}
    \end{figure}
    \begin{definition}{Limit point}{}
        \(z\in \complex\) is a \define{limit point} if for all \(r > 0\) the punctured disc, \(\discPunctured{a}{r}\) has points both in \(S\) and in \(\complex\setminus S\), i.e. \(\discPunctured{a}{r}\intersection S \ne \emptyset \ne \discPunctured{a}{r}\intersection S^{\complement}\).
    \end{definition}
    Intuitively we can think of the limit points of a set as being the `boundary' of the set as a small step in one direction takes us into the set and a small set in another direction takes us out of the set.
    Notice that the limit points of a set needn't be in the set.
    For example all \(z\) with \(\abs{z} = 1\) are limit points of \(\discOpen{0}{1}\) despite the fact that \(z\notin \discOpen{0}{1}\).
    The fact that the definition specifies a punctured disc ensures that isolated points are not limit points.
    See figure~\ref{fig:limit point}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{limit-point}
        \begin{tikzpicture}
            \tikzstyle{set} = [opacity=0.3, fill=red, draw=none]
            \tikzstyle{punctured disc} = [opacity=0.3, fill=blue, draw=none]
            
            \draw[set] (0, 0) rectangle (2, 2);
            \draw[fill=black] (2, 1) circle[radius=0.05cm];
            \draw[punctured disc] (2, 1) circle[radius=0.25cm];
            
            \node (key) at ($(current bounding box.south west) - (0, 0.2)$) {};
            \draw[set] (key) rectangle ($(key) + (0.3, -0.3)$);
            \node[right] at ($(key) + (0.3, -0.15)$) {\(S\)};
            \draw[punctured disc] ($(key) + (1, 0)$) rectangle ($(key) + (1, 0) + (0.3, -0.3)$);
            \node[right] at ($(key) + (1, 0) + (0.3, -0.15)$) {\(\discPunctured{a}{r}\)};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{A limit point, \(a\), of a set, \(S\). Notice that no matter how small we make \(r\) the punctured disc \(\discPunctured{a}{r}\) will always overlap both \(S\) and \(S^{\complement}\).}
        \label{fig:limit point}
    \end{figure}
    
    \begin{definition}{Connected set}{}
        A set \(S\) is \define{connected} if for all \(z, w\in S\) there exists a continuous path from \(z\) to \(w\).
    \end{definition}
    Intuitively a set is connected if we can join any two points without a break.
    See figure~\ref{fig:connected set}.
    For example all discs form connected sets, as does the union of overlapping discs, e.g. \(\discOpen{0}{1}\union\discOpen{1 + i}{2}\) is a connected set.
    On the other hand if the discs don't overlap then they aren't a connected set, for example \(\discOpen{0}{1}\union\discOpen{1 + i}{0.1}\) is not a connected set.
    
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{connected-set}
        \begin{tikzpicture}
            \tikzstyle{connected set} = [fill=red, draw=none, opacity=0.3]
            \tikzstyle{connected path} = [very thick, red]
            \tikzstyle{connected point} = [fill=red, color=red]
            \tikzstyle{disconnected set} = [fill=blue, draw=none, opacity=0.3]
            \tikzstyle{disconnected path} = [very thick, blue]
            \tikzstyle{disconnected point} = [fill=blue, color=blue]
            
            \draw[connected set] (0, 0) rectangle (2, 2);
            \draw[connected point] (0.3, 0.3) circle[radius=0.05cm];
            \draw[connected point] (1.7, 1.7) circle[radius=0.05cm];
            \draw[connected path] (0.3, 0.3) -- (1.7, 1.7);
            
            \begin{scope}[xshift=3cm]
                \draw[disconnected set] (0, 0) rectangle (0.8, 0.8);
                \draw[disconnected set] (1.2, 1.2) rectangle (2, 2);
                \draw[disconnected point] (0.3, 0.3) circle[radius=0.05cm];
                \draw[disconnected point] (1.7, 1.7) circle[radius=0.05cm];
                \draw[disconnected path] (0.3, 0.3) -- (0.8, 0.8);
                \draw[disconnected path] (1.2, 1.2) -- (1.7, 1.7);
            \end{scope}
            
            \node at (1, -0.5) {Conncected set};
            \node at (4, -0.5) {Disconnected set};
            
        \end{tikzpicture}
        \caption{A connected set and an disconnected set. Both show an example of two points in the set which can be joined continuously in the connected case and not in the disconnected case.}
        \label{fig:connected set}
    \end{figure}
    \begin{definition}{Region}{}
        A \define{region}, \(R\), is an open, connected set.
    \end{definition}

    \part{Complex Functions}
    \section{Complex Functions and Derivatives}
    \subsection{Complex Functions}
    \begin{definition}{Complex function}{}
        A \define{complex function}, defined on a domain \(S \subseteq\complex\), is a mapping, \(w\colon S\to\complex\), which assigns to each \(z\in S\) a value \(w(z)\in\complex\).
    \end{definition}
    Importantly a function, \(w\), assigns to each \(z\) in its domain precisely one value.
    Sometimes it is necessary to restrict the codomain of \(w\) for this to be the case.
    As we did with complex numbers we can split complex functions into real and imaginary parts.
    Let
    \[S' = \{(x, y)\in\reals^2\st x + iy \in S\} \subseteq\reals^2\]
    then we can define two functions, \(u, v\colon S'\to\reals\) such that
    \[w(z) = w(x + iy) = u(x, y) + iv(x, y) = \Re w(z) + i\Im w(z).\]
    Consider for example the function
    \begin{align*}
        w\colon\complex&\to\complex\\
        z&\mapsto z^2.
    \end{align*}
    We can expand this in terms of \(x\) and \(y\) as
    \[w(z) = z^2 = (x + iy)^2 = x^2 - y^2 + 2xyi.\]
    We see that if we define \(u(x, y) = x^2 - y^2\) and \(v(x, y) = 2xy\) then \(w\), \(u\), and \(v\) will have the desired relationship.
    
    Another example that we may consider is
    \begin{align*}
        w\colon\complex&\to\complex\\
        z&\mapsto e^z.
    \end{align*}
    Expanding this in terms of \(x\) and \(y\) we have
    \begin{align*}
        w(z) &= e^z\\
        &= e^{x + iy}\\
        &= e^xe^{iy}\\
        &= e^x(\cos y + i\sin y).
    \end{align*}
    If we define \(u(x, y) = e^x\cos y\) and \(v(x, y) = e^x\sin y\) then again we will have the desired relationship between \(w\), \(u\), and \(v\).
    Notice that \(u\) and \(v\) are periodic in \(y\) with period \(2\pi\), which means \(w\) is periodic in \(z\) with period \(2\pi i\).
    This corresponds to the argument moving once around the unit circle.
    This is fine for this definition but becomes an issue if we want to invert \(w\).
    \begin{notation*}{}
        In this course we will denote the natural log, that is the inverse of the exponential, by \(\log\).
    \end{notation*}
    We define
    \[\log z = \log \abs{z} + i\vartheta = \frac{1}{2}\log(x^2 + y^2) + i\arctan\left(\frac{y}{x}\right).\]
    Notice that since \(\arctan\colon\reals\to [-\pi/2, \pi/2]\) has a restricted codomain the value of \(\vartheta\) above is also restricted to be in \([-\pi/2, \pi/2]\) which guarantees that if \(w(z) = \log z\) then \(w\) is single valued for all values in its domain.
    
    \subsection{Limits and Continuity}
    \begin{definition}{Limit}{}
        Let \(w\colon S\subseteq\complex \to\complex\) be a complex function.
        Then for \(z_0\in S\) we define
        \[\lim_{z\to z_0}w(z) = w_0\]
        for \(z\in S\), to be the \define{limit} if for \(\varepsilon > 0\)
        \[0 < \abs{z - z_0} < \delta \implies \abs{w(z) - w_0} <\varepsilon.\]
    \end{definition}
    Intuitively what this definition means is that by making \(z\) and \(z_0\) sufficiently close we can make \(w(z)\) and \(w_0\) arbitrarily close.
    Note that we use a punctured disc around \(z_0\) because the value of \(w(z_0)\) is not important to the definition of the limit, i.e. it needn't be the case that \(w(z_0) = w_0\).
    
    \begin{definition}{Continuity}{}
        Let \(w\colon S\subseteq\complex\to\complex\) be a complex function.
        Then for \(z_0\in S\) we say that \(w\) is \define{continuous} at \(z_0\) if
        \begin{enumerate}
            \item \(w\) is defined at \(z_0\) (which we already know it is as \(z_0\in S\))
            \item The limit, 
            \[\lim_{z\to z_0}w(z)\]
            exists.
            \item The limit and the function evaluated at \(z_0\) match:
            \[\lim_{z\to z_0} w(z) = w(z_0).\]
        \end{enumerate}
        We say that \(w\) is continuous if it is continuous at all \(z_0\in S\).
    \end{definition}
    Viewing the limit as approaching a point and the evaluation, \(w(z_0)\) as the evaluation at that point intuitively a function is continuous at \(z_0\) if there isn't a sudden jump when we reach the point.
    
    \subsubsection{Infinity}
    We often see limits of the form
    \[\lim_{x\to\infty} f(x)\]
    in real analysis.
    The natural question is is there an equivalent in complex analysis.
    In real analysis there are two disjoint points, \(\pm\infty\), that get the title `infinity'.
    These are not points in \(\reals\) rather they are things that we consider values to tend to.
    These two points can be thought of as the `ends' of the real numbers in the sense that \(\reals = (-\infty, \infty)\).
    When we expand to the complex numbers we don't have a line with ends any more we have a plane.
    \begin{definition}{Extended complex plane}{}
        We define the \define{extended complex plane}, \(\complex^*\), to be the complex numbers and a symbol representing infinity, that is \(\complex^* = \complex\union\{\infty\}\).
    \end{definition}
    Infinity in complex analysis is best viewed using the Riemann sphere.
    \begin{definition}{Riemann sphere}{}
        Let \(S^2\) be the unit sphere,
        \[S^2 = \{(\xi, \eta, \zeta)\in\reals^3\st \xi^2 + \eta^2 + \zeta^2 = 1\}.\]
        The \define{Riemann sphere}, \(P\colon \complex^*\to S^2\), then defines a one to one mapping of the complex plane.
        This mapping is defined as follows.
        First embed \(\complex\) in the \((\xi, \eta)\)-plane by associating \(z = x + iy\) with \((x, y, 0)\).
        Next define \(P(\infty) = (0, 0, 1)\).
        Then define \(P(z) = (\xi, \eta, \zeta)\) as the point on the sphere other than \((0, 0, 1)\) which intersects the line from \((0, 0, 1)\) to \((x, y, 0)\).
        It can be shown then that
        \[(x, y) = \left(\frac{\xi}{1 - \zeta}, \frac{\eta}{1 - \zeta}\right)\]
        and
        \[(\xi, \eta, \zeta) = \left(\frac{2x}{\abs{z}^2 + 1}, \frac{2y}{\abs{z}^2 + 1}, \frac{\abs{z}^2 - 1}{\abs{z}^2 + 1}\right).\]
    \end{definition}
    Important points to consider are that \(P(z = 0) = (0, 0, -1)\) and \(\lim_{\abs{x}\to\infty} P(x + iy) = \lim_{\abs{y}\to\infty} P(x + iy) = (0, 0, 1)\).
    This justifies identifying \(P(\infty) = (0, 0, 1)\).
    Intuitively we can view the Riemann sphere as wrapping the complex plane around a unit sphere so that all of the points we would consider to be `at infinity' meet at the top of the sphere.
    
    \subsection{Derivatives}
    \begin{definition}{Derivative}{}
        Let \(w\colon S\subseteq\complex\to\complex\) be a complex function.
        Then for \(z_0\in\complex\) the \define{derivative} of the \(w\) at \(z_0\), denoted \(w'(z_0)\), is defined as
        \[w'(z_0) = \lim_{z\to z_0} \frac{w(z) - w(z_0)}{z - z_0} = \lim_{\Delta z \to 0} \frac{w(z_0 + \Delta z) - w(z_0)}{\Delta z},\]
        assuming that this limit exists and is independent of the direction of approach to \(z_0\).
        When this is the case we say that \(w\) is \define{differentiable} at \(z_0\).
    \end{definition}
    This doesn't, at first, appear to be that different to the derivative in real analysis.
    This means that derivatives of functions of \(z\) will appear similar to how they appear for the equivalent real function.
    \begin{example}
        \textit{Find the derivative of the complex function \(w\) defined by \(w(z) = z^2\).}
        \begin{align*}
            w'(z) &= \lim_{\Delta z \to 0} \frac{(z + \Delta z)^2 - z^2}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{z^2 + 2z\Delta z + (\Delta z)^2 - z^2}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{2z\Delta z + (\Delta z)^2}{\Delta z}\\
            &= \lim_{\Delta z\to 0} (2z + \Delta z)\\
            &= 2z.
        \end{align*}
        Which is exactly what we would expect if \(w(z) = z^2\) was a real function.
    \end{example}
    However the extra `room' that we have in the complex numbers which allows us to approach a point not just from above and below but anywhere else in the plane means that many seemingly simple functions don't have derivatives.
    \begin{example}
        \textit{Show that the complex function \(w\), defined by \(w(z) = z^*\), is nowhere differentiable.}
        
        First we consider the derivative at some \(z\in\complex\) approached along a line parallel to the real axis:
        \[L_1 = \lim_{\Delta x \to 0} \frac{(z + \Delta x)^* - z^*}{\Delta x} = \lim_{\Delta x \to 0} \frac{z^* + \Delta x - z^*}{\Delta z} = \lim_{\Delta x \to 0}\frac{\Delta x}{\Delta x} = 1.\]
        Now consider the derivative at the same point but approached along a line perpendicular to the real axis:
        \[L_2 = \lim_{\Delta y\to 0} \frac{(z + i\Delta y)^* - z}{i\Delta y} = \lim_{\Delta y \to 0} \frac{z^* - i\Delta y - z^*}{i\Delta y} = \lim_{\Delta y \to 0} \frac{-i\Delta y}{i\Delta y} = -1.\]
        More generally we can approach along a line at an angle \(\vartheta\) to the real axis:
        \[L_\vartheta = \lim_{\Delta R\to 0} \frac{(z + \Delta R e^{i\vartheta})^* - z^*}{\Delta Re^{i\vartheta}} = \lim_{\Delta R\to 0} \frac{z^* + \Delta Re^{-i\vartheta} - z^*}{\Delta Re^{i\vartheta}} = \lim_{\Delta R\to 0} \frac{\Delta Re^{-i\vartheta}}{\Delta Re^{i\vartheta}} = e^{-2i\vartheta}.\]
        Since this is not independent of \(\vartheta\) the direction of approach matters so \(w\) is not differentiable at any point in \(\complex\).
    \end{example}
    
    \subsection{Cauchy--Riemann Relations}
    It was quite a pain showing that a function as simple as \(w(z) = z^*\) is nowhere differentiable.
    Fortunately there are other tests that we can use which are faster and easier than looking at the limit definition.
    \begin{notation*}{}
        Suppose \(u\) is a function of the real variables \(x\) and \(y\).
        Then we will use the notation
        \[\pdv{u}{x} = u_x, \qquad\text{and}\qquad \pdv{u}{y} = u_y.\]
    \end{notation*}
    \begin{theorem}{Cauchy--Riemann relations}{}
        If \(w = u + iv\colon S\subseteq \complex\to\complex\) is differentiable at a point \(z = x + iy\in S\) then the \define{Cauchy--Riemann relations},
        \[u_x(x, y) = v_y(x, y), \qquad\text{and}\qquad u_y(x, y) = -v_x(x, y)\]
        hold.
    \end{theorem}
    \begin{proof}
        Let \(w\colon S\subseteq\to\complex\) be a complex function which is differentiable at \(z = x + iy\in S\).
        We can write \(w(z) = u(x, y) + iv(x, y)\).
        Since \(w\) is differentiable the following limit exists and is independent of the direction of approach:
        \begin{align*}
            w'(z) &= \lim_{\Delta z \to 0} \frac{w(z + \Delta z) - w(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{u(x + \Delta x, y + \Delta y) + iv(x + \Delta x, y + \Delta y) - u(x, y) - v(x, y)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{u(x + \Delta x, y + \Delta y) - u(x, y) + i[v(x + \Delta x, y + \Delta y) - v(x, y)]}{\Delta z}. \stepcounter{equation}\tag{\theequation}\label{eqn:derivative as lim of u and v}
        \end{align*}
        We can approach this limit from any direction.
        If we approach it along a line parallel to the real axis, in particular choosing \(\Delta z = \Delta x\), then we get
        \begin{align*}
            w'(z) &= \lim_{\Delta x\to 0} \frac{u(x + \Delta x, y) - u(x, y) + i[v(x + \Delta x, y) - v(x, y)]}{\Delta x} \\
            &= \lim_{\Delta x \to 0} \left[ \frac{u(x + \Delta x, y) - u(x, y)}{\Delta x} + i \frac{v(x + \Delta x, y) - v(x, y)}{\Delta x} \right]\\
            &= \pdv{u}{x} + i\pdv{v}{x}\\
            &= u_x(x, y) + iv_x(x, y).
        \end{align*}
        If instead we approach along a line perpendicular to the real axis, in particular choosing \(\Delta z = i\Delta y\), then we get
        \begin{align*}
            w'(z) &= \lim_{\Delta y \to 0} \frac{u(x, y + \Delta y) - u(x, y) + i[v(x, y + \Delta y) - v(x, y)]}{i\Delta y}\\
            &= \lim_{\Delta y\to 0} \left[ \frac{1}{i}\frac{u(x, y + \Delta y) - u(x, y)}{\Delta y} + \frac{v(x, y + \Delta y) - v(x, y)}{\Delta y} \right]\\
            &= \frac{1}{i}\pdv{u}{y} + \pdv{v}{y}\\
            &= -iu_y(x, y) + v_y(x, y).
        \end{align*}
        Since \(w\) is differentiable the result of these two approaches must be equal.
        Equating real and imaginary parts we have
        \[u_x = v_y, \qquad\text{and}\qquad u_y = -v_x.\]
        These are known as the \define{Cauchy--Riemann relations}.
    \end{proof}
    We can use these to calculate the derivative of \(w\) as
    \[w' = u_x + iv_x = v_y - iu_y.\]
    We may be attempted to view \(w\) as a function \(w\colon\reals^2 \to\reals^2\) and then apply the chain rule
    \[\dv{w}{z} = \pdv{w}{x}\pdv{x}{z} + \pdv{w}{y}\pdv{y}{z}\]
    but this is \emph{wrong}.
    We can apply the chain rule separately to \(u\) and \(v\) as these are functions of real values or we can apply the chain rule to functions of the form \(w(f(z))\) but to the variable \(z\), not to \(x\) and \(y\).
    
    Note that satisfying the Cauchy--Riemann relations is a necessary condition for differentiability, not a sufficient one.
    There are functions that satisfy the Cauchy--Riemann relations but \emph{aren't} differentiable.
    However we can add a condition to get sufficient conditions.
    \begin{theorem}{Sufficient conditions for differentiability}{}
        Let \(w\colon S\to\complex\) be a complex function.
        Then \(w\) is differentiable at \(z_0 = x_0 + iy_0\) if \(w\) satisfies the Cauchy--Riemann relations and \(u\) and \(v\) are differentiable at \((x_0, y_0)\).
    \end{theorem}
    \begin{proof}
        If \(u\) and \(v\) are differentiable at \((x_0, y_0)\) then we can write
        \begin{align*}
            u(x, y) &= u(x_0, y_0) + u_x(x_0, y_0)\Delta x + u_y(x_0, y_0)\Delta y + \varepsilon_1\sqrt{(\Delta x)^2 + \Delta y^2}\\
            v(x, y) &= v(x_0, y_0) + v_x(x_0, y_0)\Delta x + v_y(x_0, y_0)\Delta y + \varepsilon_2\sqrt{(\Delta x)^2 + \Delta y^2}
        \end{align*}
        where \(\varepsilon_1\) and \(\varepsilon_2\) tend to 0 as we move toward \((x_0, y_0)\).
        We can substitute these into equation~\ref{eqn:derivative as lim of u and v} and we find that
        \begin{align*}
            w'(x_0 + iy_0) &= \lim_{\Delta z\to 0} \left[ \frac{u_x(x_0, y_0)\Delta x + u_y(x_0, y_0)\Delta y + i[v_x(x_0, y_0)\Delta x + v_y(x_0, y_0)\Delta y]}{\Delta x + i\Delta y} \right.\\
            &\left. \qquad + (\varepsilon_1 + i\varepsilon_2)\frac{\sqrt{(\Delta x)^2 + (\Delta y)^2}}{\Delta z}\right]
        \end{align*}
        where \(\Delta z = \Delta x + i\Delta y\).
        Assuming that \(u\) and \(v\) satisfy the Cauchy--Riemann relations this becomes
        \begin{align*}
            w'(x_0 + iy_0) &= \lim_{\Delta z\to 0} \left[ \frac{u_x(x_0, y_0)\Delta x - v_x(x_0, y_0)\Delta y + i[u_x(x_0, y_0)\Delta x + u_x(x_0, y_0)\Delta y]}{\Delta x + i\Delta y} \right.\\
            &\left. \qquad + (\varepsilon_1 + i\varepsilon_2)\frac{\sqrt{(\Delta x)^2 + (\Delta y)^2}}{\Delta z}\right]\\
            &= \lim_{\Delta z\to 0} \left[ \frac{u_x(x_0, y_0)(\Delta x + i\Delta y) + iv_x(x_0, y_0)(\Delta x + i\Delta y)}{\Delta x + i\Delta y} \right.\\
            &\left. \qquad + (\varepsilon_1 + i\varepsilon_2)\frac{\sqrt{(\Delta x)^2 + (\Delta y)^2}}{\Delta z}\right]\\
            &= u_x(x_0, y_0) + iv_x(x_0, y_0) + \lim_{\Delta z \to 0}(\varepsilon_1 + \varepsilon_2)\frac{\abs{\Delta z}}{\Delta z}.
        \end{align*}
        Notice now that \(\abs{\abs{\Delta z}/\Delta z} = 1\) and therefore \(\abs{\Delta z}/\Delta z\) is bounded so the limit term vanishes as \(\Delta z \to 0\) since \(\varepsilon_1, \varepsilon_2\to 0\).
        Thus
        \[w'(x_0 + iy_0) = u_x(x_0, y_0) + iv_x(x_0, y_0)\]
        so \(w\) is differentiable at \(x_0 + iy_0\).
    \end{proof}
    \subsection{Properties of the Derivative}
    \begin{lemma}{Linearity of the derivative}{}
        The derivative is linear.
        By this we mean that if \(w\) and \(f\) are complex functions which are continuous and differentiable at \(z\) and \(\alpha\in\complex\) then
        \[(\alpha w)'(z) = \alpha w(z),\qquad\text{and}\qquad (w + f)'(z) = w'(z) + f'(z).\]
    \end{lemma}
    \begin{proof}
        Let \(w\), \(f\), and \(\alpha\) be as in the hypothesis.
        Then
        \begin{align*}
            (\alpha w)'(z) &= \lim_{\Delta z\to 0} \frac{(\alpha w)(z + \Delta z) - (\alpha w)(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{\alpha w(z + \Delta z) - \alpha w(z)}{\Delta z}\\
            &= \alpha\lim_{\Delta z \to 0} \frac{w(z + \Delta z) - w(z)}{\Delta z}\\
            &= \alpha w'(z).
        \end{align*}
        Also
        \begin{align*}
            (w + f)'(w) &= \lim_{\Delta z \to 0} \frac{(w + f)(z + \Delta z) - (w + f)(z)}{\Delta z}\\
            &= \lim_{\Delta z \to 0} \frac{w(z + \Delta z) + f(z + \Delta z) - w(z) - f(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{w(z + \Delta z) - w(z)}{\Delta z} + \lim_{\Delta z \to -} \frac{f(z + \Delta z) - f(z)}{\Delta z}\\
            &= w'(z) + f'(z).
        \end{align*}
    \end{proof}
    \begin{lemma}{Product rule}{}
        Let \(w\) and \(f\) be complex functions which are continuous and differentiable at \(z\).
        Then
        \[(wf)'(z) = w'(z)f(z) + w(z)f'(z).\]
    \end{lemma}
    \begin{proof}
        Let \(w\) and \(f\) be as in the hypothesis.
        Then
        \begin{align*}
            (wf)' &= \lim_{\Delta z\to 0} \frac{(wf)(z + \Delta z) - (wf)(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{w(z + \Delta z)f(z + \Delta z) - w(z)f(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{w(z + \Delta z)f(z + \Delta z) - w(z + \Delta z)f(z) + w(z + \Delta z)f(z) - w(z)f(z)}{\Delta z}\\
            &= \lim_{\Delta z\to 0} w(z + \Delta z)\frac{f(z + \Delta z) - f(z)}{\Delta z} + \lim_{\Delta z \to 0} f(z)\frac{w(z + \Delta z) - w(z)}{\Delta z}\\
            &= w(z)f'(z) + f(z)w'(z)
        \end{align*}
    \end{proof}
    \begin{lemma}{Chain rule}{}
        Let \(w\) and \(f\) be complex functions such that \(f\) is continuous and differentiable at \(z\) and \(w\) is continuous and differentiable at \(f(z)\).
        Then
        \[(w\circ f)'(z) = w'[f(z)]f'(z).\]
    \end{lemma}
    \begin{proof}
        Let \(w\) and \(f\) be as in the hypothesis.
        Then
        \begin{align*}
            (w \circ f)'(z) &= \lim_{\Delta z \to 0} \frac{(w \circ f)(z + \Delta z) + (w \circ f)(z)}{\Delta z}\\
            &= \lim_{\Delta z \to 0} \frac{w[f(z + \Delta z)] - w[f(z)]}{\Delta z}\\
            &= \lim_{\Delta z\to 0} \frac{w[f(z + \Delta z)] - w[f(z)]}{f(z + \Delta z) - f(z)}\frac{f(z + \Delta z) - f(z)}{\Delta z}\\
            &= w'[f(z)]f'(z).
        \end{align*}
        This assumes that \(f(z + \Delta z) \ne f(z)\).
        If this isn't the case then clearly \(f'(z) = 0\) and also \(w[f(z + \Delta z)] - w[f(z)] = w[f(z)] - w[f(z)] = 0\) so \((w\circ f)'(z) = 0\) so the chain rule still holds.
    \end{proof}
    
    \section{Analytic Functions}
    \subsection{Examples}
    \begin{example}
        \textit{Where is \(w(z) = z^2\) differentiable?}
        \[w(z) = w(x + iy) = x^2 - y^2 + 2ixy \implies u(x, y) = x^2 - y^2, \qquad\text{and}\qquad v(x, y) = 2xy.\]
        The first derivatives of \(u\) and \(v\) are then
        \begin{align*}
            u_x &= 2x, & v_y &= 2x,\\
            u_y &= -2y, & v_x &= 2y.
        \end{align*}
        Recall that the Cauchy--Riemann relations are \(u_x = v_y\) and \(u_y = -v_x\) we see that \(w\) satisfies these at all \(z \in\complex\).
        Further each \(u\) and \(v\) are differentiable on \(\reals^2\) so \(w\) is differentiable on \(\complex\).
    \end{example}
    \begin{example}
        \textit{Where is \(w(z) = \abs{z}^2\) differentiable?}
        \[w(z) = w(x + iy) = x^2 + y^2 \implies u(x, y) = x^2 + y^2, \qquad\text{and}\qquad v(x, y) = 0.\]
        The first derivatives of \(u\) and \(v\) are then
        \begin{align*}
            u_x &= 2x, & v_y &= 0,\\
            u_y &= 2y, & v_x &= 0.
        \end{align*}
        The Cauchy--Riemann relations are thus only satisfied at \(z = 0\).
        Both \(u\) and \(v\) are differentiable at \((0, 0)\) so \(w\) is differentiable at \(z = 0\) only.
    \end{example}
    \begin{example}
        \textit{Where is \(w(z) = e^z\) differentiable?}
        \[w(z) = w(x + iy) = e^x(\cos y + i\sin y) \implies u(x, y) = e^x\cos y, \qquad\text{and}\qquad v(x, y) = e^x\sin y.\]
        The first derivatives of \(u\) and \(v\) are then
        \begin{align*}
            u_x &= e^x\cos y, & v_y &= e^x\cos y,\\
            u_y &= -e^x\sin y, & v_x &= e^x\sin y.
        \end{align*}
        The Cauchy--Riemann relations are satisfied at all \(z\in\complex\) and \(u\) and \(v\) are differentiable on \(\reals^2\) so \(w\) is differentiable on \(\complex\).
    \end{example}
%    \begin{example}
%        \textit{For what values of \(\alpha\in\reals\) is \(w(z) = (x + \alpha y)^2 + 2i(x - \alpha y)\) differentiable at some point and what are those points?}
%        \[u(x, y) = (x + \alpha y)^2, \qquad\text{and}\qquad v(x, y) = 2(x - \alpha y).\]
%        The first derivatives of \(u\) and \(v\) are then
%        \begin{align*}
%            u_x &= 2(x + \alpha y), & v_y &= -2\alpha,\\
%            u_y &= 2\alpha(x + \alpha y), & v_x &= 2.
%        \end{align*}
%        Imposing that these satisfy the Cauchy--Riemann relations we get
%        \begin{align*}
%            2x + \alpha y &= -2\alpha\\
%            2\alpha x + \alpha^2 y &= -2
%        \end{align*}
%        This is a series of simultaneous equations which can be represented by
%        \[
%            \begin{pmatrix}
%                2 & \alpha\\
%                2\alpha & \alpha^2
%            \end{pmatrix}
%            \begin{pmatrix}
%                x\\ y
%            \end{pmatrix}
%            =
%            \begin{pmatrix}
%                -2\alpha\\ -2
%            \end{pmatrix}
%        \]
%        These have a solution if and only if the matrix above is invertible which means that we require it to be non-singular:
%        \[
%            \begin{vmatrix}
%                2 & \alpha\\
%                2\alpha & \alpha^2
%            \end{vmatrix}
%            = 2\alpha^2 - 2\alpha^2 = 0
%        \]
%    \end{example}
    \subsection{Analytic Functions}
    We have seen that it is easy to accidentally define innocent looking functions, such as \(w(z) = z^*\), which are continuous everywhere but differentiable almost nowhere.
    The nest definition defines a type of function which will behave very similarly to real functions when it comes to differentiability.
    \begin{definition}{Analytic function}{}
        A function, \(w\colon S\subseteq\complex\to\complex\), is said to be \define{analytic} or \define{holomorphic} at \(z_0\in S\) if \(w\) is differentiable at \(z_0\) and at every point in the neighbourhood of \(z_0\).
        We say that \(w\) is analytic on an open subset \(S'\subseteq S\) if \(w\) is differentiable at all \(z_0\in S'\).
    \end{definition}
    Notice that the neighbourhood of \(z_0\) is a region of \(\complex\), that is an infinite, connected, open set.
    The \emph{open} part of this requirement is important.
    If the set isn't open then we can take \(z_0\) to be a limit point and then it is possible that \(w(z_0 + \Delta z)\) won't be defined even as \(\Delta z \to 0\).
    \begin{definition}{Entire function}{}
        A function, \(w\colon \complex \to\complex\) is \define{entire} or \define{regular} if it is analytic on \(\complex\), that is it is analytic at all \(z_0 \in\complex\).
    \end{definition}
    For example if \(w(z) = z^2\) we have already seen that this is differentiable for all \(z\in\complex\).
    Therefore \(w\) is entire.
    Similarly if \(w(z) = e^z\) then \(w\) is entire.
    It can also be shown that \(w(z) = e^{\alpha z}\) for \(\alpha\in\complex\) is entire.
    \begin{lemma}{\(\bm{z^n}\) is entire}{z^n entire}
        The function
        \begin{align*}
            w\colon\complex&\to\complex\\
            z&\mapsto z^n
        \end{align*}
        for \(n\in\naturals\) is entire.
    \end{lemma}
    \begin{proof}
        First consider the case \(n = 1\).
        That is
        \[w(z) = w(x + iy) = z = x + iy \implies u(x, y) = x, \qquad \text{and} \qquad v(x, y) = y.\]
        The derivatives of \(u\) and \(v\) are
        \begin{align*}
            u_x &= 1, & v_y &= 1\\
            u_y &= 0, & v_y &= 0.
        \end{align*}
        Clearly \(u\) and \(v\) are differentiable and satisfy the Cauchy--Riemann relations for all \((x, y)\in\reals^2\).
        Therefore \(w\) is differentiable for all \(z\in\complex\) so \(w\) is entire.
        
        Now assume that the hypothesis is true for some specific \(n = k\).
        That is that \(w(z) = z^k\) is entire.
        Therefore \(w'\) exists everywhere.
        Using this we consider \(f(z) = z^{k + 1} = zz^k = zw(z)\).
        Note that
        \[f(z) = zw(z) = (x + iy)(u + iv) = xu - yv + i(xv + yu).\]
        Hence
        \[f(z) = f(x + iy) = g(x, y) + ih(x, y) = xu(x, y) - yv(x, y) i(xv(x, y) + yu(x, y)).\]
        Where
        \[g(x, y) = xu(x, y) - yv(x, y), \qquad\text{and}\qquad h(x, y) = xv(x, y) + yu(x, y).\]
        Thus we can see if the Cauchy--Riemann relations hold for \(g\) and \(h\):
        \begin{align*}
            g_x &= u + xu_x - yv_x, & h_y &= xv_y + u + yu_y,\\
            g_y &= xu_y - v - yv_y, & h_x &= v + xv_x + yu_x.
        \end{align*}
        The derivatives of \(u\) and \(v\) are guaranteed to exist as \(w\) is differentiable.
        Using the Cauchy--Riemann relations for \(u\) and \(v\) we have
        \begin{align*}
            g_x &= u + xu_x + yu_y, & h_y &= xu_x + u + yu_y,\\
            g_y &= xu_y - v - yu_x, & h_x &= v - xu_y + yu_x
        \end{align*}
        So we see that the Cauchy--Riemann relations are satisfied everywhere and that \(g\) and \(h\) are differentiable everywhere.
        Thus \(f\) is differentiable everywhere so is entire.
        
        Hence by mathematical induction \(w(z) = z^n\) is entire for all \(n\in\naturals\).
    \end{proof}
    \begin{lemma}{Sum of entire functions is entire}{sum of entire functions}
        The sum of two entire functions is entire.
    \end{lemma}
    \begin{proof}
        Let \(w, f\colon \complex\to\complex\) be entire functions and \(u, v, g, h\colon\reals^2\to\reals\) be such that \(w = u + iv\) and \(f = g + ih\).
        Then
        \[w + f = (u + g) + i(v + h).\]
        Checking the Cauchy--Riemann relations for these we see that
        \begin{align*}
            (u + g)_x &= u_x + g_x, & (v + h)_y &= v_y + h_y,\\
            (u + g)_y &= u_y + g_y, & (v + h)_x &= v_x + h_x.
            \shortintertext{Now using the Cauchy--Riemann relations for \(u\), \(v\), \(g\), and \(h\) we have}
            (u + g)_x &= u_x + g_x, & (v + h)_y &= u_x + g_x,\\
            (u + g)_y &= u_y + g_y, & (v + h)_x &= -u_y - g_y.
        \end{align*}
        So we see that \(u + g\) and \(v + h\) satisfy the Cauchy--Riemann relations and are differentiable everywhere meaning that \(f + w\) is differentiable everywhere and therefore \(f + w\) is entire.
    \end{proof}
    \begin{corollary}{Polynomials are entire}{}
        All polynomials, \(P_n\in\complex[z]\),
        \[P_n(z) = \sum_{k=0}^{n} a_kz^k\]
        for \(a_k\in\complex\) are entire.
    \end{corollary}
    \begin{proof}
        First if \(w\) is an entire function then by the linearity of the derivative \(aw\) for \(a\in\complex\) is also an entire function.
        By lemma~\ref{lem:z^n entire} \(z^k\) is entire and therefore \(a_kz^k\) is also entire.
        Considering the sum
        \[P_n(z) = \sum_{k=0}^{n} a_kz^k = (a_0 + (a_1z + (a_2z^2 + (\dotsb (a_{n-2}z^{n-2} +(a_{n-1}z^{n-1} + a_nz^n))))))\]
        we see that we can take any finite sum and reduce it to repeatedly summing pairs of functions.
        Each function is entire and each of these sums of pairs of functions returns an entire function by lemma~\ref{lem:sum of entire functions}.
        Hence \(P_n(z)\) is entire.
    \end{proof}
    
    \begin{definition}{Complex trigonometric functions}{}
        We can define \(\sin, \cos\colon\complex\to\complex\) as
        \[\cos z = \frac{1}{2}(e^{iz} + e^{-iz}), \qquad\text{and}\qquad \sin z = \frac{1}{2i}(e^{iz} - e^{iz}).\]
    \end{definition}
    Importantly this means that these complex trig functions evaluate to the same value as their real counterparts with a real input.
    Notice the resemblance to the hyperbolic trig functions:
    \[\cosh z = \frac{1}{2}(e^{z} + e^{-z}), \qquad\text{and}\qquad \sinh z = \frac{1}{2}(e^z - e^{-z}).\]
    \begin{corollary}{Trigonometric functions are entire}{}
        Trig functions and hyperbolic trig functions are entire.
    \end{corollary}
    \begin{proof}
        The trig functions and hyperbolic trig functions defined on \(\complex\) are defined as a sum of two exponentials of the form \(e^{\alpha z}\) with \(\alpha\in\complex\).
        These exponentials are entire and therefore the trig and hyperbolic trig functions are entire.
    \end{proof}
    \begin{example}
        \textit{Where is \(w(z) = \abs{z}^2\) analytic?}
        
        Recall that \(w(z) = \abs{z}^2\) is differentiable only at \(z = 0\).
        Therefore it is not analytic anywhere as it is differentiable at a point and not in its neighbourhood.
    \end{example}
    Similarly to above a function that is differentiable only along a line will not be analytic anywhere as the neighbourhood of any point on the line will contain points not on the line.
    This was the purpose of our definition, to exclude functions that are differentiable at a point or a few points but not in a region.
    This turns out to be a very strict requirement which allows us to prove some very strong results.
    As part of this we will consider functions analytic on a region apart from a few points inside.
    These points tend to require special consideration so we give them a name:
    \begin{definition}{Isolated singular point}{}
        Let \(w\colon S\subseteq\complex\to\complex\).
        We say that \(z_0\) is an \define{isolated singular point} of \(w\) if there exists an open domain \(S\ni z_0\) such that \(w\) is analytic for all \(z\in S\), \(z \ne z_0\).
    \end{definition}
     \begin{definition}{Stationary point}{}
        If \(w\colon S\subseteq \complex \to \complex\) is analytic in an open domain, \(D\subseteq S\), and \(z_0\in D\) then we say that \(z_0\) is a \define{stationary point} if \(w'(z_0) = 0\).
    \end{definition}
    \begin{theorem}{Properties of an analytic function}{}
        Let \(w\colon S\subseteq\complex\to\complex\) be analytic in \(S'\subseteq S\) and let \(w(x + iy) = u(x, y) + iv(x, y)\).
        Then \(u\) and \(v\) have the following properties in \(S'\):
        \begin{enumerate}[label=(\roman*)]
            \item Both \(u\) and \(v\) are harmonic, that is they satisfy Laplace's equation, \(\laplacian u = \laplacian v = 0\) where \(\laplacian = \partial_x^2 + \partial_y^2\) is the two dimensional Laplacian.
            \item The level curves of \(u\) and \(v\) are orthogonal.
            \item A stationary point is always a saddle point.
        \end{enumerate}
    \end{theorem}
    \begin{proof}
        We will prove these in the order stated.
        \begin{enumerate}[label=(\roman*)]
            \item Since \(w\) is analytic in the region of interest we know that they are continuous and differentiable.
            This means that we can change the order of partial derivatives.
            Thus
            \[u_{xx} = \pdv{u_x}{x} = \pdv{v_y}{y} = \pdvsec{v}{x}{y} = \pdvsec{v}{y}{x} = \pdv{v_x}{y} = -\pdv{u_y}{y} = -u_{yy}.\]
            Hence
            \[\laplacian u = u_xx + u_yy = u_xx - u_xx = 0.\]
            Similarly
            \[v_{xx} = \pdv{v_x}{x} = -\pdv{u_y}{x} = -\pdvsec{u}{x}{y} = -\pdvsec{u}{y}{x} = -\pdv{u_x}{y} = -\pdv{v_y}{y} = -v_yy\]
            so
            \[\laplacian v = v_{xx} + v_{yy} = v_{xx} - v_{xx} = 0.\]
            
            \item The level curves of a function \(f\colon\reals^2 \to \reals\) are perpendicular to \(\grad f = f_x\ve{x} + f_y\ve{y}\).
            Therefore if the curves of constant \(u\) and \(v\) are orthogonal we expect their gradients to be as well.
            This is easy to show:
            \[(\grad u) \cdot (\grad v) = (u_x\ve{x} + u_y\ve{y}) \cdot (v_x\ve{x} + v_y\ve{y}) = u_xv_x + u_yv_y = u_xv_x - u_xv_x = 0.\]
            So \(\grad u\) and \(\grad v\) are perpendicular so the level curves of \(u\) and \(v\) are perpendicular.
            
            \item A function \(f\colon\reals^2\to\reals\) is a local maximum (or minimum) at \((x, y)\) if \(f'(x, y) = 0\) and the Hessian matrix, \(H_{ij} = \partial_i\partial_j f\), is positive definite (or negative definite).
            If the Hessian is indefinite then \((x, y)\) is a saddle point.
            Recall that a matrix, \(M\), is positive (or negative) definite if all of its eigenvalues are positive (or negative) and indefinite if some of its eigenvalues are positive and some are negative.
            So the third part of this theorem equates to stating that the Hessian matrices for \(u\) and \(v\) are indefinite, i.e. of their two eigenvalues one is positive and one is negative.
            The Hessian matrices for \(u\) and \(v\) are
            \[
                H(u) =
                \begin{pmatrix}
                    u_{xx} & u_{xy}\\
                    u_{yx} & u_{yy}
                \end{pmatrix}
                , \qquad\text{and}\qquad H(v) =
                \begin{pmatrix}
                    v_{xx} & v_{xy}\\
                    v_{yx} & v_{yy}
                \end{pmatrix}
                .
            \]
            We know from the first part of this theorem that \(u_{xx} = -u_{yy}\) and \(v_{xx} = -v_{yy}\).
            Also applying the Cauchy--Riemann relations we have \(u_{xy} = v_{yy} = -v_{xx}\) and \(v_{xy} = -u_{yy} = u_{xx}\).
            \[
                H(u) =
                \begin{pmatrix}
                    u_{xx} & -v_{xx}\\
                    -v_{xx} & -u_{xx}
                \end{pmatrix}
                , \qquad\text{and}\qquad H(v) =
                \begin{pmatrix}
                    v_{xx} & u_{xx}\\
                    u_{xx} & -v_{xx}
                \end{pmatrix}
                .
            \]
            Now notice that \(\abs{H(u)} = \abs{H(v)} = -u_xx^2 - v_xx^2 \le 0\).
            If the determinants are zero then \(H\) are indefinite.
            If the determinants are non-zero then it is possible to diagonalise the matrix.
            Then the determinant will be the product of the leading diagonal, which is all of the eigenvalues.
            For the determinant to be negative since there are two eigenvalues we need one eigenvalue to be negative and the other to be positive.
            This makes \(H\) an indefinite matrix.
        \end{enumerate}
    \end{proof}
    
    \section{Consequences of Analyticity}
    \begin{theorem}{Constant analytic functions}{}
        Let \(w\colon S\subseteq\complex\to\complex\) be analytic on \(S\).
        Then
        \begin{enumerate}[label=(\roman*)]
            \item If \(w'(z) = 0\) for all \(z\in S\) then \(w(z)\) is constant for all \(z \in S\).
            \item If \(\abs{w(z)}\) is constant for all \(z\in S\) then \(w(z)\) is also constant for all \(z\in S\).
        \end{enumerate}
    \end{theorem}
    \begin{proof}
        We will prove these in the order stated.
        \begin{enumerate}[label=(\roman*)]
            \item The \gls{mvt} for several variables states that for \(f\colon\reals^n\to\reals\) and \(\vv{a}, \vv{b}\in\reals^n\) there exists \(\vv{c}\in\reals^n\) such that
            \[f(\vv{b}) - f(\vv{a}) = [\grad f(\vv{c})] \cdot (\vv{b} - \vv{a}).\]
            Specifically in the one dimensional case this takes the form
            \[f'(c) = \frac{f(b) - f(a)}{b - a}.\]
            This theorem doesn't hold for complex functions, however we can apply it to the real and imaginary parts of \(w\), \(u\) and \(v\) respectively.
            
            Let \(w\colon S\to\complex\) be such that \(w'(z) = 0\) for all \(z\in S\) and \(w(z) = w(x + iy) = u(x, y) + iv(x, y)\) where \(u, v\colon\reals^2\to\reals\).
            Then for \(\vv{a}, \vv{b}\in S' = \{(x, y)\in\reals^2\st x + iy\in S\}\) we can say that there exists \(\vv{c}\in\reals^2\) such that
            \[u(\vv{b}) - u(\vv{a}) = [\grad u(\vv{c})]\cdot(\vv{b} - \vv{a}).\]
            However in this case we are assuming \(w'(z) = 0\) which necessitates that all partial derivatives are also zero.
            Thus \(\grad u(\vv{c}) = 0\) for all \(\vv{c}\in S'\).
            This means that \(u(\vv{b}) - u(\vv{a}) = 0\) hence \(u(\vv{b}) = u(\vv{a})\).
            Since this holds for any pair of points, \(\vv{a}, \vv{b}\in S'\) we must have that \(u(x, y)\) is constant for all \((x, y)\in S'\).
            By the same logic we must also have that \(v(x, y)\) is constant for all \((x, y)\in S'\) and hence \(w(z)\) is constant for all \(z\in S\).
            
            \item Let \(w\colon S\to\complex\) be such that \(\abs{w(z)} = C\) is constant for all \(z\in S\).
            Then \(u^2 + v^2 = C^2\).
            Differentiating with respect to \(x\) and separately with respect to \(y\) we get
            \[2uu_x + 2vv_x = 0, \qquad\text{and}\qquad 2uu_y + 2vv_y = 0.\]
            Applying the Cauchy--Riemann relations we get
            \[uu_x - vu_y = 0, \qquad\text{and}\qquad uu_y + vu_x = 0.\]
            Since both equations hold simultaneously we can solve them and find that \((u^2 + v^2)u_y = C^2u_y = 0\).
            If \(u\) and \(v\) are both zero then \(C = 0\).
            If this is not the case then \(u_x\) and \(u_y\) must be zero.
            Similarly we can show that \(v_x\) and \(v_y\) must be zero and hence \(w(z)\) is constant for all \(z\in S\).
        \end{enumerate}
    \end{proof}
    
    \subsection{Reconstruction}
    \begin{definition}{Harmonic conjugate}{}
        Let \(u, v\colon S\subseteq\reals^2\to\reals\).
        We say \(v\) is the \define{harmonic conjugate} of \(u\) if \(u\) and \(v\) are both harmonic and they satisfy the Cauchy--Riemann relations in an open subset, \(S\subseteq \reals^2\).
    \end{definition}
    Note that if \(v\) is the harmonic conjugate of \(u\) then \(w(x + iy) = u(x, y) + iv(x, y)\) is analytic on \(S\).
    For a given harmonic function \(u\colon\reals^2\to\reals\) its harmonic conjugate, if it exists, is unique up to a constant.
    The process of finding the harmonic conjugate is best demonstrated with an example.
    \begin{example}
        \textit{Given the function \(u(x, y) = y^3 - 3x^2y\) find its harmonic conjugate.}
        
        We start by computing the partial derivatives of \(u\):
        \[u_x = -6xy, \qquad\text{and}\qquad u_y = 3y^2 - 3x^2.\]
        From the Cauchy--Riemann relations and the fundamental theorem of calculus we have that
        \[v = \int v_y \dd{y} + f(x) = \int u_x \dd{y} + f(x) = -6x\int y \dd{y} + f(x) = -3xy^2 + h(x)\]
        for some `constant' of integration \(h\).
        Hence
        \[v_x = -3y^2 + h'(x).\]
        We can also compute this value using the Cauchy--Riemann relations which gives
        \[v_x = -u_y = 3x^2 - 3y^2.\]
        For both of these to be equal we require
        \[h'(x) = 3x^2 \implies h(x) = \int 3x^2 \dd{x} = x^3 + C\]
        Finally
        \[v(x, y) = -3xy^2 + x^3 + C.\]
        Thus
        \[w(z) = w(x + iy) = y^3 - 3x^2y + i(x^3 - 3xy^2 + C) = i(z^3 + C)\]
        is entire, which we already know as \(w\) is a polynomial.
        
        We made a decision at the start to integrate \(v_y\), we could have instead integrated \(v_x\) and we will arrive at the same result:
        \[v = \in v_x \dd{x} + f(y) = -\int u_y \dd{x} + f(y) = \int (3x^2 - 3y^2) \dd{x} + f(y) = x^3 - 3xy^2 + h(y).\]
        Thus
        \[v_y = -6xy + h'(y)\]
        or by the Cauchy--Riemann relations
        \[v_y = u_x = -6xy\]
        so we see that this time \(h'(y) = 0\) meaning that \(h(y) = C\) is constant.
        Thus
        \[v(x, y) = x^3 - 3xy^2 + C\]
        which is the same result as we got the first time.
    \end{example}
    
    \section{Branch Points}\label{sec:branch points}
    \subsection{Elementary Functions}
    \subsubsection{Polynomials}
    A polynomial of order \(n\),
    \[P_n(z) = \sum_{k = 0}^{n} a_kz^k,\]
    is a linear combination of powers of \(z\) which are entire so \(P_n\) is entire.
    The fundamental theorem of algebra, which we will prove later, states that \(P_n\) has exactly \(n\) roots.
    For example \(w(z) = z^4\) has roots at \(z = 1, -1, i, -i\).
    \(z^4\) will map any wedge covering \(\pi/2\, \si{\radian}\) of \(\complex\) to the whole of \(\complex\).
    For example consider figure~\ref{fig:pi/2 wedges map to C under z->z^4} which shows the complex plane divided into four wedges and the image\footnote{Recall that the image of a set, \(A\subseteq S\), under the function \(w\colon S\subseteq\complex\to\complex\) is the set \(w(A) = \{w(z)\st z\in A\}\).} of one of these wedges after the mapping \(z\mapsto z^4\).
    The image of one of these wedges is \(\complex\).
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{quartic-mapping}
        \begin{tikzpicture}[
                axis/.style={thick},
                line/.style={yellow, ultra thick}
                my color/.style={fill=#1, opacity=0.3}
            ]
%            \tikzstyle{axis} = [thick]
%            \tikzstyle{line} = [yellow, ultra thick]
%            \tikzstyle{my color} = [fill={#1}, opacity=0.3]
            \draw[axis, ->] (-2, 0) -- (2, 0);
            \draw[axis, ->] (0, -2) -- (0, 2);
            \begin{scope}
                \clip (-2, -2) rectangle (2, 2);
                \begin{scope}[rotate=30]
                    \fill[red, opacity=0.3] (0, 0) rectangle (4, 4);
                    \fill[blue, opacity=0.3] (0, 0) rectangle (4, -4);
                    \fill[green, opacity=0.3] (0, 0) rectangle (-4, 4);
                    \fill[purple, opacity=0.3] (0, 0) rectangle (-4, -4);
                    \draw[line] (0.5, 0) arc (0:90:0.5);
                \end{scope}
            \end{scope}
            \node (label 1) at (0, -2.5) {\(z = Re^{i\vartheta}\)};
            \draw[line] (label 1.west) -- ($(label 1.west) - (0.5, 0)$);
            \node[right] at ($(label 1.west) - (0, 0.5)$) {\(\vartheta\in[\pi/6, 2\pi/3)\)};
            \fill[red, opacity=0.3] ($(label 1.west) - (0.5, 0.75)$) rectangle ($(label 1.west) - (0, 0.25)$);
            \draw[very thick, ->] (2.5, 0) -- (3.5, 0) node[midway, above] {\(z \mapsto z^4\)};
            \begin{scope}[xshift=6cm]
                \draw[axis, ->] (-2, 0) -- (2, 0);
                \draw[axis, ->] (0, -2) -- (0, 2);
                \fill[red, opacity=0.3] (-2, -2) rectangle (2, 2);
                \draw[line] (0, 0) circle[radius=1];
                \node (label 2) at (0, -2.5) {\(z = R^4e^{4i\vartheta}\)};
                \draw[line] (label 2.west) -- ($(label 2.west) - (0.5, 0)$);
                \node[right] at ($(label 2.west) - (0, 0.5)$) {\(4\vartheta\in[2\pi/3, 8\pi/3)\)};
                \fill[red, opacity=0.3] ($(label 2.west) - (0.5, 0.75)$) rectangle ($(label 2.west) - (0, 0.25)$);
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{Four possible wedges that all map to \(\complex\) under \(z\mapsto z^4\). The red wedge is \(\vartheta\in[\pi/6, 2\pi/3)\). The curve \(Re^{i\vartheta}\) within this wedge maps to a circle of radius \(R^4\) as \(2\vartheta\in[4\pi/3, 8\pi/3)\) which is a \(2\pi\) range.}
        \label{fig:pi/2 wedges map to C under z->z^4}
    \end{figure}
    While this isn't particularly interesting for the mapping \(z\mapsto z^4\) it causes problems for the inverse mapping, \(z\mapsto z^{1/4}\).
    We have to ask the question which of the four wedges that map to \(\complex\) in the forward mapping should we map to in the reverse mapping.
    Or we could even map to a mixture of different wedges.
    In this and the next few sections we will discover the consequences of such choices.
    
    One immediate choice is if we want \(1^{1/3} = 1\) then we could choose the \(\pi/3\) wedge given by \(\vartheta\in[0, \pi/3]\).
    However this means that \((-1)^{1/3} \ne -1\) even though this is the value we would normally consider since \(\arg(-1) = \pi \notin [0, \pi/3]\).
    Instead we have
    \[(-1)^{1/3} = (e^{i\pi})^{1/3} = e^{i\pi/3} = \frac{1}{2} + i\frac{\sqrt{3}}{2}.\]
    We have even more of a problem if we consider irrational roots.
    For example the \(r\)th roots of \(z\) for some \(r\in\reals\) is
    \[\sqrt[r]{z} = \sqrt[r]{\abs{z}e^{i\vartheta + 2\pi ki}} = \sqrt[r]{z}\exp\left[i\frac{\vartheta}{r} + \frac{2\pi ki}{r}\right]\]
    for all \(k\in\integers\).
    If \(r\in\integers\) then eventually we will get to a point where the argument starts overlapping with previous values as we increase \(k\) however if, for example, \(r = e\) then this doesn't happen and we will end up with an infinite number of different values.
    
    \subsubsection{Exponential and Logarithm}
    The exponential function has many of the expected properties, for example
    \[e^{z_1 + z_2} = e^{z_1}e^{z_2},\qquad  e^{z}\ne 0 \forall z\in\complex, \qquad\text{and}\qquad e^{x + iy} = e^x(\cos y + i\sin y).\]
    Likewise the logarithm also has many of the expected properties, for example
    \[\log(e^z) = z, \qquad \log(z_1z_2) = \log z_1 + \log z_2, \qquad \log\left(\frac{1}{z}\right) = -\log z,\]
    \[\text{and}\qquad \log z = \log(\abs{z}e^{i\vartheta}) = \log\abs{z} \log e^{-\vartheta} = \log\abs{z} + i\vartheta.\]
    However \(e^z\) is periodic with period \(2\pi i\).
    This means that \(z\mapsto e^z\) maps a strip of width \(2\pi\) to \(\complex\setminus\{0\}\).
    See figure~\ref{fig:2pi stripes map to C under z->e^z}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{exponential-mapping}
        \begin{tikzpicture}[
                axis/.style={thick},
                line/.style={yellow, ultra thick}
            ]
%            \tikzstyle{axis} = [thick]
%            \tikzstyle{line} = [yellow, ultra thick]
%            \tikzstyle{my color} = [fill={#1}, opacity=0.3]
            \draw[axis, ->] (-2, 0) -- (2, 0);
            \draw[axis, ->] (0, -2) -- (0, 2);
            \fill[red, opacity=0.3] (-2, -0.5) rectangle (2, 0.5);
            \fill[blue, opacity=0.3] (-2, 0.5) rectangle (2, 1.5);
            \fill[green, opacity=0.3] (-2, -1.5) rectangle (2, -0.5);
            \fill[magenta, opacity=0.3] (-2, 1.5) rectangle (2, 2);
            \fill[orange, opacity=0.3] (-2, -1.5) rectangle (2, -2);
            \draw[line] (0.75, -0.5) -- (0.75, 0.5);
            
            \node (label 1) at (0, -2.5) {\small\(z = C + iy\)};
            \draw[line] (label 1.west) -- ($(label 1.west) - (0.5, 0)$);
            \node[right] at ($(label 1.west) - (0, 0.5)$) {\small\(\Im(z) \in (-\pi, \pi]\)};
            \fill[red, opacity=0.3] ($(label 1.west) - (0.5, 0.75)$) rectangle ($(label 1.west) - (0, 0.25)$);
            
            \draw[very thick, ->] (2.5, 0) -- (3.5, 0) node[midway, above] {\(z \mapsto e^z\)};
            \begin{scope}[xshift=6cm]
                \draw[axis, ->] (-2, 0) -- (2, 0);
                \draw[axis, ->] (0, -2) -- (0, 2);
                \fill[red, opacity=0.3] (-2, -2) rectangle (2, 2);
                \fill[white, opacity=0.3] (0, 0) circle[radius=0.075cm];
                \draw[axis] (-0.1, 0) -- (0.1, 0);
                \draw[axis] (0, -0.1) -- (0, 0.1);
                \draw[line] (0, 0) circle[radius=1cm];
                
                \node (label 2) at (0.35, -2.5) {\small\(z = e^{C}(\cos y + i\sin y)\)};
                \draw[line] (label 2.west) -- ($(label 2.west) - (0.5, 0)$);
                \node[right] at ($(label 2.west) - (0, 0.5)$) {\small\(z\in\complex\setminus\{0\}\)};
                \fill[red, opacity=0.3] ($(label 2.west) - (0.5, 0.75)$) rectangle ($(label 2.west) - (0, 0.25)$);
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{Stripes of width \(2\pi\) which all map to \(\complex\setminus\{0\}\) under \(z\mapsto e^z\). The red stripe is \(\Im(z) \in (-\pi, \pi]\). The curve \(z = C + iy\) for some constant \(C\in\reals\) maps to a circle of radius \(e^C\).}
        \label{fig:2pi stripes map to C under z->e^z}
    \end{figure}
    In order for \(\log z\) to be single valued we have to make a choice to restrict \(\vartheta\) to some \(2\pi\) interval.
    Common choices are \((-\pi, \pi]\) and \([0, 2\pi)\).
    
    There is another problem however.
    Suppose we choose \(\vartheta \in (-\pi, pi]\).
    Now move smoothly around a circle of arbitrary radius, \(R\).
    This corresponds to increasing \(\vartheta\) smoothly and moving along the curve given by \(Re^{i\vartheta}\).
    Most of the time \(\Re(\log z)\) and \(\Im(\log z)\) change smoothly as we move around the circle up until the point \(\vartheta = \pi\).
    At this point if we move from above the real axis to just below, even if we do so be an arbitrarily small amount, there will be a jump in \(\vartheta\) of \(2\pi\) which means there will be a jump in \(\Im(\log z)\) of \(2\pi\).
    
    \subsubsection{Hyperbolic and Trigonometric Functions}
    Hyperbolic and trigonometric functions on \(\complex\) are defined using complex exponentials as
    \[\cosh z = \frac{1}{2}(e^{-z} + e^{-z}), \qquad \sinh z = \frac{1}{2}(e^{-z} - e^{-z}), \qquad \tanh = \frac{\sinh z}{\cosh z} = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} = \frac{1 - e^{-2z}}{1 + e^{-2z}},\]
    \[\cos z = \frac{1}{2}(e^{iz} + e^{-iz}), \qquad \sin z = \frac{1}{2i}(e^{iz} - e^{-iz}),\]
    \[\text{and}\qquad \tan z = \frac{\sin z}{\cos z} = \frac{e^{iz} - e^{-iz}}{i(e^{iz} + e^{-iz})} = \frac{1 - e^{-2iz}}{i(1 - e^{-2iz})}.\]
    We can see from these formulas that the hyperbolic and trigonometric functions are inextricably linked by
    \[\cos z = \cosh(iz), \qquad\text{and}\qquad \sin z = -i\sinh(iz).\]
    Note that multiplication by \(\pm i\) is a rotation by \(\pm\pi/2\) in the complex plane.
    Therefore we expect \(\sin\) to be a rotated version of \(\sinh\) with a phase shift.
    Similarly \(\cos\) is a phase shifted version of \(\cosh\).
    \begin{figure}[ht]
        \centering
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[scale=0.4]{cosh_phase.png}
            \caption{The phase of \(\cosh(z)\)}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[scale=0.4]{sinh_phase.png}
            \caption{The phase of \(\sinh(z)\)}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[scale=0.4]{cos_phase.png}
            \caption{The phase of \(\cos(z)\)}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[scale=0.4]{sin_phase.png}
            \caption{The phase of \(\sin(z)\)}
        \end{subfigure}
        \caption{The phases of \(\cosh(z)\), \(\sinh(z)\), \(\cos(z)\), and \(\sin(z)\).}
    \end{figure}
    The following trig identities still hold for the complex versions:
    \begin{align*}
        \sin(z_1 + z_2) &= \sin(z_1)\cos(z_2) + \sin(z_2)\cos(z_1)\\
        \cos(z_1 + z_2) &= \cos(z_1)\cos(z_2) + \sin(z_1)\sin(z_2)\\
        1 &= \sin^2(z) + \cos^2(z)
    \end{align*}
    The inverse hyperbolic and trigonometric functions are given by
    \[\arcosh(z) = \log\left(z + \sqrt{z^2 - 1}\right), \qquad \arsinh(z) = \log\left(z + \sqrt{z^2 + 1}\right),\]
    \[\arccos(z) = \frac{1}{i}\log\left(z + \sqrt{1 - z^2}\right), \qquad\text{and}\qquad \arcsin(z) = \frac{1}{i}\log\left(iz + \sqrt{1 - z^2}\right).\] 
    
    \subsection{Branch Points}
    Recall that we mentioned earlier a discontinuity in \(\log(z)\) when traversing a circle about the origin.
    This is because \(z = 0\) is a branch point of \(\log z\).
    \begin{definition}{Branch point}{}
        Let \(w\colon S\subseteq\complex\to\complex\).
        We say that \(z_0\in\complex^*\) is a \define{branch point} of \(w\) if the neighbourhood, \(\discPunctured{z_0}{\varepsilon}\), contains points where \(w\) is discontinuous for arbitrarily small \(\varepsilon > 0\).
    \end{definition}
    To show that a point is a branch point it suffices to show that a circle about that point with arbitrarily small radius contains a discontinuity.
    A branch point is \emph{not} an isolated singularity as \(w\) is, by definition, continuous in the neighbourhood of an isolated singularity.
    Again notice that the value of \(w\) at \(z_0\) is unimportant in the question of whether \(z_0\) is a branch point of \(w\).
    Notice that \(z = \infty\) can be a branch point.
    We can check for this by considering the transformation \(z \to 1/t\) as \(t\to 0\).
    
    \begin{example}
        \textit{We have already seen that \(w(z) = \log z\) has a branch point at \(z = 0\).
        Does it have a branch point at \(z = \infty\)?}
        
        Make the transformation \(z \to 1/t\):
        \[\log z \to \log \frac{1}{t} = -\log t.\]
        Since this has a factor of \(\log t\) it will have a branch point at \(t = 0\) and therefore \(\log z\) has a branch point at \(z = \infty\).
    \end{example}
    \begin{example}
        \textit{Where are the branch points of \(w(z) = \sqrt{z}\)?}
        
        We can write an arbitrary real power of \(z\) as
        \[z^{\alpha} = e^{\alpha\log z} = \exp[\alpha\log\abs{z} + i\alpha(\vartheta + 2\pi n)].\]
        We see that this contains a logarithm and therefore has a branch point at \(z = 0, \infty\).
    \end{example}
    From these two examples if we have a function of square roots and logarithms we can find the branch points simply by looking for when the arguments of said logarithms and square roots are zero.
    
    \section{Branch Cuts}\label{sec:branch cuts}
    \begin{example}
        \textit{Where are the branch points of \(w(z) = \sqrt{z^2 - 1}\)?}
        
        We can write
        \[w(z) = \sqrt{z^2 - 1} = \sqrt{z - 1}\sqrt{z + 1}.\]
        First we consider when the argument of the square roots may be \(0\), we see this happens at \(z = \pm 1\).
        What about \(z = \infty\)?
        Again we make the transformation \(z \to 1/t\):
        \[\sqrt{z^2 - 1} \to \sqrt{\frac{1}{t^2} - 1} = \sqrt{\frac{1 - t^2}{t^2}} = \frac{\sqrt{1 - t^2}}{t}.\]
        Now as \(t \to 0\) this is a singularity, however that doesn't matter as the value of \(w\) is unimportant at a branch point.
        Since the argument of the square root is non-zero at \(t = 0\) this is not a branch point.
        Therefore the branch points of \(w\) are \(z = \pm 1\).
    \end{example}
    We will use this example to develop an important concept.
    A point in the plane can be expressed in polar coordinates centred at \(z = \pm 1\), see figure~\ref{fig:z in polar coords based on +/-1}.
    In these coordinates
    \[z + 1 = R^- e^{i\vartheta^-}, \qquad\text{and}\qquad z - 1 = R^{i\vartheta^+}.\]
    This allows us to express \(w(z) = \sqrt{z^2 - 1}\) as
    \[w(z) = \sqrt{z^2 - 1} = \sqrt{z + 1}\sqrt{z - 1} = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(\vartheta^+ + \vartheta^-)\right].\]
    We will use this form to investigate the discontinuities of \(w\).
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{double-polar-coordinates}
        \begin{tikzpicture}
            \tikzstyle{axis} = [thick, ->]
            \draw[axis] (-4, 0) -- (4, 0);
            \draw[axis] (0, -1) -- (0, 4);
            \coordinate (z=1) at (2, 0);
            \coordinate (z=-1) at (-2, 0);
            \coordinate (z) at (3, 3);
            \node[below] at (z=1) {\(1\)};
            \node[below] at (z=-1) {\(-1\)};
            \node[above right] at (z) {\(z\)};
            \begin{scope}
                \clip (z=1) -- (z) -- (z=-1) -- cycle;
                \draw (z=-1) circle[radius=0.5cm];
            \end{scope}
            \begin{scope}
                \clip (z=1) -- (z) -- (4, 0) -- (z=1);
                \draw (z=1) circle[radius=0.5cm];
            \end{scope}
            \draw (z=1) -- (z) node[midway, right] {\(R^+\)};
            \draw (z=-1) -- (z) node[midway, above] {\(R^-\)};
            \node at ($(z=1) + (0.68, 0.35)$) {\(\vartheta^+\)};
            \node at ($(z=-1) + (0.8, 0.2)$) {\(\vartheta^-\)};
            \draw[color=red, fill=red] (z=1) circle[radius=0.05cm]; 
            \draw[color=red, fill=red] (z=-1) circle[radius=0.05cm];
            \draw[color=green, fill=green] (z) circle[radius=0.05cm];
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{A point, \(z\), can be thought of in two sets of polar coordinates centred at \(\pm 1\).}
        \label{fig:z in polar coords based on +/-1}
    \end{figure}
    What we will see is that there are discontinuities regardless of how we restrict \(\vartheta^\pm\) to have a single valued function.
    We consider three different paths across the real axis, each starting at a point \(x + i\delta\) above the axis for some \(\delta > 0\)  and ending at \(x + i\delta\) below the axis.
    If there is a discontinuity above the axis then even as \(\delta \to 0\) there will be a non-zero jump in the value of \(w\).
    
    \begin{itemize}
        \item The first choice we make is \(\vartheta^\pm \in (-\pi, \pi]\).
        \begin{itemize}
            \item The first path we consider has \(x \in (1, \infty)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} = 0\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(0 + 0)\right] = \sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} \to 0\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(0 + 0)\right] = \sqrt{R^+R^-}.\]
            Both of these are equal so there is no discontinuity in the \((1, \infty)\) interval of the real axis.
            
            \item The second path we consider has \(x \in (-1, 1)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = \pi\) and \(\vartheta^- = 0\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(\pi + 0)\right] = e^{i\pi/2}\sqrt{R^+R^-} = i\sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = -\pi\) and \(\vartheta^- = 0\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(-\pi + 0)\right] = e^{-i\pi/2}\sqrt{R^+R^-} = -i\sqrt{R^+R^-}.\]
            These are not equal so there is a discontinuity in the \((-1, 1)\) interval of the real axis.
            
            \item The third path we consider has \(x\in(-\infty, -1)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} = \pi\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(\pi + \pi)\right] = e^{i\pi}\sqrt{R^+R^-} = -\sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} = -\pi\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(-\pi + -\pi)\right] = e^{-i\pi}\sqrt{R^+R^-} = \sqrt{R^+R^-}.\]
            Both of these are equal so there is no discontinuity in the \((-\infty, 1)\) interval of the real axis.
        \end{itemize}
        We conclude that with the choice \(\vartheta^{\pm} \in (-\pi, \pi]\) there is a discontinuity only crossing the interval \((-1, 1)\) of the real axis.
        
        \item The second choice we make is \(\vartheta^+\in(-\pi, \pi]\) and \(\vartheta^-\in[0, 2\pi)\).
        \begin{itemize}
            \item The first path we consider has \(x \in (1, \infty)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} = 0\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(0 + 0)\right] = \sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = 0\) and \(\vartheta^- = 2\pi\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(0 + 2\pi)\right] = e^{i\pi}\sqrt{R^+R^-} = -\sqrt{R^+R^-}.\]
            These are not equal so there is a discontinuity in the \((1, \infty)\) interval of the real axis.
            
            \item The second path we consider has \(x\in(-1, 1)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = -\pi\) and \(\vartheta^- = 2\pi\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(2\pi - \pi)\right] = e^{i\pi/2}\sqrt{R^+R^-} = i\sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = -\pi\) and \(\vartheta^- = 2\pi\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(-\pi + 2\pi)\right] = e^{i\pi/2}\sqrt{R^+R^-} = i\sqrt{R^+R^-}.\]
            Both of these are equal so there is no discontinuity in the \((-1, 1)\) interval of the real axis.
            
            \item The third path we consider has \(x\in(-\infty, -1)\).
            \subitem Above the axis in the limit \(\delta \to 0\) we have \(\vartheta^{\pm} = \pi\).
            Hence
            \[\lim_{\delta\to 0} w(x + i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(\pi + \pi)\right] = e^{i\pi}\sqrt{R^+R^-} = \sqrt{R^+R^-}.\]
            \subitem Below the axis in the limit \(\delta \to 0\) we have \(\vartheta^+ = -\pi\) and \(\vartheta^- = \pi\).
            Hence
            \[\lim_{\delta\to 0} w(x - i\delta) = \sqrt{R^+R^-}\exp\left[i\frac{1}{2}(-\pi + \pi)\right] = \sqrt{R^+R^-}.\]
            These are not equal so there is a discontinuity in the \((-\infty, 1)\) interval of the real axis.
        \end{itemize}
        We conclude that with the choice \(\vartheta^+\in(-\pi, \pi]\) and \(\vartheta^-\in[0, 2\pi)\) there is a discontinuity crossing the real axis in either \((-\infty, -1)\) or \((1, \infty)\).
    \end{itemize}
    This demonstrates the importance of choosing the argument.
    In general it is possible to move discontinuities by changing the argument but we cannot get rid of them.
    There is no `right answer', it is best to make a choice and write it down and be careful to stick with it.
    
    \begin{definition}{Branch cut}{}
        A \define{branch cut} is an arbitrary path that joins two branch points and as a result of which the function in question becomes single valued.
    \end{definition}
    Figure~\ref{fig:sqrt z riemann surface} shows a Riemann surface, which is a way of plotting complex functions.
    This one shows \(\sqrt{z}\) which we can see is multi valued.
    We can think of branch points as the points where multiple sheets coincide.
    Figure~\ref{fig:sqrt z riemann surface with branch cut} shows the same Riemann surface after a branch cut along the negative real axis, which joins \(0\) and \(\infty\), the two branch points of \(\sqrt{z}\).
    The function is now single valued and the discontinuity at the branch cut is fairly obvious.
    \begin{figure}[ht]
        \centering
        \includegraphics[scale=0.6]{sqrt_z_riemann_surface.png}
        \caption{The Riemann surface of \(\sqrt{z}\) showing the real and imaginary parts in the bottom plane and \(\Re(\sqrt{z})\) in the vertical axis.}
        \label{fig:sqrt z riemann surface}
    \end{figure}
    \begin{figure}[ht]
        \centering
        \includegraphics[scale=0.6]{sqrt_z_riemann_surface_with_branch_cut.png}
        \caption{The Riemann surface of \(\sqrt{z}\) with a branch cut along the negative real axis in order to make the function single valued. The branch cut is shown in blue.}
        \label{fig:sqrt z riemann surface with branch cut}
    \end{figure}
    
    \begin{figure}[ht]
        \centering
        \includegraphics[scale=0.6]{sqrt_z_squared_minus_1_riemann_surface.png}
        \caption{The Riemann surface of \(\sqrt{z^2 - 1}\) with two branch points at \(z = \pm 1\).}
    \end{figure}
    \begin{figure}[ht]
        \centering
        \includegraphics[scale=0.6]{sqrt_z_squared_minus_1_riemann_surface_with_branch_cuts}
        \caption{The Riemann surface of \(\sqrt{z^2 - 1}\) with a branch point from \(z = \infty\) to \(z = \pm 1\). Essentially this cuts the bottom half off to make the function single valued.}
    \end{figure}

    \part{Integrals}
    \section{Complex Integration}
    \subsection{Integrating Functions From \texorpdfstring{\(\reals\)}{R} to \texorpdfstring{\(\complex\)}{C}}
    Before we define integration in the complex plane we consider a simpler case.
    Consider a function, \(w\colon\reals\to\complex\).
    We can write this function as
    \[w(t) = u(t) + iv(t)\]
    where \(u, v\colon\reals\to\reals\).
    If \(u\) and \(v\) are both piecewise continuous (that is contain a countable number of discontinuities) then we can integrate \(w\) the same way we would integrate a real integral.
    For example integrating over \((a, b)\) we have
    \[\int_a^b w(t) \dd{t} = \int_a^b u(t)\dd{t} + i\int_a^b v(t) \dd{t} = [U(t) + iV(t)]_a^b\]
    where \(U\) and \(V\) are the antiderivatives of \(u\) and \(v\).
    This simplified case of integrating only along \(\reals\) actually turns out to be very close to the more common case of a function defined on a particular path in the complex plane.
    We simply need to parametrise the path with a real parameter and then complex integrals become remarkably similar to their real counterpart.
    For example the integral as defined above is linear, that is for \(\alpha, \beta\in\complex\) and piecewise continuous functions \(f, g\colon\reals\to\complex\)
    \[\int_a^b [\alpha f(t) + \beta g(t)] \dd{t} = \alpha \int_a^b f(t) \dd{t} + \beta \int_a^b g(t) \dd{t}.\]
    
    \subsection{Arcs and Contours}
    The main difference between integrating a function defined on \(\reals\) and a function defined on \(\complex\) is that in the second case there are multiple paths we can take to get from \(a\) to \(b\).
    We have to define the path we are integrating along and in general it makes a difference which path we choose.
    This should be familiar from line integrals from multivariable calculus.
    In the complex plane we define a contour to integrate along.
    There are a few restraints on what paths we can choose as a contour.
    \begin{definition}{Smooth arc}{}
        The set of points
        \[\{\gamma(t) = x(t) + iy(t) \st x, y\colon\reals\to\reals\wedge t\in(a, b)\subseteq\reals\}\]
        is a \define{smooth arc} with end points \(\{a, b\}\) if both \(x(t)\) and \(y(t)\) are continuous and differentiable and \(\gamma'(t) = x'(t) + iy'(t) \ne 0\) for all \(t\in(a, b)\).
    \end{definition}
    \begin{notation*}{}
        We denote by \(C^k(X)\) the set of all functions defined on \(X\) with at least \(k\) continuous derivatives (on some domain of interest).
        Often we write \(C^k\) when the domain is obvious.
        For example \(C^0\) is the set of continuous functions which may or may not be differentiable and \(C^1\) is the set of differentiable functions with continuous derivatives. 
        Note that since we define \(f\in C^k\) to have at least \(k\) continuous derivatives we also know that \(f\in C^{k'}\) for all \(k'\le k\), for example the function defined by \(f(z) = e^z\) is in \(C^{\infty}\) but it is also in \(C^k\) fo all \(k\in\naturals\).
    \end{notation*}
    \begin{definition}{Contour}{}
        A \define{contour}, \(\gamma\), is a continuous chain of a finite number of smooth arcs.
        We say that \(\gamma\) is piecewise smooth.
    \end{definition}
    The condition that the number of arcs is finite is important.
    \begin{example}\label{exa:contours}
        Consider the path defined by
        \[\gamma(t) = z_0 + te^{i\vartheta}, \qquad t\in(0, 1)\]
        for some constant \(\vartheta\).
        To see what this arc looks like consider \(\gamma(0) = z_0\) and \(\gamma(1) = z_0 + e^{i\vartheta}\).
        This arc corresponds to a straight line between these two points as can be seen in figure~\ref{fig:contour example 1}.
        Notice that \(\gamma'(t) = e^{i\vartheta}\) is non-zero for all finite \(\vartheta\) so \(\gamma\) is a smooth arc.
        
        Consider the path defined by
        \[\gamma(t) = z_0 + Re^{it}, \qquad t\in(0, \pi/2)\]
        for some constant \(R\).
        To see what this arc looks like consider \(\gamma(0) = z_0 + R\) and \(\gamma(1) = z_0 + iR\).
        This arc corresponds to an arc (in the part of a circle sense) centred on \(z_0\) with radius \(R\) starting at 0 and going round to \(\pi/2\) as can be seen in figure~\ref{fig:contour example 2}.
        Notice that \(\gamma'(t) = iRe^it\) is non-zero for all finite \(t\) so \(\gamma\) is a smooth arc.
        
        Consider the path defined by
        \[\gamma(t) = t + ie^{-it}, \qquad t\in(0, 3\pi).\]
        Notice that
        \[\Re(z) = t + \cos t, \qquad\text{and}\qquad \Im(z) = 1 - \sin t\]
        so
        \[z'(t) = 1 - \sin t - i\cos t.\]
        This is zero for \(t = \pi/2 + 2n\pi\), \(n\in\integers\).
        Therefore this is \emph{not} a smooth arc.
        However as we see in figure~\ref{fig:contour example 3} we can decompose it into three smooth arcs which makes it a valid contour.
        \tikzexternalenable
        \begin{figure}[ht]
            \centering
            \begin{subfigure}{0.4\textwidth}
                \centering
                \tikzsetnextfilename{contour_example_1}
                \begin{tikzpicture}
                    \tikzstyle{contour} = [very thick]
                    \draw[contour] (0, 0) -- (2, 2);
                    \draw[fill=black] (0, 0) circle[radius=0.05cm] node[below left] {\(z_0\)};
                    \draw[fill=black] (2, 2) circle[radius=0.05cm] node[above right] {\(z_0 + e^{i\vartheta}\)};
                    \begin{scope}
                        \clip (0, 0) -- (2, 2) -- (2, 0) -- cycle;
                        \draw (0, 0) circle[radius=0.5cm];
                    \end{scope}
                    \node at (0.6, 0.2) {\(\vartheta\)};
                    \draw[dashed] (0, 0) -- (1, 0);
                \end{tikzpicture}
                \caption{The contour defined by \(\gamma(t) = z_0 + te^{i\vartheta}\) for \(t\in(0, 1)\).}
                \label{fig:contour example 1}
            \end{subfigure}
            \begin{subfigure}{0.4\textwidth}
                \centering
                \tikzsetnextfilename{contour_example_2}
                \begin{tikzpicture}
                    \tikzstyle{contour} = [very thick]
                    \draw[fill=black] (0, 0) circle[radius=0.05cm] node[below left] {\(z_0\)};
                    \draw[fill=black] (2, 0) circle[radius=0.05cm] node[below] {\(z_0 + R\)};
                    \draw[fill=black] (0, 2) circle[radius=0.05cm] node[above] {\(z_0 + iR\)};
                    \begin{scope}
                        \clip (0, 0) -- (3, 0) -- (3, 3) -- (0, 3) -- cycle;
                        \draw[contour] (0, 0) circle[radius=2cm];
                    \end{scope}
                    \draw[dashed] (0, 2) -- (0, 0) -- (2, 0);
                    \draw (0.5, 0) -- (0.5, 0.5) -- (0, 0.5);
                \end{tikzpicture}
                \caption{The contour defined by \(\gamma(t) = z_0 + Re^{it}\) for \(t\in(0, \pi/2)\).}
                \label{fig:contour example 2}
            \end{subfigure}
            \begin{subfigure}{0.9\textwidth}
                \centering
                \tikzsetnextfilename{contour_example_3}
                \begin{tikzpicture}
                    \tikzstyle{contour} = [very thick]
                    \begin{axis}[xmin=0,xmax=10, samples=50, axis equal image, hide axis]
                        \addplot[contour, red, domain=0:1.571] ({x + cos(deg(x))}, {1 - sin(deg(x))});
                        \addplot[contour, blue, domain=1.571:7.854] ({x + cos(deg(x))}, {1 - sin(deg(x))});
                        \addplot[contour, green, domain=7.854:9.42] ({x + cos(deg(x))}, {1 - sin(deg(x))});
                    \end{axis}
                \end{tikzpicture}
                \caption{The contour defined by \(\gamma(t) = t + i + e^{-it}\) for \(t\in(0, 3\pi)\). Different colours are used to plot the three smooth arcs that make up the contour. The smooth arcs start and end at the points where \(\gamma'(t) = 0\) which is \(\pi/2 + 2n\pi\) for \(n\in\integers\).}
                \label{fig:contour example 3}
            \end{subfigure}
            \caption{Various examples of contours.}
        \end{figure}
        \tikzexternaldisable
    \end{example}
    \subsection{The Integral}
    \begin{definition}{Integral}{}
        Let \(\gamma\) be a contour.
        We split \(\gamma\) into \(n\) sections and define \(\{z_{\alpha}\}\) as the set of \(n + 1\) end points of each section.
        Let \(w\colon\complex\to\complex\) be a piecewise continuous complex function.
        Define the sum
        \[S_n = \sum_{\alpha = 1}^{n} w(z_\alpha)(z_{\alpha} - z_{\alpha - 1}).\]
        Now let \(n\to\infty\) and let the length of each segment \(\abs{z_\alpha - z_{\alpha - 1}} \to 0\).
        If this limit exists we say that \(w\) is \define{integrable} on \(\gamma\).
        In this case the limit is called the \define{integral} of \(w\) on \(\gamma\), or in the normal notation
        \[ \lim_{n\to\infty} S_n = \int_\gamma w(z) \dd{z}.\]
    \end{definition}
    \begin{lemma}{Linearity of the integral}{}
        Let \(\gamma\) be a contour, let \(f\) and \(g\) be piecewise continuous functions on \(\gamma\), and let \(\alpha, \beta\in\complex\) be constants.
        Then
        \[\int_\gamma (\alpha f(z) + \beta g(z)) \dd{z} = \alpha \int_\gamma f(z) \dd{z} + \beta \int_\gamma g(z) \dd{z}.\]
    \end{lemma}
    \begin{proof}
        Split the contour \(\gamma\), as in the definition of the integral, into \(n\) sections with end points \(z_{i}\) and length \(\abs{z_{i} - z_{i - 1}}\) such that the of each interval vanishes as \(n \to \infty\).
        Then
        \begin{align*}
            \int_\gamma (\alpha f(z) + \beta g(z)) \dd{z} &= \lim_{n\to\infty} \left[(\alpha f(z_{i}) \beta g(z_i))(z_i - z_{i-1})\right]\\
            &= \lim_{n\to\infty} \left[\alpha f(z_{i})(z_i - z_{i-1}) \beta g(z_i)(z_i - z_{i-1})\right]\\
            &= \alpha\lim_{n\to\infty} f(z_{i})(z_i - z_{i-1}) \beta\lim_{n\to\infty} g(z_i)(z_i - z_{i-1})\\
            &= \alpha \int_\gamma f(z) \dd{z} + \beta \int_\gamma g(z) \dd{z}.
        \end{align*}
        Here we have used the fact that
        \[\lim_{n\to\infty} [aA_n + bB_n] = a\lim_{n\to\infty}A_n + b\lim_{n\to\infty}B_n\]
        for some convergent complex sequences \((A_n)\) and \((B_n)\) and complex constants \(a\) and \(b\).
    \end{proof}
    \begin{definition}{Closed contour}{}
        Let \(\gamma\) be a contour with endpoints \(a\) and \(b\).
        If \(a = b\) we say that the contour is \define{closed}.
    \end{definition}
    Note that this sort of closed is not the same as the topological sort of closed (i.e. that the set contains its boundary).
    \begin{notation*}{}
        If \(\gamma\) is a closed contour and \(w\) is integrable on \(\gamma\) then we denote the integral by
        \[\oint_{\gamma} w(z) \dd{z}.\]
        As a matter of convention when integrating along a closed contour we go anticlockwise.
    \end{notation*}
    
    \subsection{Evaluating Integrals}
    Now that we have defined an integral we can start actually integrating things.
    Let \(\{\gamma_k\}\) be smooth arcs which together form a contour, \(\gamma\).
    Let \(\gamma_k\) be parametrised by some real variable \(t \in (a, b)\).
    Under this parametrisation the points on \(\gamma_k\) can be written as \(z = z[\gamma_k(t)] = x(t) + iy(t)\) where \(x, y\colon\reals\to\reals\).
    Differentiating we have
    \[\dv{z}{t} = x'(t) + iy'(t) = \gamma_k'(t) \implies \dd{z} = [x'(t) + iy(t)]\dd{t} = \gamma_k'(t)\dd{t}.\]
    Now let \(w\colon\complex\to\complex\) be integrable on \(\gamma\) and let \(w(\gamma(t)) = u(t) + iv(t)\) where \(u, v\colon\reals\to\reals\).
    Then the substitution \(z\to\gamma_k\) gives us
    \begin{align*}
        \int_{\gamma_k} w(z)\dd{z} &= \int_a^b w[\gamma_k(t)] \gamma_k'(t) \dd{t}\\
        &= \int_a^b [u(t) + iv(t)][x'(t) + iy'(t)] \dd{t}\\
        &= \int_a^b [u(t)x'(t) - v(t)y'(t)]\dd{t} + i\int_a^b [v(t)x'(t) + u(t)y'(t)]\dd{t}.
    \end{align*}
    These integrals can then be easily evaluated using techniques from real integral calculus.
    
    \begin{lemma}{Integral properties}{}
        Let \(\gamma\) be a piecewise smooth contour and let \(f\) be a continuous function on \(\gamma\).
        Then the following hold.
        \begin{enumerate}
            \item Inverting the contour inverts the integral:
            \[\int_{-\gamma} f(z) \dd{z} = -\int_{\gamma} f(z) \dd{z}.\]
            
            \item If \(\gamma\) can be decomposed into two smooth contours \(\gamma_1\) and \(\gamma_2\) then
            \[\int_\gamma f(z) \dd{z} = \int_{\gamma_1} f(z) \dd{z} + \int_{\gamma_2} f(z) \dd{z}.\]
            
            \item Two different parametrisations of \(\gamma\) will yield the same result.
            That is if \(\gamma_1\) and \(\gamma_2\) are smooth arcs with endpoints \(\{a, b\}\) and \(\{a', b'\}\) respectively and \(g\colon(a, b) \to (a', b')\) such that \(g(\gamma_1) = \gamma_2\) then
            \[\int_{\gamma_1} f(z) \dd{z} = \int_{\gamma_2} f(z) \dd{z}.\]
        \end{enumerate}
    \end{lemma}
    \begin{proof}
        ~  % Forces a space which makes enumerate start on a new line.
        \begin{enumerate}
            \item Consider the definition of the integral over \(\gamma\)
            \begin{align*}
                -\int_{\gamma}f(z)\dd{z} &= -\lim_{n\to\infty} \sum_{\alpha=1}^{n} f(z_{\alpha})(z_{\alpha}-z_{\alpha-1})\\
                &= \lim_{n\to\infty} \sum_{\alpha=1}^{n} f(z_{\alpha})(z_{\alpha-1}-z_{\alpha})\\
                &= \int_{-\gamma} f(z) \dd{z}.
            \end{align*}
            This proves the first statement.
            
            An alternative proof of this statement can be given by parametrising the contour.
            Consider a parametrisation of \(\gamma\) by some real variable \(t\in(0, 1)\) and notice that \(-\gamma\) is then parametrised by the same parametrisation with \(1 - t'\) where \(t'\in(0, 1)\).
            The end points are inverted but it is the same set of points.
            Hence
            \begin{align*}
                \int_{-\gamma} f(z) \dd{z} &= -\int_{t'=0}^{t'=1} f[\gamma(1 - t')]\gamma'(1 - t')\dd{t'}\\
                &= \int_{t'=1}^{t'=0} f[\gamma(1 - t')]\gamma'(1 - t')\dd{t'}
                \shortintertext{nows substituting \(1 - t' = t\)}
                &= -\int_{t=0}^{t=1} f[\gamma(t)]\gamma'(t)\dd{t}\\
                &= -\int_{\gamma} f(z)\dd{z}.
            \end{align*}
            This proves the property also.
            
            \item Let \(\gamma\) be parametrised by a real variable \(t\in[a, b]\).
            Let \(c\) be such that \(\gamma(t)\) corresponds to a point on \(\gamma_1\) if \(t\in(a, c)\) and a point on \(\gamma_2\) if \(t\in(c, b)\).
            The integrals of the real and imaginary parts of \(f\) behave like real integrals and we know for a real integral of some integrable function \(h\) on \((a, b)\) that
            \[\int_a^b h(t)\dd{t} = \int_a^c h(t) \dd{t} + \int_c^b h(t) \dd{t}\]
            where \(a \le c \le b\).
            Applying this to the real and complex parts of the integral of \(f\) we have
            \[\int_a^b f[\gamma(t)]\gamma'(t) = \int_a^c f[\gamma_1(t)]\gamma_1'(t)\dd{t} + \int_c^b f[\gamma_1(t)]\gamma_2'(t)\dd{t}.\]
            Hence
            \[\int_\gamma f(z) \dd{z} = \int_{\gamma_1} f(z) \dd{z} + \int_{\gamma_2} f(z)\dd{z}.\]
            This proves the second property.
            
            \item For the final property we have
            \begin{align*}
                \int_{\gamma_2} f(z) \dd{z} &= \int_{a'}^{b'} f[\gamma_2(t)]\gamma_2'(t)\dd{t}\\
                &= \int_{a'}^{b'} f\{g[\gamma_1(t)]\}\dv{g[\gamma_1(t)]}{t}\dd{t}\\
                &= \int_{a'}^{b'} f\{g[\gamma_1(t)]\}\dd{g[\gamma_1(t)]}
                \shortintertext{making the substitution \(g[\gamma_2(t)] \to \gamma_1(t)\) we have \(\dd{t'} = \dd{g[\gamma_2]}\) so we get}
                &= \int_a^b f[\gamma_1(t')]\gamma_1'(t)\dd{t'}\\
                &= \int_{\gamma_1} f(z) \dd{z}.
            \end{align*}
            This proves the third property.
        \end{enumerate}
    \end{proof}
    
    \subsubsection{Evaluating Integrals Examples}
    With these properties we are finally ready for some examples.
    \begin{example}\label{exa:integral 1}
        \textit{
            Let \(f(z) = z^2\).
            Find the integral
        }
            \[\int_{\gamma} z^2 \dd{z}\]
        \textit{
            where \(\gamma\) is one of the following contours:
        }
        \begin{enumerate}[label=\textit{\arabic*.}]
            \item \textit{a straight line segment from \(0\) to \(1 + i\),}
            \item \textit{two straight line segments from \(0\) to 1 and from 1 to \(1 + i\).}
        \end{enumerate}

        \begin{enumerate}
            \item We can parametrise the first contour as \(\gamma(t) = t(1 + i)\) with \(t\in(0, 1)\).
            Then \(\gamma'(t) = 1 + i\), which is non-zero as required.
            The integral is then
            \[\int_\gamma z^2 \dd{z} = \int_0^1 [t(1 + i)]^2(1 + i) \dd{t} = (1 + i)^3\int_0^1 t^2\dd{t} = (1 + i)^3\left[\frac{1}{3}t^3\right]_0^1 = (1 + i)^3\frac{1}{3} = \frac{-2 + 2i}{3}.\]
            
            \item The second contour can be parametrised in two parts by \(\gamma_1(t) = t\) for \(t\in(0, 1)\) and \(\gamma_2(t) = 1 + it\) for \(t\in(0, 1)\).
            The derivatives of the contours are \(\gamma_1'(t) = 1\) and \(\gamma_2'(t) = i\) which are both non-zero as required.
            Integrating over these contours we have
            \[\int_{\gamma_1} z^2\dd{z} = \int_0^1 t^2 \dd{t} = \frac{1}{3}\]
            and
            \[\int_{\gamma_2} z^2 \dd{z} = \int_0^1 (1 + it)^2i\dd{t} = i\int_0^t (1 - t^2 + 2it)\dd{t} = -1 + \frac{2i}{3}.\]
            Thus the integral along the whole contour is
            \[\int_{\gamma_1}z^2\dd{z} + \int_{\gamma_2}z^2\dd{z} = \frac{-2 + 2i}{3}.\]
        \end{enumerate}
        Notice that both contours gave the same result.
        This is not the case in general as we will see in the next example.
    \end{example}
    \begin{example}\label{exa:integral 2}
        \textit{
            Let \(f(z) = 1/z\).
            Find the integral
        }
            \[\int_{\gamma} \frac{1}{z} \dd{z}\]
        \textit{
            where \(\gamma\) is one of the following contours
        }
        \begin{enumerate}[label=\textit{\arabic*.}]
            \item \textit{\(\gamma_1\), the upper semicircle from \(-1\) to 1,}
            \item \textit{\(\gamma_2\), the lower semicircle from \(-1\) to 1.}
        \end{enumerate}
        \begin{enumerate}
            \item \(\gamma_1\) can be parametrised as \(\gamma_1(t) = e^{it}\) where \(t\in(0, \pi)\).
            Note that for the direction to be from \(-1\) to 1 we need to start at \(t = \pi\).
            The derivative of this contour parametrisation is \(\gamma'(t) = ie^{it}\) which is non-zero on \((0, \pi)\) as required.
            The integral is then
            \[\int_{\gamma_1} \frac{1}{z}\dd{z} = \int_{\pi}^{0} \frac{1}{e^{it}}ie^{it}\dd{t} = i\in_\pi^0 \dd{t} = -i\pi.\]
            
            \item \(\gamma_2\) can be parametrised as \(\gamma_2(t) = e^{it}\) where \(t\in(-\pi, 0)\).
            The derivative of this contour parametrisation is \(\gamma'(t) = ie^{it}\) which is non-zero on \((-\pi, 0)\) as required.
            The integral is then
            \[\int_{\gamma_2} \frac{1}{z}\dd{z} = \int_{-\pi}^{0} \frac{1}{e^{it}}ie^{it}\dd{t} = i\in_{-\pi}^0 \dd{t} = i\pi.\]
        \end{enumerate}
        We see that the value of the integral depends on the contour chosen.
    \end{example}
    \begin{example}\label{exa:integral 3}
        \textit{
            Let \(f(z) = \abs{z}^2\).
            Find the integral
        }
            \[\int_\gamma f(z)\dd{z}\]
        \textit{
            where \(\gamma\) is one of the following contours
        }
        \begin{enumerate}[label=\textit{\arabic*.}]
            \item \textit{\(\gamma_1\), a straight segment from \(-1\) to \(i\),}
            \item \textit{\(\gamma_2\), a \(\pi/2\) circular arc of radius 1 from \(-1\) to \(i\).}
        \end{enumerate}
        \begin{enumerate}
            \item \(\gamma_1\) can be parametrised as \(\gamma_1(t) = -1 + (1 + i)t\) with \(t\in(0, 1)\).
            The derivative of this contour parametrisation is \(\gamma_1'(t) = 1 + i\) which is non-zero as required.
            The integral is then
            \[\int_{\gamma_1} \abs{z}^2 = \int_0^1 \abs{t - 1 + it}(1 + i)\dd{t} = (1 + i)\int_0^1 [(t - 1)^2 + t^2] \dd{t} = \frac{2}{3}(1 + i).\]
            
            \item \(\gamma_2\) can be parametrised as \(\gamma_2(t) = e^{it}\) where \(t\in(\pi/2, \pi)\).
            Note that for the direction to be from \(-1\) to \(i\) we need to start at \(t = \pi\).
            The derivative of this contour parametrisation is \(\gamma'(t) = ie^{it}\) which is non-zero on \((\pi/2, \pi)\) as required.
            The integral is then
            \[\int_{\gamma_2} \abs{z}^2\dd{z} = \int_{\pi}^{\pi/2} \abs{e^{it}}^2 ie^{it} \dd{t} = \int_{\pi}^{\pi/2} ie^{it} \dd{t} = i + 1.\]
        \end{enumerate}
        Again we see that the result depends on the contour.
    \end{example}
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \begin{subfigure}{0.4\textwidth}
            \centering
            \tikzsetnextfilename{integral-example-1}
            \begin{tikzpicture}[
                    axis/.style={very thick, ->},
                    point/.style={fill=black}
                ]
%                \tikzstyle{contour} = [ultra thick, color={#1}]
%                \tikzstyle{axis} = [very thick, ->]
%                \tikzstyle{point} = [fill=black]
                \draw[axis] (0, -1.5) -- (0, 1.5) node[above] {\(\Im\)};
                \draw[axis] (-1.5, 0) -- (1.5, 0) node[right] {\(\Re\)};
                \draw[ultra thick, red] (0, 0) -- (1, 1);
                \draw[ultra thick, red, ->] (0, 0) -- (0.5, 0.5);
                \draw[ultra thick, blue] (0, 0) -- (1, 0);
                \draw[ultra thick, blue, ->] (0, 0) -- (0.5, 0);
                \draw[ultra thick, blue] (1, 0) -- (1, 1);
                \draw[ultra thick, blue, ->] (1, 0) -- (1, 0.5);
                \draw[point] (0, 0) circle[radius=0.05cm];
                \draw[point] (1, 1) circle[radius=0.05cm];
            \end{tikzpicture}
            \caption{The contours in example~\ref{exa:integral 1}}
        \end{subfigure}
        \begin{subfigure}{0.4\textwidth}
            \centering
            \tikzsetnextfilename{integral-example-2}
            \begin{tikzpicture}[
                    axis/.style={very thick, ->},
                    point/.style={fill=black}
                ]
%                \tikzstyle{contour} = [ultra thick, color={#1}]
%                \tikzstyle{axis} = [very thick, ->]
%                \tikzstyle{point} = [fill=black]
                \draw[axis] (0, -1.5) -- (0, 1.5) node[above] {\(\Im\)};
                \draw[axis] (-1.5, 0) -- (1.5, 0) node[right] {\(\Re\)};
                \draw[ultra thick, red] (-1, 0) arc(180:0:1);
                \draw[ultra thick, red, ->] (-1, 0) arc(180:135:1);
                \draw[ultra thick, red, ->] (-1, 0) arc(180:45:1);
                \draw[ultra thick, blue] (-1, 0) arc(-180:0:1);
                \draw[ultra thick, blue, ->] (-1, 0) arc(-180:-135:1);
                \draw[ultra thick, blue, ->] (-1, 0) arc(-180:-45:1);
                \draw[point] (-1, 0) circle[radius=0.05cm];
                \draw[point] (1, 0) circle[radius=0.05cm];
            \end{tikzpicture}
            \caption{The contours in example~\ref{exa:integral 2}}
        \end{subfigure}
        \begin{subfigure}{0.4\textwidth}
            \centering
            \tikzsetnextfilename{integral-example-3}
            \begin{tikzpicture}[
                axis/.style={very thick, ->},
                point/.style={fill=black}
                ]
%                \tikzstyle{contour} = [ultra thick, color={#1}]
%                \tikzstyle{axis} = [very thick, ->]
%                \tikzstyle{point} = [fill=black]
                \draw[axis] (0, -1.5) -- (0, 1.5) node[above] {\(\Im\)};
                \draw[axis] (-1.5, 0) -- (1.5, 0) node[right] {\(\Re\)};
                \draw[ultra thick, red] (-1, 0) -- (0, 1);
                \draw[ultra thick, red, ->]  (-1, 0) -- (-0.5, 0.5);
                \draw[ultra thick, blue] (-1, 0) arc(180:90:1);
                \draw[ultra thick, blue, ->] (-1, 0) arc(180:135:1);
            \end{tikzpicture}
            \caption{The contours in example~\ref{exa:integral 2}}
        \end{subfigure}
    \tikzexternaldisable
    \end{figure}
    
    \section{Cauchy's Integral Theorem}
    \subsection{Bounding Integrals}
    \begin{lemma}{Integral bound}{integral bound}
        Let \(\gamma\) be a contour and let \(f\) be a piecewise continuous function on \(\gamma\).
        Then
        \[\abs{\int_{\gamma} f(z) \dd{z}} \le \int_{\gamma} \abs{f(z) \dd{z}} = \int_{\gamma} \abs{f(z)}\abs{\dd{z}}.\]
    \end{lemma}
    \begin{proof}
        Let
        \[I = \int_\gamma f(z) \dd{z}.\]
        Since this is a complex integral in general \(I\in\complex\).
        Therefore we can write \(I\) as \(I = Re^{i\vartheta}\).
        This lemma is interested in providing a bound on \(R = \abs{I}\).
        Note that \(e^{-i\vartheta}I = e^{-i\vartheta}Re^{i\vartheta} = R\) and that \(\abs{e^{i\vartheta}} = 1\).
        Then
        \begin{align*}
            \abs{\int_{\gamma} f(z) \dd{z}} &= e^{i\vartheta} \int_\gamma f(z) \dd{z}\\
            &= \int_{\gamma} e^{-i\vartheta} f(z) \dd{z}.
        \end{align*}
        The integral in the last step is real since it is equal to the absolute value of another integral.
        This means we can take the real part without changing anything so
        \begin{align*}
            \abs{\int_{\gamma} f(z) \dd{z}} &= \Re\left[\int_\gamma e^{-i\vartheta} f(z)\dd{z}\right]\\
            &= \int_{\gamma} \Re[e^{-i\vartheta} f(z)\dd{z}]
        \end{align*}
        Now we use \(\Re(z) \le \abs{z}\) from the first point of theorem~\ref{lem:modulus inequalities} and we get
        \begin{align*}
            \abs{\int_{\gamma} f(z) \dd{z}} &\le \int_\gamma \abs{e^{-i\vartheta}f(z)\dd{z}}\\
            &= \int_{\gamma} \abs{f(z) \dd{z}}\\
            &= \int_{\gamma} \abs{f(z)} \abs{\dd{z}}.
        \end{align*}
    \end{proof}
    Note that we have to take the absolute value of the measure, \(\dd{z}\), for this inequality to hold.
    This will be important in the next lemma.
    Consider
    \[\int_{\gamma} \abs{\dd{z}}\]
    for some contour \(\gamma\).
    Appealing to the definition of the integral this is simply
    \[\int_{\gamma} \abs{\dd{z}} = \lim_{N\to\infty} \sum_{i=1}^{N}\abs{z_{i} - z_{i-1}}.\]
    That is the sum of the length of all of the segments of the contour, which when summed just gives the length of the contour, \(L\).
    
    \begin{lemma}{ML lemma}{ML lemma}
        Let \(\gamma\) be a contour on \(\complex\) with length \(L\).
        Let \(f\) be a function that is piecewise continuous on \(\gamma\).
        Let \(M\) be a real constant that bounds \(\abs{f(z)}\) on \(\gamma\).
        That is for all \(z\in\gamma\) \(M \ge \abs{f(z)}\).
        Then
        \[\abs{\int_\gamma f(z)\dd{z}} \le ML.\]
    \end{lemma}
    \begin{proof}
        By lemma~\ref{lem:integral bound} we know that
        \[\abs{\int_\gamma f(z)\dd{z}} \le \int_{\gamma} \abs{f(z)} \abs{\dd{z}}.\]
        Clearly if we replace \(\abs{f(z)}\) with \(M\) the value of the integral can only increase.
        Therefore
        \[\abs{\int_\gamma f(z)\dd{z}} \le \int_{\gamma} M\abs{\dd{z}} = M\int_{\gamma} \abs{\dd{z}} = ML.\]
    \end{proof}
    
    \begin{example}
        \textit{Let \(\alpha\in\reals\). Show, using integral bounds, that \(\abs{\exp(2\pi\alpha i) - 1} \le 2\pi\abs{\alpha}\).}
        
        If \(\alpha = 0\) then equality holds.
        Therefore assume \(\alpha \ne 0\).
        We consider
        \[\int_{\gamma}e^{i\alpha z}\dd{z}\]
        where \(\gamma\) is a straight line from \(0\) to \(2\pi\).
        Applying a bound to the integral we have
        \[\abs{\int_{\gamma} e^{i\alpha z}\dd{z}} \le \int_{\gamma} \abs{e^{-i\alpha z}\dd{z}} = \int_0^{2\pi} \abs{e^{i\alpha t}}\dd{t} = \int_0^{2\pi}\dd{t} = 2\pi.\]
        Evaluating the integral instead gives
        \[\abs{\int_{\gamma} e^{i\alpha z}\dd{z}} = \abs{\int_0^{2\pi} e^{i\alpha t}\dd{t}} = \abs{\left[\frac{1}{i\alpha} e^{i\alpha z}\right]_0^{2\pi}} = \abs{\frac{1}{\alpha}}\abs{e^{2\pi i\alpha} - 1}.\]
        Comparing these we have
        \[\abs{e^{2i\alpha} - 1} \le 2\pi\abs{\alpha}.\]
    \end{example}
    
    \begin{example}
        \textit{Let \(\gamma\) be a circle of radius \(R\).
        Estimate the following limits:}
        \[\lim_{R\to\infty} \oint_{\gamma} \frac{z^2}{z^4 + 1}\dd{z}, \qquad\text{and}\qquad \lim_{R\to 0} \oint_{\gamma} \frac{z^2}{z^4 + 1}\dd{z}.\]
        We can parametrise \(\gamma\) as \(\gamma(t) = Re^{it}\) for \(t\in(0, 2\pi)\).
        Therefore \(\gamma'(t) = iRe^{it}\) which is non-zero as required.
        We will also need another result that we can derive from the third point of theorem~\ref{lem:modulus inequalities} which states that for \(\alpha, \beta\in\complex\) 
        \[\abs{\alpha - \beta} \ge \abs{\abs{\alpha} - \abs{\beta}}.\]
        Inverting this we have
        \[\frac{1}{\abs{\alpha - \beta}} \le \frac{1}{\abs{\abs{\alpha} - \abs{\beta}}}.\]
        We can now bound the integrals.
        \begin{align*}
            \abs{\oint_{\gamma} \frac{z^2}{z^4 + 1} \dd{z}} &\le \oint_{\gamma} \abs{\frac{z^2}{z^4 + 1} \dd{z}}\\
            &= \oint_{\gamma} \frac{\abs{z^2}}{\abs{z^4 + 1}}\abs{\dd{z}}\\
            &= \int_0^{2\pi} \frac{R^2e^{2it}}{\abs{R^4e^{4it} + 1}}\abs{Re^it\dd{t}}\\
            &= \int_0^{2\pi} \frac{R^3}{\abs{R^4e^{4it} + 1}}\dd{t}.
        \end{align*}
        Considering the specific case \(R\to\infty\) we have
        \begin{align*}
            \lim_{R\to\infty} \abs{\oint_{\gamma} \frac{z^2}{z^4 + 1} \dd{z}} &\le \lim_{R\to\infty} \int_0^{2\pi} \frac{R^3}{\abs{R^4e^{4it} + 1}}\dd{t}\\
            &\le \lim_{R\to\infty} \int_0^{2\pi} \frac{R^3}{\abs{R^4e^{4it}} - \abs{1}} \dd{t}\\
            &= \lim_{R\to\infty} \frac{R^3}{R^4 - 1} \int_0^{2\pi} \dd{t}\\
            &= \lim_{R\to\infty} \frac{2\pi R^3}{R^4 - 1}\\
            &= 0.
        \end{align*}
        Here we have used \(1 = -(-1)\) and the inequality we derived at the start of the example.
        Similarly considering \(R\to 0\) we have
        \begin{align*}
            \lim_{R\to 0} \abs{\oint_{\gamma} \frac{z^2}{z^4 + 1} \dd{z}} &\le \lim_{R\to 0} \int_0^{2\pi} \frac{R^3}{\abs{R^4e^{4it} + 1}}\dd{t}\\
            & \le \lim_{R\to 0} \int_0^{2\pi} \frac{R^3}{\abs{1} - \abs{R^4e^{4it}}}\dd{t}\\
            &= \lim_{R\to 0} \frac{R^3}{1 - R^3} \int_0^{2\pi} \dd{t}\\
            &=\lim_{R\to 0} \frac{2\pi R^3}{1 - R^4}\\
            &= 0.
        \end{align*}
    \end{example}
    \subsection{The Fundamental Theorem of Calculus}
    Previously we saw that the value of an integral depends on the contour.
    We have also seen an example where this wasn't the case.
    In this section we will establish conditions on a function such that its integral between two points is independent of the contour.
    \begin{definition}{Antiderivative}{}
        Let \(S\) be a region of \(\complex\) and let \(f\) be a continuous function on \(S\).
        We say that \(F\colon S\to\complex\) is the \define{antiderivative} of \(f\) if for all \(z\in S\) \(F'(z) = f(z)\).
    \end{definition}
    Notice that this means that \(F\) must be differentiable on \(S\) which in turn means that \(F\) must be analytic inside \(S\) but not necessarily on the border.
    
    For example \(f(z) = z^2\) has as an antiderivative \(F(z) = z^3/3\).
    The function \(F(z) = \log z\) is in general \emph{not} the antiderivative of \(f(z) = 1/z\) as to make \(F\) single valued and therefore a valid function we have to make a branch cut.
    This means that \(F\) is only an antiderivative of \(1/z\) on regions that don't surround the origin.
    
    \begin{theorem}{Fundamental theorem of calculus}{ftc}
        Let \(S\) be an open region in \(\complex\) and let \(f\colon S\to\complex\) be continuous.
        Then the following statements are equivalent:
        \begin{enumerate}
            \item \(f\) has an antiderivative, \(F\), on \(S\).
            \item Let \(\gamma\) and \(\gamma'\) be arbitrary contours in \(S\) such that both have the same endpoints.
            Then
            \[\int_\gamma f(z) \dd{z} = \int_{\gamma'} f(z)\dd{z}.\]
            \item For any given closed contour \(\gamma\) in \(S\)
            \[\oint_{\gamma} f(z) \dd{z} = 0.\]
        \end{enumerate}
    \end{theorem}
    \begin{proof}
        We will start by proving that the first statement implies the second.
        Suppose there exists a function, \(F\), such that \(F\) is the antiderivative of \(f\).
        Let \(\gamma\) be a contour parametrised by some real variable, \(t\) and let \(\gamma\) have endpoints \(t_i\) and \(t_f\).
        Applying the chain rule we have
        \[[F(\gamma(t))]' = F'[\gamma(t)]\gamma'(t) = f(\gamma(t))\gamma'(t)\]
        having used the definition \(F'(z) = f(z)\).
        We can write \(F(\gamma(t)) = U(t) + iV(t)\) where \(U, V\colon\reals\to\reals\) and satisfy the real fundamental theorem of calculus.
        Therefore
        \begin{align*}
            \int_\gamma f(z) \dd{z} &= \int_{t_i}^{t_f} f[\gamma(t)]\gamma'(t)\dd{t}\\
            &= \int_{t_i}^{t_f} [F(\gamma(t))]'\dd{t}\\
            &= \int_{t_i}^{t_f} [U + iV(t)]'\dd{t}\\
            &= [U(t) + iV(T)]_{t_i}^{t_f}\\
            &= F[\gamma(t_f)] - F[\gamma(t_f)].
        \end{align*}
        This depends only on the endpoints of \(\gamma\) proving that the existence of the antiderivative implies the equality of integrals over different contours.
        
        Next we will prove that the second statement proves the third.
        Combining this with the first part of this proof this also proves that the first statement implies the third by transitivity of implication.
        Let \(\gamma_1\) and \(\gamma_2\) be contours joining points \(a\) and \(b\) in \(S\).
        Then if we start at \(a\) and first traverse \(\gamma_1\) we get to \(b\) and the traversing \(\gamma_2\) backwards takes us back to \(a\) so \(\gamma = \gamma_1 - \gamma_2\) is a closed contour.
        Assuming that the integral over any contour from \(a\) to \(b\) is the same we have
        \begin{align*}
            0 &= \int_{\gamma_1} f(z)\dd{z} - \int_{\gamma_2} f(z)\dd{z}\\
            &= \int_{\gamma_1} f(z) \dd{z} + \int_{-\gamma_2} f(z)\dd{z}\\
            &= \oint_{\gamma} f(z) \dd{z}.
        \end{align*}
        Hence independence of contours leads to all integrals over a closed contour being zero.
        
        Next we will show that the third statement implies the second.
        Let \(\gamma\) be a closed contour and choose \(a, b\in\gamma\) such that \(\gamma\) is split into two contours, \(\gamma_1\) and \(-\gamma_2\).
        Then by hypothesis the integral over \(\gamma\) is zero so
        \begin{align*}
            0 &= \oint_{\gamma} f(z)\dd{z}\\
            &= \int_{\gamma_1} f(z) \dd{z} + \int_{-\gamma_2} f(z)\dd{z}\\
            &= \int_{\gamma_1} f(z) \dd{z} - \int_{\gamma_2} f(z)\dd{z}
        \end{align*}
        so
        \[\int_{\gamma_1} f(z)\dd{z} = \int_{\gamma_2 f(z)}\dd{z}.\]
        
        Finally we need to prove that either of the second two statements implies the first.
        Let \(\gamma\) be some contour with endpoints \(z_0\) and \(z\).
        Parametrise \(\gamma\) with some real variable \(\zeta\).
        Assuming that the integral is independent of the contour chosen the following definition of a function, \(F\), is well defined as it depends only on the endpoints of the contour.
        \[F(z) = \int_{z_0}^{z} f(\zeta) \dd{\zeta}.\]
        To show the first statement holds we need to show \(F'(z) = f(z)\) for all \(z\in S\).
        To do this we appeal to the definition of the derivative.
        First we write
        \begin{align*}
            F(z + \Delta z) - F(z) &= \int_{z_0}^{z + \Delta z} f(\zeta)\dd{\zeta} - \int_{z_0}^{z} f(\zeta)\dd{\zeta}\\
            &= \int_{z}^{z + \Delta z} f(\zeta)\dd{\zeta}.
        \end{align*}
        We now use a trick of adding zero to get
        \[\int_{z}^{z + \Delta z} f(\zeta)\dd{\zeta} = \int_z^{z + \Delta z} f(z) - f(z) + f(\zeta)\dd{\zeta}.\]
        We now divide by \(\Delta z\) and get
        \begin{align*}
            \frac{F(z + \Delta z) - F(z)}{\Delta z} &= \frac{1}{\Delta z} \int_{z}^{z + \Delta z} f(z) - f(z) + f(\zeta)\dd{\zeta}\\
            &= \frac{f(z)}{\Delta z}\int_{z}^{z + \Delta z}\dd{\zeta} + \frac{1}{\Delta z} \int_{z}^{z + \Delta z} f(\zeta) - f(z)\dd{\zeta}\\
            &= \frac{f(z)}{\Delta z}\Delta z + \frac{1}{\Delta z} \int_{z}^{z + \Delta z} f(\zeta) - f(z)\dd{\zeta}\\
            &= f(z) + \frac{1}{\Delta z} \int_{z}^{z + \Delta z} f(\zeta) - f(z)\dd{\zeta}.
        \end{align*}
        We now take a limit as \(\Delta z \to 0\) and we have
        \[\lim_{\Delta z \to 0} \frac{F(z + \Delta z) - F(z)}{\Delta z} = f(z) + \lim_{\Delta z\to 0} \frac{1}{\Delta z}\int_{z}^{z + \Delta z} f(\zeta) - f(z)\dd{\zeta}.\]
        We see that if the limit on the right hand side vanishes then we will be left with \(F'(z) = f(z)\) which is what we want.
        To show that this integral does indeed vanish we use the ML lemma (lemma~\ref{lem:ML lemma}).
        Since \(S\) is open and \(\Delta z \to 0\) we are safe to assume that \(z + \Delta z\in \discOpen{z}{\delta}\) for some \(\delta > 0\) and that \(D\subseteq S\).
        We are free to choose any contour as by hypothesis the integral does not depend on the contour.
        Therefore we choose a straight line from \(z\) to \(z + \Delta z\).
        The length of this contour is \(L = \abs{\Delta z}\).
        
        Since \(f\) is continuous in \(S\), and therefore continuous in \(D\), by definition of continuity if \(\abs{z - z_0} < \delta\) for some \(\delta > 0\) then there exists \(\varepsilon>0\) such that \(\abs{f(z) - f(z_0)} < \varepsilon\).
        Specifically if \(\delta\) is allowed to be arbitrarily small then \(\varepsilon\) can become arbitrarily small.
        We choose a \(\delta\) which is slightly bigger than \(\abs{\Delta z}\) and this means that \(\abs{f(\zeta) - f(z)} < \varepsilon\) for some \(\varepsilon\).
        Let \(M = \varepsilon\) as clearly this bounds \(\abs{f(\zeta) - f(z)}\).
        Then by the ML lemma
        \[\abs{\lim_{\Delta z\to 0} \frac{1}{\Delta z} \int_z^{z + \Delta z} f(\zeta) - f(z)\dd{z}} \le \lim_{\Delta z\to 0}\frac{\varepsilon\abs{\Delta z}}{\Delta z} = \lim_{\Delta z\to 0}\varepsilon = 0.\]
        This proves that
        \[f(z) = \lim_{\Delta z\to 0} \frac{F(z + \Delta z) - F(z)}{\Delta z} = F'(z).\]
    \end{proof}
    
    \subsection{Cauchy's Integral Theorem}
    The fundamental theorem of calculus (theorem~\ref{thm:ftc}) tells us that if \(f\colon S\subseteq\complex\to\complex\) is continuous then it has an antiderivative if and only if all of its closed contour integrals vanish.
    However in general there are an infinite number closed contours and checking them all is not possible.
    Fortunately there is another theorem that we will prove in this section which tells us exactly when this is the case.
    
    \begin{definition}{Simply connected region}{}
        Let \(S\subseteq\complex\) be an open region.
        We say that \(S\) is \define{simply connected} if any path between two points in \(S\) can be continuously transformed into any other path with the same endpoints without leaving \(S\).
        Equivalently \(S\) is \define{simply connected} if any closed path inside \(S\) can be contracted into a point without leaving \(S\).
    \end{definition}
    Intuitively \(S\) is simply connected if it connected has no holes.
    This is because for us to deform a path to a path on the other side of a hole we would have to either jump over the hole, breaking the continuity condition, or leave \(S\).
    
    \begin{definition}{Simple contour}{}
        A contour, \(\gamma\), is a \define{simple contour} if it does not intersect itself.
    \end{definition}
    We are now ready for perhaps the most important theorem of this course.
    
    \begin{theorem}{Cauchy's integral theorem}{cauchy's integral theorem}
        Let \(S\) be an open, simply connected region.
        Let \(f\colon S\to\complex\) be analytic in \(S\) and let \(f'(z)\) be continuous in \(S\).
        Then for any given closed contour \(\gamma\)
        \[\oint_{\gamma} f(z) \dd{z} = 0.\]
    \end{theorem}
    \begin{proof}
        We assume without loss of generality that \(\gamma\) is a simple contour.
        If this is not the case and \(\gamma\) has a finite number of self intersections then we can split \(\gamma\) at each self intersection into two separate contours and the following applies to each sub-contour individually.
        If \(\gamma\) intersects itself an infinite number of times then this theorem can be proven using an auxiliary contour that only intersects the original at its endpoints.
        This produces two simple contours and then by the fundamental theorem of calculus (theorem~\ref{thm:ftc}) it is possible to prove that Cauchy's theorem also holds for the original contour.
        
        Any simple closed contour divides \(\complex\) into two simply connected components\footnote{while stated here as an obvious fact this is actually known as the Jordan curve theorem and is actually not very easy to prove.}.
        Let \(S'\) be the interior of this curve.
        For this proof we will use the \(\reals^2\) version of Green's theorem which states that if \(P, Q\colon\reals^2\to\reals\) are \(C^1\) functions on a simply connected region, \(\tilde{S}\) then on a simple closed contour, \(\partial \tilde{S}\), bounding \(\tilde{S}\) we have
        \begin{align*}
            \oint_{\partial \tilde{S}} (P(\vv{r})\vh{x} + Q(\vv{r})\vh{y}) \cdot \dd{r} &= \oint_{\partial \tilde{S}} [P(x, y)\dd{x} + Q(x, y)\dd{y}]\\
            &= \iint_{\tilde{S}} \left[\pdv{Q}{x} - \pdv{P}{y}\right]\dd{x}\dd{y}.
        \end{align*}
        Since \(f'\) is continuous by hypothesis its real and imaginary parts, \(u,v\colon\reals^2\to\reals\), individually are \(C^1\) and satisfy the conditions for Green's theorem to apply.
        Thus
        \begin{align*}
            \oint_{\gamma} f(z) \dd{z} &= \oint_{\gamma} [u(x, y) + iv(x, y)](\dd{x} + i\dd{y})\\
            &= \oint_{\gamma} [u(x, y)\dd{x} - v(x, y)\dd{y}] + i\oint_{\gamma} [u(x, y)\dd{y} + v(x, y)\dd{x}].
        \end{align*}
        Applying Green's theorem to the real part of the integral and also the Cauchy--Riemann relations we have
        \begin{align*}
            \oint_{\gamma} [u(x, y)\dd{x} - v(x, y)\dd{y}] &= \iint_{S'} \left[-\pdv{v}{x} - \pdv{u}{y}\right]\dd{x}\dd{y}\\
            &= \iint_{S'} \left[-v_x - u_y\right]\dd{x}\dd{y}\\
            &= \iint_{S'} \left[u_y - u_y\right]\dd{x}\dd{y}\\
            &= 0.
        \end{align*}
        Applying Green's theorem to the imaginary part of the integral and also the Cauchy--Riemann relations we have
        \begin{align*}
            \oint_{\gamma} [v(x, y)\dd{x} + u(x, y)\dd{y}] &= \iint_{S'} \left[\pdv{u}{x} - \pdv{v}{y}\right]\dd{x}\dd{y}\\
            &= \iint_{S'} \left[u_x - v_y\right]\dd{x}\dd{y}\\
            &= \iint_{S'} \left[u_x - u_x\right]\dd{x}\dd{y}\\
            &= 0.
        \end{align*}
        So we find that
        \[\oint_\gamma f(Z) \dd{z} = 0.\]
    \end{proof}
    
    This result is useful but the condition that \(f'\) is continuous is actually be dropped as analyticity is such a strict condition.
    The theorem then requires a different proof as we can no longer use Green's theorem directly.
    Instead the approach to proving this theorem is similar to the proof of Green's theorem.
    This version of the theorem is often called the Cauchy--Goursat theorem.
    \begin{theorem}{Cauchy--Goursat theorem}{cauchy-goursat}
        Let \(S\) be an open simply connected region and let \(f\colon S\to\complex\) be analytic in \(S\).
        Then for any given closed contour \(\gamma\)
        \[\oint_{\gamma} f(z) \dd{z} = 0.\]
    \end{theorem}
    \begin{proof}
        Again we assume without loss of generality that \(\gamma\) is a simple contour.
        We also assume that it is oriented anticlockwise.
        Let \(S'\) be the region bounded by \(\gamma\).
        We split \(S\) into a grid of smaller square regions each with a contour, \(\gamma_i\), as a border.
        Where one of these squares intersects \(\gamma\) we take \(\gamma_i\) as the square border inside \(S'\) and the contour \(\gamma\) as the border where the square would leave \(S'\).
        
        We now consider the sum of the integrals over each \(\gamma_i\).
        We use the fact that every edge of a square is traversed in both directions and so the contributions cancel.
        Since the number of squares is finite we have
        \[\sum_{i}\oint_{\gamma_i} f(z)\dd{z} = \oint_{\gamma} f(z) \dd{z}.\]
        For each square contour we now define the following function
        \[
            \delta_i(z) = 
            \begin{cases}
                [f(z) - f(z_i)]/[z - z_i] - f'(z_i), & z \ne z_i\\
                0, & z = z_i
            \end{cases}
        \]
        where \(z_i\) is an arbitrary fixed point in \(\gamma_i\).
        In the limit \(z\to z_i\) the fraction in the definition of \(\delta_i\) approaches \(f'(z)\).
        Since \(f\) is analytic \(f'\) exists not only at \(z_i\) but in a neighbourhood of \(z_i\).
        Therefore we can choose our square contours in such a way that
        \[\abs{\frac{f(z) - f(z_i)}{z - z_i} - f'(z_i)}\le \varepsilon\]
        for some arbitrarily small \(\varepsilon>0\) simply by choosing sufficiently small squares.
        From this we can write
        \[f(z) = f(z_i) + f'(z_i)(z - z_i) + (z - z_i)\delta_i(z)\]
        for some \(z\in\gamma_i\).
        Hence
        \begin{align*}
            \oint_{\gamma_i} f(z)\dd{z} &= \oint_{\gamma_i} f(z_i)\dd{z} + \oint_{\gamma_i} f'(z_i)(z - z_i)\dd{z} + \oint_{\gamma_i} (z - z_i)\delta_i(z) \dd{z}\\
            &= f(z_i)\oint\gamma_i \dd{z} + f'(z_i)\oint_{\gamma_i}(z - z_i)\dd{z} + \oint(z - z_i)\delta_i(z)\dd{z}.
        \end{align*}
        The first two integrals vanish as the integrands satisfy the conditions of Cauchy's integral theorem (theorem~\ref{thm:cauchy's integral theorem}).
        The third integral can be bounded.
        If we take the side of one of the squares to be \(l_i\) then \(\gamma_i\) is at most as long as \(4l_i\).
        Also \(\abs{z - z_i} < \sqrt{2}l_i\) as the furthest two points in a square can be is diagonally opposite.
        The length of \(\gamma_i\) is then less that \(4l_i + L_i\) where \(L_i\) is the length of the portion of \(\gamma\) that is contained in \(\gamma_i\) for squares on the boundary.
        Therefore by the \nameref{lem:ML lemma}.
        \[\abs{\oint_{\gamma_i} (z - z_i)\delta_i(z)\dd{z}} \le \sqrt{2}l_i\varepsilon(4l_i + L_i).\]
        This means that
        \begin{align*}
            \abs{\oint_{\gamma} f(z) \dd{z}} &= \abs{\sum_{i} \oint_{\gamma_i} f(z) \dd{z}}
            \shortintertext{applying the triangle inequality for multiple summands this becomes}
            &\le \sum_{i} \abs{\oint_{\gamma_i} f(z) \dd{z}}\\
            &\le \sum_{i} \sqrt{2}l_i\varepsilon(4l_i + L_i).
        \end{align*}
        Now notice that
        \[\sum_{i}l_i^2 = A\]
        is the total area of the internal squares and that
        \[\sum_i L_i = L\]
        is the length of \(\gamma\).
        Since \(L_i\) is zero for internal squares we can perform this sum only for external squares.
        Therefore
        \begin{align*}
            \sum_{i} l_i(4l_i + L_i) &= 4\sum_{\text{int}~i} l_i^2 + \sum_{\text{ext}~i} l_iL_i\\
            &= 4A + L\sqrt{A}.
        \end{align*}
        Since we can make \(\varepsilon\) arbitrarily small and the length of a smooth contour is finite we have
        \[\abs{\oint_{\gamma} f(z)\dd{z}} \le \sqrt{2}\varepsilon(4A + L\sqrt{A}) \to 0.\]
        And since the absolute value must be non-negative we have
        \[\oint_{\gamma} f(z) \dd{z} = 0.\]
    \end{proof}
    This proof worked because analyticity is such a strict condition.
    While we lost the condition that \(f'\) be continuous we were able to use analyticity to construct \(\delta_i\) which is continuous and plays the role of \(f'\) in this proof.
    
    \section{Consequence's of the Cauchy--Goursat Theorem}
    \subsection{Deformation Theorem}
    \begin{theorem}{Deformation theorem}{deformation}
        Let \(S\) be an open region and let \(\gamma_1\) and \(\gamma_2\) be positively oriented closed contours in \(S\).
        Let \(f\colon S\to\complex\) be analytic in the region between the two contours.
        Then
        \[\oint_{\gamma_1} f(z)\dd{z} = \oint_{\gamma_2}\dd{z}.\]
    \end{theorem}
    \begin{proof}
        Without loss of generality we can assume that the contours do not intersect.
        Consider the contours shown in figure~\ref{fig:contour for deformation theorem}.
        Choose two points, \(z_1\) on \(\gamma_1\) and \(z_2\) on \(\gamma_2\).
        Take an arbitrary contour \(\overline{z_1z_2}\) from \(z_1\) to \(z_2\) such that this contour remains entirely in the region where \(f\) is analytic.
        \begin{figure}[ht]
            \centering
            \tikzexternalenable
            \tikzsetnextfilename{deformation-theorem-contour}
            \begin{tikzpicture}
                \tikzstyle{region} = [fill=#1, fill opacity=0.3, ultra thick]
                \draw[fill=red, fill opacity=0.3, ultra thick, use Hobby shortcut, closed=true] (0, 0) .. (2, 1) .. (3, 0) .. (4, 4) .. (1, 3) .. (0,3);
                \draw[fill=white, fill opacity=0.3, ultra thick, use Hobby shortcut, closed=true, fill opacity=1] (0, 1) .. (1, 1.5) .. (3, 1) .. (4, 3) .. (1, 2) .. (0, 1);
                \draw[ultra thick] (0, 0) -- (0, 1);
                \node[above right] at (4, 4) {\(\gamma_1\)};
                \node[below left] at (4, 3) {\(\gamma_2\)};
                \node[above] at (0.2, 1) {\(z_2\)};
                \node[below] at (0, 0) {\(z_1\)};
                \draw[->] (-0.2, 0.2) -- (-0.2, 0.8);
                \draw[->] (0.2, 0.8) -- (0.2, 0.2);
            \end{tikzpicture}
            \tikzexternaldisable
            \caption{Two closed, non-intersecting contours with \(f\) analytic on the red region.}
            \label{fig:contour for deformation theorem}
        \end{figure}
        Construct the auxiliary contour
        \[\gamma = \gamma_1 + \overline{z_1z_2} - \gamma_2 + \overline{z_2z_1}.\]
        Since \(\gamma\) encloses a region where \(f\) is analytic the integral along \(\gamma\) must be zero by the Cauchy--Goursat theorem (theorem~\ref{thm:cauchy-goursat}).
        Hence
        \begin{align*}
            0 &= \oint_\gamma f(z)\dd{z}\\
            &= \oint_{\gamma_1} f(z)\dd{z} + \int_{\overline{z_1z_2}} f(z)\dd{z} + \oint_{-\gamma_2} f(z) \dd{z} + \int_{\overline{z_2z_1}} f(z)\dd{z}\\
            &= \oint_{\gamma_1} f(z)\dd{z} + \int_{\overline{z_1z_2}} - \oint_{\gamma_2} f(z)\dd{z} - \int_{\overline{z_1z_2}} f(z)\dd{z}\\
            &= \oint_{\gamma_1} f(z)\dd{z} - \oint_{\gamma_2} f(z)\dd{z}.
        \end{align*}
        So
        \[\oint_{\gamma_1} f(z)\dd{z} = \oint_{\gamma_2} f(z)\dd{z}.\]
    \end{proof}
    \begin{example}
        Let \(f(z) = 1/z\). Let \(\gamma_1\) be the positively oriented unit circle, \(\abs{z} = 1\), and let \(\gamma_2\) be any arbitrary contour containing the origin.
        Combining the two contours in example~\ref{exa:integral 2} we see that
        \[\oint_{\gamma_1}\frac{1}{z}\dd{z} = 2\pi i.\]
        Using the deformation theorem (theorem \ref{thm:deformation}) since \(1/z\) is analytic for all \(z \ne 0\) and \(0\) is not between the two contours we have
        \[\oint_{\gamma_2} \frac{1}{z}\dd{z} = \oint_{\gamma_1}\frac{1}{z} \dd{z} = 2\pi i.\]
    \end{example}
    
    \subsection{Cauchy's Integral Formula}
    \begin{theorem}{Cauchy's Integral Formula}{cif}
        Let \(\gamma\) be a closed, positively oriented contour.
        Let \(S\) be an open, simply connected region containing \(\gamma\).
        Let \(f\colon S\to\complex\) be analytic on \(S\).
        Let \(z_0\) be any point inside \(\gamma\).
        Then
        \[f(z_0) = \frac{1}{2\pi i} \oint_{\gamma} \frac{f(z)}{z - z_0} \dd{z}.\]
    \end{theorem}
    \begin{proof}
        Since \(f\) and \(z - z_0\) are analytic on \(S\) the only point where \(f(z)/(z - z_0)\) is not analytic is \(z = z_0\).
        Let \(\gamma_\varepsilon\) be the contour consisting of the circle centred on \(z_0\) with radius \(\varepsilon\), that is \(\abs{z - z_0} = \varepsilon\).
        Since \(f\) is analytic in the region between \(\gamma\) and \(\gamma_\varepsilon\) we have
        \begin{align*}
            \int_{\gamma} \frac{f(z)}{z - z_0} \dd{z} &= \oint_{\gamma_\varepsilon} \frac{f(z)}{z - z_0}\dd{z}\\
            &= \oint_{\gamma_\varepsilon} \frac{f(z_0) + f(z) - f(z_0)}{z - z_0}\dd{z}\\
            &= \oint_{\gamma_\varepsilon} \frac{f(z_0)}{z - z_0} \dd{z} + \oint_{\gamma_\varepsilon} \frac{f(z) - f(z_0)}{z - z_0}\dd{z}.
        \end{align*}
        Since \(f(z_0)\) is a constant the first integral is
        \begin{align*}
            \oint_{\gamma_\varepsilon} \frac{f(z_0)}{z - z_0} \dd{z} &= f(z_0) \oint_{\gamma_\varepsilon} \frac{1}{z - z_0}\dd{z}\\
            &= f(z_0) 2\pi i.
        \end{align*}
        We can bound the second integral.
        Consider the parametrisation \(\gamma_\varepsilon(\vartheta) = z_0 + \varepsilon e^{i\vartheta}\) for \(\vartheta\in[0, 2\pi]\).
        \(\gamma_\varepsilon'(\vartheta) = i\varepsilon e^{i\vartheta}\ne 0\), therefore
        \begin{align*}
            \abs{\oint_{\gamma_\varepsilon} \frac{f(z) - f(z_0)}{z - z_0}\dd{z}} &\le \oint_{\gamma
            _\varepsilon} \abs{\frac{f(z) - f(z_0)}{z - z_0}} \abs{\dd{z}}\\
            &= \int_0^{2\pi} \abs{\frac{f(z) - f(z_0)}{(z_0 + \varepsilon e^{i\vartheta}) - z_0}}\abs{i\varepsilon e^{i\vartheta}} \dd{\vartheta}\\
            &= \int_{0}^{2\pi} \abs{\frac{f(z) - f(z_0)}{\varepsilon e^{i\vartheta}}} \abs{i\varepsilon e^{i\vartheta}}\dd{\vartheta}\\
            &= \int_0^{2\pi} \abs{f(z) - f(z_0)}\abs{i}\dd{\vartheta}\\
            &= \int_0^{2\pi} \abs{f(z) - f(z_0)} \dd{\vartheta}.
        \end{align*}
        Since \(f\) is analytic it is also continuous which means there exists arbitrarily small \(\delta > 0\) such that by choosing a sufficiently small \(\varepsilon\) we have \(\abs{f(z) - f(z_0)} < \delta\).
        Thus
        \[\abs{\oint_{\gamma_\varepsilon} \frac{f(z) - f(z_0)}{z - z_0}\dd{z}} \le \int_0^{2\pi} \abs{f(z) - f(z_0)}\dd{\vartheta} \le 2\pi\delta \to 0\qquad\text{as}\qquad \varepsilon\to 0.\]
        Therefore
        \[\oint_{\gamma} \frac{f(z)}{z - z_0}\dd{z} = 2\pi i f(z_0).\]
    \end{proof}
    This is a very strong result.
    It tells us that the values of an analytic function inside a simply connected region are completely determined by the values of the function on the boundary no matter how large the region.
    We can use this result to compute many integrals without needing to integrate properly.
    The general process for this is as follows:
    \begin{enumerate}
        \item Plot the contour.
        \item Find the singularities of \(f\) inside the contour.
        \item Split the contour into smaller pieces each containing at most one singularity.
        \item Evaluate each sub-contour separately by re-expressing \(f(z)\) as
        \[f(z) = \frac{g(z)}{z - z_0}.\]
        \item Add the values of all contours being careful to consider directions so that the required parts cancel.
    \end{enumerate}
    This will be demonstrated with the next few examples.
    \begin{example}
        \textit{Let \(f(z) = \cos(z)/z\). Evaluate}
        \[\oint_{\gamma} f(z)\dd{z}\]
        \textit{where \(\gamma\) is the circle \(\abs{z - 4} = 5.\)}
        
        The only singularity that \(f\) has is \(z = 0\) which is contained in \(\gamma\).
        We can write \(f\) as
        \[f(z) = \frac{\cos z}{z} = \frac{g(z)}{z}\]
        where \(g(z) = \cos(z)\).
        We can directly apply Cauchy's integral formula then:
        \[\oint_{\gamma} \frac{\cos z}{z - 0} \dd{z} = 2\pi_i g(0) = 2\pi i\cos(0) = 2\pi i.\]
    \end{example}
    \begin{example}
        \textit{Let \(f(z) = z^2/(z^2 + 1)\). Evaluate}
        \[\oint_\gamma f(z) \dd{z}\]
        \textit{where \(\gamma\) is the circle \(\abs{z - i} = 1\).}
        
        First notice that
        \[f(z) = \frac{z^2}{(z + i)(z - i)}\]
        so \(z = \pm i\) are the only singularities of \(f\).
        Of these singularities \(z = i\) is the only singularity inside the contour.
        Therefore
        \[g(z) = \frac{z^2}{z + i}\]
        is analytic inside \(\gamma\).
        We can then directly apply Cauchy's integral formula:
        \begin{align*}
            \oint_{\gamma} \frac{z^2}{z^2 + 1} \dd{z} &= \oint_{\gamma} \frac{g(z)}{z - i}\dd{z}\\
            &= 2\pi ig(i)\\
            &= 2\pi i\frac{i^2}{i + i}\\
            &= -\pi.
        \end{align*}
    \end{example}
    \begin{example}
        \textit{Let \(f(z) = \cos(\pi z) / (z^2 - 1)\). Evaluate}
        \[\oint_{\gamma}f(z)\dd{z}\]
        \textit{where \(\gamma\) is the circle \(\abs{z} = 2\).}
        
        \(f\) has two singularities, \(z = \pm 1\).
        Both of these lie inside \(\gamma\).
        We split \(\gamma\) into two parts, \(\gamma_1\) and \(\gamma_2\) such that \(\gamma_1 + \gamma_2 = \gamma\).
        One way to do this is shown in figure~\ref{fig:cif example contour}.
        \begin{figure}[ht]
            \centering
            \tikzexternalenable
            \tikzsetnextfilename{contour-for-cif-example}
            \begin{tikzpicture}
                \tikzstyle{contour} = [ultra thick]
                \tikzstyle{axis} = [thick]
                \draw[axis, ->] (0, -3) -- (0, 3) node[above] {\(\Im\)};
                \draw[axis, ->] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[contour] (0, 0) circle[radius=2cm];
                \draw[contour] (0, 2) -- (0, -2);
                \draw[contour, ->] (1.4105, 1.41) -- (1.41, 1.4105);
                \draw[contour, ->] (-1.41, 1.4105) -- (-1.4105, 1.41);
                \draw[->] (0.2, 0.5) -- (0.2, -0.5);
                \draw[->] (-0.2, -0.5) -- (-0.2, 0.5);
                \draw[fill] (1, 0) circle[radius=0.05cm] node[below] {\(1\)};
                \draw[fill] (-1, 0) circle[radius=0.05cm] node[below] {\(-1\)};
            \end{tikzpicture}
            \tikzexternaldisable
            \caption{One possible way to split the contour into two parts.}
            \label{fig:cif example contour}
        \end{figure}
        Notice that the part of the contour that appears in both sub-contours is in opposite directions and so that part of the integral cancels.
        We can now write
        \[f(z) = \frac{\cos(\pi z)}{z^2 - 1} = \frac{\cos(\pi z)}{(z + 1)(z - 1)}.\]
        Considering first the sub-contour, \(\gamma_+\), containing \(z = 1\) we can write
        \[f(z) = \frac{g_+(z)}{z - 1}, \qquad\text{where}\qquad g_+(z) = \frac{\cos(\pi z)}{z + 1}\]
        and so using Cauchy's integral formula
        \[\oint_{\gamma_+} \frac{\cos(\pi z)}{z^2 - 1} \dd{z} = \oint_{\gamma_+} \frac{g_+(z)}{z - 1} \dd{z} = 2\pi ig_+(1) = 2\pi i\frac{\cos(\pi)}{1 + 1} = -\pi i.\]
        Similarly considering the sub-contour, \(\gamma_-\), containing \(z = -1\) we can write
        \[f(z) = \frac{g_-(z)}{z + 1}, \qquad\text{where}\qquad g_-(z) = \frac{\cos(\pi z)}{z - 1}.\]
        Using Cauchy's integral formula we have
        \[\oint_{\gamma_-} \frac{\cos(\pi z)}{z^2 - 1}\dd{z} = \oint_{\gamma_-} \frac{g_-(z)}{z + 1}\dd{z} = 2\pi ig_-(-1) = 2\pi i\frac{\cos(-\pi)}{-1 - 1} = i\pi.\]
        Hence
        \[\oint_{\gamma}f(z) \dd{z} = \oint_{\gamma_+}f(z)\dd{z} + \oint_{\gamma_-} f(z)\dd{z} = -i\pi + i\pi = 0.\]
    \end{example}
    
    \section{More Consequences of the Cauchy--Goursat Theorem}
    \subsection{Generalised Cauchy's Integral Formula}
    \begin{theorem}{Generalised Cauchy's Integral Formula}{}
        Let \(\gamma\) be a closed, positively oriented contour.
        Let \(S\) be an open, simply connected region containing \(\gamma\).
        Let \(f\colon S\to\complex\) be analytic on \(S\).
        Let \(z_0\) be any point inside \(\gamma\).
        Then
        \[f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_{\gamma} \frac{f(z)}{(z - z_0)^{n+1}}\dd{z}.\]
    \end{theorem}
    \begin{proof}
        First consider the case of \(n = 1\).
        Applying Cauchy's integral formula to the definition of the derivative we have
        \begin{align*}
            f'(z_0) &= \lim_{\Delta z \to 0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z}\\
            &= \frac{1}{2\pi i} \lim_{\Delta z \to 0} \frac{1}{\Delta z} \left[ \oint_{\gamma} \frac{f(z)}{z - (z_0 + \Delta z)}\dd{z} - \oint_{\gamma} \frac{f(z)}{z - z_0}\dd{z}\right]\\
            &= \frac{1}{2\pi i} \lim_{\Delta z \to 0} \frac{1}{\Delta z}\oint_\gamma \left[ \frac{f(z)}{z - (z_0 + \Delta z)} - \frac{f(z)}{z - z_0}\right] \dd{z}\\
            &= \frac{1}{2\pi i} \lim_{\Delta z \to 0} \frac{1}{\Delta z}\oint_\gamma \frac{[z - z_0]f(z) - [z - (z_0 + \Delta z)]f(z)}{(z - (z_0 + \Delta z))(z - z_0)} \dd{z}\\
            &= \frac{1}{2\pi i} \lim_{\Delta z \to 0} \frac{1}{\Delta z}\oint_\gamma \frac{f(z)\Delta z}{(z - (z_0 + \Delta z))(z - z_0)}\dd{z}\\
            &= \frac{1}{2\pi i} \lim_{\Delta z \to 0} \oint_\gamma \frac{f(z)}{(z - (z_0 + \Delta z))(z - z_0)}\dd{z}\\
            &= \frac{1}{2\pi i} \oint_{\gamma} \frac{f(z)}{(z - z_0)^2}\dd{z}.
        \end{align*}
        So Cauchy's generalised integral formula holds for \(n = 1\).
        
        This can be extended inductively to prove the theorem.
    \end{proof}
    \begin{example}\label{exa:integral 1/z-a}
        \textit{Let \(\gamma\) be a positively oriented closed contour and let \(a\) be a point inside \(\gamma\). Then for \(n\in\integers\) evaluate}
        \[\oint_\gamma (z - a)^{-n-1}\dd{z}.\]
        If \(n < 0\) then the integrand is analytic and so the integral vanishes by the Cauchy--Goursat theorem (theorem~\ref{thm:cauchy-goursat}).
        If \(n \ge 0\) we can use the generalised Cauchy integral formula for the \(n\)th derivative:
        \[
            \oint_\gamma \frac{1}{(z - a)^{n + 1}} = \frac{2\pi i}{n!} \eval{\dv[n]{z}(1)}_{z=a} = 
            \begin{cases}
                2\pi i, & \qif*n = 0,\\
                0, & \qif*n \ne 0.
            \end{cases}
        \]
    \end{example}
    Cauchy's integral formula leads to the following corollary:
    \begin{corollary}{}{analytic functions smooth}
        Let \(S\) be an open region and let \(f\colon S\to\complex\) be analytic on \(S\).
        Then for all \(z\in S\) the all derivatives at \(z\) exist and are analytic.
        We say that \(f\) is \define{smooth} or \(C^\infty\).
    \end{corollary}
    \begin{proof}
        This follows immediately from Cauchy's integral formula for derivatives which we can apply since \(f\) is analytic.
        Since \(S\) is open for any \(z\in S\) there exists a simple closed contour satisfying the necessary conditions for Cauchy's integral formula to apply.
        By the hypothesis since \(f\) is analytic \(f'\) exists.
        We can then use Cauchy's integral formula for the second derivative to construct \(f''\) in that neighbourhood.
        Therefore \(f'\) is analytic.
        Assume now that \(f^{(k)}\) is analytic.
        Then this means that \(f^{(k+1)}\) exists.
        Cauchy's integral formula then allows us to construct \(f^{(k+2)}\) so \(f^{(k + 1)}\) is analytic.
        Thus by mathematical induction \(f^{(n)}\) is analytic for all \(n\in\naturals\) which means that \(f\) is smooth.
        We can also conclude that all partial derivatives of \(u = \Re(f)\) and \(v = \Im(f)\) exists and are continuous.
    \end{proof}
    
    \subsection{Liouville's Theorem}
    \begin{theorem}{Liouville's Theorem}{liouville}
        Let \(f\colon\complex\to\complex\) be a bounded, entire function.
        Then \(f\) is constant
    \end{theorem}
    \begin{proof}
        By hypothesis there exists \(M\in\reals_{>0}\) such that \(\abs{f(z)} \le M\) for all \(z\in\complex\).
        We can use Cauchy's integral formula on a circular contour, \(\gamma\), of radius \(R\) to bound \(f'\):
        \begin{align*}
            \abs{f'(z)} &= \abs{\frac{1}{2\pi i} \oint_{\gamma} \frac{f(\zeta)}{(\zeta - z)^2} \dd{\zeta}}\\
            &= \frac{1}{2\pi} \abs{\oint_\gamma \frac{f(\zeta)}{(\zeta - z)^2} \dd{\zeta}}\\
            &\le \frac{1}{2\pi} \oint_\gamma \abs{\frac{f(\zeta)}{(\zeta - z)^2}\dd{\zeta}}\\
            &= \frac{1}{2\pi} \int_0^{2\pi} \frac{\abs{f(Re^{i\vartheta})}}{\abs{Re^{i\vartheta} - z}^2} R\dd{\vartheta}\\
            &\le \frac{1}{2\pi} \int_0^{2\pi} \frac{MR}{(R - \abs{z}^2)^2}\dd{\vartheta}\\
            &= \frac{MR}{(R - \abs{z})^2}\\
            &\sim \frac{1}{R}
        \end{align*}
        This vanishes independently of \(z\) since we can take \(R\) to be arbitrarily large.
        Hence \(f'(z) = 0\) which means \(f(z)\) is constant.
    \end{proof}
    The contrapositive\footnote{If \(P\implies Q\) then \(\neg Q\implies \neg P\) is a logically equivalent statement called the contrapositive.} of this theorem is often more useful:
    \addtocounter{theoremCounter}{-1}
    \begin{theorem}{Liouville's Theorem (Contrapositive)}{}
        If \(f\) is non-constant, entire function then there exists \(z\in\complex^*\) such that \(f(z)\) diverges.
    \end{theorem}
    We can use this to prove the fundamental theorem of algebra.
    \begin{theorem}{Fundamental Theorem of Algebra}{}
        Let \(P_n\) be a polynomial of degree \(n \ge 1\) with complex coefficients (\(P_n\in\complex[z]\)).
        Then \(P_n\) has \(n\) roots, \(z_i\), including repeated roots, for which \(P_n(z_i) = 0\).
    \end{theorem}
    \begin{proof}
        Suppose that \(P_n\) has no roots.
        Then \(P_n(z)\ne 0\) for all \(z\in\complex\).
        Hence \(1/P_n(z)\) is entire since \(P_n\) is entire.
        Let \(\zeta\in\complex\) be the minimum of \(P_n\).
        Then \(\abs{1/P_n(z)} \le \abs{1/P_n(\zeta)}\) for all \(z\in\complex\).
        Hence by Liouville's theorem (theorem~\ref{thm:liouville}) \(1/P_n\) is constant which can only be the case if \(P_n\) is constant which it clearly isn't.
        Thus \(P_n\) has at least one root.
        Call this root \(z_1\).
        Then we can factorise \(P_n\) as
        \[P_n(z) = (1 - z_1)Q_{n-1}(z)\]
        where \(Q_{n-1}\in\complex[z]\) is a polynomial of order \(n-1\).
        
        Suppose now that \(P_{k}\in\complex[z]\) is a \(k\)th order polynomial for some \(k\in\naturals\) and has \(k\) roots .
        Hence \(P_{k+1}\in\complex[z]\) is a polynomial of order \(k+1\) and has at least \(k\) roots.
        Consider
        \[f(z) = \frac{\prod_{i=1}^{k}(z - z_i)}{P_n(z)}\]
        where \(z_i\) are the the \(k\) roots of \(P_k\) assumed to exist.
        The function above is analytic almost everywhere except at the point \(z\) where \(f(z) \sim (a_{k+1}z)^-1\to 0\) as \(z\to\infty\).
        The other singularities cancel with the numerator.
        Since \(a_{k+1}\ne 0\) (as \(P_{k+1}\) must have a \(z^{k+1}\) term to be of order \(k + 1\)) we must have that \(P_{k+1}\) has another root meaning it has \(k + 1\) roots.
    \end{proof}
    
    \begin{theorem}{Morera's Theorem}{}
        Let \(S\) be an open region and let \(f\colon S\to\complex\) be continuous on \(S\).
        Suppose that
        \[\int_\gamma f(z) \dd{z} = 0\]
        for all contours \(\gamma\) contained in \(S\).
        Then \(f\) is analytic.
    \end{theorem}
    \begin{proof}
        The fundamental theorem of calculus (theorem~\ref{thm:ftc}) means that
        \[\oint_\gamma f(z)\dd{z} = 0\]
        for all \(\gamma\) is equivalent to \(f\) having an antiderivative, \(F\), such that \(f(z) = F'(z)\forall z\in S\).
        This is true for all \(z\) in \(S\) so \(F\) is analytic.
        By corollary~\ref{cor:analytic functions smooth} the derivative of an analytic function is also analytic so \(f = F'\) is analytic.
    \end{proof}
    This theorem is the converse of the Cauchy--Goursat theorem.
    
    \part{Series}
    \section{Sequences and Series}
    \begin{definition}{Sequence}{}
        A \define{sequence} is a function whose domain is an interval of integers, i.e. \(a\colon[\alpha, \beta]\intersection\integers\to X\).
    \end{definition}
    This is a very formal and broad definition.
    For our use we are mostly interested in (one-sided) infinite sequences of complex numbers.
    In this case a sequence is a function \(a\colon \integers_{\ge0} \to \complex\).
    
    \begin{notation*}{}
        If \(a\colon\integers_{\ge0}\to\complex\) is an infinite complex sequence (henceforth a sequence) then we write \(a_n = a(n)\) and denote the whole sequence as \(\{a_n\} = \{a_0, a_1, \dotsc\} = \{a_n\}_{n=0}^{\infty}\).
    \end{notation*}
    Sequences are naturally ordered by \(n\) and the order is important, this means \(\{1, 2, 3, \dotsc\}\ne \{2, 1, 3, \dotsc\}\).
    There are two common ways to define a sequence.
    We could give an explicit formula as a function of \(n\), for example \(a_n = n\) corresponds to the sequence \(\{0, 1, 2, \dotsc\}\).
    Or we could give a recursive definition such as \(a_n = a_{n-1} + 1\) and \(a_0 = 0\), this also corresponds to \(\{0, 1, 2, \dotsc\}\).
    
    \begin{definition}{Convergence (Sequences)}{}
        A sequence, \(\{a_n\}\), \define{converges} to a value \(a\in\complex\) if for all \(\varepsilon>0\) there exists \(N\in\integers_{\ge0}\) such that for all \(n \ge N\)
        \[\abs{a_n - a} < \varepsilon.\]
    \end{definition}
    \begin{notation*}{}
        If \(\{a_n\}\) is a sequence and converges to \(a\) then we write
        \[a = \lim_{n\to\infty} a_n, \qquad\text{or}\qquad \{a_n\}\to a.\]
    \end{notation*}
    \begin{example}
        Consider the sequence defined by \(a_n = (n + 1)^{-1}\).
        This converges to 0.
        To show this we need to find a value of \(N\), which is in general a function of \(\varepsilon\) such that the convergence definition is satisfied for a given \(\varepsilon\).
        The convergence criteria is
        \[\abs{a_n - a} < \varepsilon \implies \abs{\frac{1}{n + 1} - 0} = \frac{1}{n + 1} < \varepsilon.\]
        Rearranging we have
        \[n > \frac{1}{\varepsilon} - 1.\]
        Thus we choose \(N\) to be the smallest integer satisfying this, that is \(N = \lceil 1/\varepsilon\rceil - 1\).
        Having found \(N\) we now check that the convergence criteria are satisfied.
        Let \(n \ge N = \lceil 1/\varepsilon \rceil - 1\).
        Then
        \[\abs{a_n - 0} = \abs{\frac{1}{n + 1}} < \abs{\frac{1}{(1/\varepsilon - 1) + 1}} = \abs{\frac{1}{1/\varepsilon}} = \abs{\varepsilon} = \varepsilon.\]
        So the convergence definition is satisfied and
        \[\lim_{n\to\infty} \frac{1}{n + 1} = 0.\]
    \end{example}
    Not being mathematicians we aren't that interested in proving convergence and often simply assume convergence.
    
    \begin{definition}{Limit Point (Sequence)}{}
        Let \(\{a_n\}\) be a sequence. We say that \(l\) is a \define{limit point} of \(\{a_n\}\) if for all \(\varepsilon>0\) there exists at least one \(n\in\integers_{\ge 0}\) such that \(a_n\in\discPunctured{l}{\varepsilon}\).
    \end{definition}
    Note that the disc is punctured.
    This means that terms of a sequence aren't automatically limit points.
    Consider the sequence defined by \(a_n = n\).
    A punctured disc of radius \(0.1\) placed at \(1\) doesn't contain any points in \(\{a_n\}\) and so \(1\) is not a limit point of \(\{a_n\}\).
    Even sequences which don't converge can have limit points.
    For example the sequence defined by
    \[a_n = (-1)^n\frac{n}{n + 1}\]
    oscillates between \(\pm 1\) so doesn't converge but both \(\pm 1\) are limit points.
    
    \begin{definition}{Series}{}
        A \define{series}, \(S\), is the formal sum of all the elements of a sequence.
    \end{definition}
    \begin{definition}{Partial Sum}{}
        The \(n\)th \define{partial sum} of the sequence \(\{a_n\}\) is
        \[S_n = \sum_{j=1}^{n} a_j = a_0 + a_1 + \dotsb + a_n.\]
    \end{definition}
    \begin{definition}{Convergence (Series)}{}
        The series
        \[\sum_{j=0}^{\infty} a_j\]
        \define{converges} to \(S\) if the sequence \(\{S_n\}\) of partial sums,
        \[\sum_{j=0}^{n} a_n,\]
        converges to \(S\).
    \end{definition}
    \begin{definition}{Absolute Convergence}{}
        A complex series,
        \[\sum_{j=0}^{\infty} a_n,\]
        is \define{absolutely convergent} if the real series,
        \[\sum_{j=0}^{\infty} \abs{a_n},\]
        converges.
    \end{definition}
    If a complex series is absolutely convergent it is also convergent.\footnote{The property of a metric space that all absolutely convergent series are convergent is called completeness and is a key property of a Hilbert space.}
    \begin{definition}{Uniform Convergence}{}
        Let \(\{a_n\}\) be a sequence depending on \(z\).
        Let \(\{S_n\}\) be the sequence of partial sums of \(\{a_n\}\).
        Let \(S = \sum_{i=1}^{\infty} a_n\) be a convergent series.
        Then \(S\) is a \define{uniformly convergent} series if for arbitrary \(\varepsilon > 0\) there exists \(N\) such that for all \(n \ge N\) we have \(\abs{S_n - S} < \varepsilon\).
        That is \(S\) converges independent of the value of \(z\).
    \end{definition}
    Intuitively the terms of a uniformly convergent series get closer and closer to the value the series converges to.
    Uniform convergence is an important condition as it allows us to do things like exchange integrals and infinite sums or integrals and derivatives without changing anything.
    We often assume this is ok in physics but if the objects involved aren't uniformly convergent then it may not be.
    
    \subsection{Convergence Tests}
    Proving convergence is often not that easy but there are convergence tests that can sometimes be helpful.
    In the following take \(\{a_n\}\) to be a convergent sequence.
    \begin{itemize}
        \item If
        \[\lim_{n\to\infty} a_n \ne 0\]
        then \(\sum a_n\) diverges.
        \item \emph{Comparison Test:} If \(\sum \abs{b_n}\) converges and there exists \(N\in\integers_{\ge0}\) such that for all \(n > N\) we have \(\abs{a_n} < \abs{b_n}\) then \(\sum \abs{a_n}\), and hence \(\sum a_n\), converges.
        \item \emph{Ratio Test:} Let
        \[l = \lim_{n\to\infty} \abs{\frac{a_{n+1}}{a_n}}.\]
        If \(l < 1\) then \(\sum a_n\) converges absolutely.
        If \(l > 1\) then \(\sum a_n\) diverges.
        If \(l = 1\) then no conclusion can be drawn.
        \item \emph{\(n\)th Root Test:} Let
        \[l = \lim_{n\to\infty} \sqrt[n]{a_n}.\]
        If \(l < 1\) then \(\sum a_n\) converges absolutely.
        If \(l > 1\) then \(\sum a_n\) diverges.
        If \(l = 1\) then no conclusion can be drawn.
        \item \emph{Weierstrass \(M\)-Test:} If \(a_n\) depends on \(z\) and there exists a sequence of non-negative, real numbers, \(\{M_n\}\), such that for all \(n \ge 1\) and for all \(z\in R\) we have \(\abs{a_n(z)} \le M_n\) and
        \[\sum_{n=1}^{\infty} M_n\]
        converges then
        \(\sum a_n\) converges absolutely and uniformly on the region \(R\).
    \end{itemize}
    
    \subsection{Geometric Series}
    A geometric series is a series defined by \(a_n = z^n\) for some \(z\in\complex\).
    Consider
    \begin{align*}
        S_n &= 1 + z + z^2 + \dotsc + z^{n-1} + z^n\\
        zS_n &= \hphantom{1 +} z + z^2 + z^3 + \dotsc + z^n + + z^{n+1}\\
        (1 - z)S_n &= 1 + z^{n+1}\\
        \implies S_n &= \frac{1 + z^{n+1}}{1 - z}.
    \end{align*}
    If \(\abs{z} > 1\) then this series diverges.
    If \(\abs{z} < 1\) then this series converges.
    The partial sums converge uniformly to \(1 / (1 - z)\) so
    \[S = \sum_{n=0}^{\infty} z^n = \frac{1}{1 - c}.\]
    
    \subsection{Taylor Series}
    \begin{theorem}{Taylor's Theorem}{}
        Let \(S\) be an open region and let \(f\colon S\to\complex\) be analytic.
        Let \(z_0\in S\) and let \(R\in[0, \infty)\) be the largest value such that the open disc, \(\discOpen{z_0}{R}\), centred on \(z_0\) and of radius \(R\), is contained entirely in \(S\).
        Then there exists a unique sequence, \(\{c_n\}\), such that
        \[f(z) = \sum_{n=0}^{\infty} c_n(z - z_0)^n.\]
        Further this series is uniformly convergent on the disc \(\discOpen{z_0}{R}\) and 
        \[c_n = \frac{1}{2\pi i}\oint_{\gamma} \frac{f(z)}{(z - z_0)^{n+1}}\dd{z} = \frac{f^{(n)}(z_0)}{n!}\]
        where \(\gamma\) is any positively oriented contour inside \(\discOpen{z_0}{R}\) and contains \(z_0\).
    \end{theorem}
    \begin{proof}
        For a given \(z\in\discPunctured{z_0}{R}\) we can choose a contour \(\gamma\) which is a a circle of radius \(r\) centred on \(z_0\) such that \(\abs{z - z_0} < r < R\).
        Since \(f(z)\) is analytic in this region we can apply Cauchy's integral formula:
        \[f(z) = \frac{1}{2\pi i}\oint_{\gamma} \frac{f(w)}{w - z}\dd{w}.\]
        Consider
        \[\frac{1}{w - z} = \frac{1}{w - z_0}\frac{1}{1 - \frac{z - z_0}{w - z_0}}\]
        since \(\abs{w - z_0} > \abs{z - z_0}\) we have \(\abs{(z - z_0)/(w - z_0)} < 1\) and so we recognise the second fraction as the value of a geometric series giving us
        \[\frac{1}{w - z} = \frac{1}{w - z_0} \sum_{n=0}\left(\frac{z - z_0}{w - z_0}\right)^n.\]
        Since the geometric series is uniformly convergent we could just substitute it directly into the integral and safely exchange the integral and sum.
        However we can also split the sum in two and after some manipulations we don't need to rely on uniform convergence.
        \begin{align*}
            \frac{1}{w - z} &= \frac{1}{w - z_0} \left[\sum_{n=0}^{N-1} \left(\frac{z - z_0}{w - z_0}\right) + \sum_{n=N}^{\infty}\left(\frac{z-z_0}{w - z_0}\right)^n\right]\\
            &= \frac{1}{w - z_0} \left[\sum_{n=0}^{N-1} \left(\frac{z - z_0}{w - z_0}\right) + \left(\frac{z - z_0}{w  - z_0}\right)^N\sum_{n=N}^{\infty}\left(\frac{z-z_0}{w - z_0}\right)^{n-N}\right]\\
            &= \frac{1}{w - z_0} \left[\sum_{n=0}^{N-1} \left(\frac{z - z_0}{w - z_0}\right) + \left(\frac{z - z_0}{w  - z_0}\right)^N\sum_{n=0}^{\infty}\left(\frac{z-z_0}{w - z_0}\right)^n\right]\\
            &= \frac{1}{w - z_0} \left[\sum_{n=0}^{N-1} \left(\frac{z - z_0}{w - z_0}\right) + \left(\frac{z - z_0}{w  - z_0}\right)^N\frac{1}{1 - \frac{z - z_0}{w - z_0}}\right]\\
            &= \frac{1}{w - z_0} \left[\sum_{n=0}^{N-1} \alpha^n + \frac{\alpha^N}{1 - \alpha}\right]\\
        \end{align*}
        where \(\alpha = (z - z_0)/(w - z_0)\).
        We can now substitute this into Cauchy's integral formula.
        Since the only sums involved are now finite then exchanging the integral and sum is valid as the integral is linear.
        \begin{align*}
            f(z) &= \frac{1}{2\pi i} \oint_{\gamma} \frac{f(w)}{w - z} \dd{w}\\
            &= \frac{1}{2\pi i} \oint_{\gamma} \frac{f(w)}{w - z_0} \left[\sum_{n=0}^{N - 1}\alpha^n + \frac{\alpha^N}{1 - \alpha}\right]\dd{w}\\
            &= \frac{1}{2\pi i} \sum_{n=0}^{N-1} \oint_{\gamma} \frac{f(w)\alpha^n}{w - z_0}\dd{w} + \frac{1}{2\pi i}\oint_{\gamma} \frac{f(w)\alpha^N}{(w - z_0)(1 - \alpha)}\dd{w}.
        \end{align*}
        We now take the limit of \(N \to \infty\) and we have
        \[f(z) = \frac{1}{2\pi i} \sum_{n=0}^{\infty} \oint_{\gamma} \frac{f(w)\alpha^n}{w - z_0}\dd{w}.\]
        The second integral vanishes in the limit as \(\abs{\alpha} < 1\).
        We can further simplify this first integral:
        \begin{align*}
            f(z) &= \frac{1}{2\pi i} \sum_{n=0}^{\infty} \oint_{\gamma} \frac{f(w)\alpha^n}{w - z_0}\dd{w}\\
            &= \frac{1}{2\pi i} \sum_{n=0}^{\infty} \oint_{\gamma} \frac{f(w)(z - z_0)^n}{(w - z_0)^{n+1}}\dd{w}\\
            &= \frac{1}{2\pi i} \sum_{n=0}^{\infty} (z - z_0)^n \oint_{\gamma} \frac{f(w)}{(w - z_0)^{n+1}}\dd{w}
        \end{align*}
        we can now apply Cauchy's integral formula for the \(n\)th derivative to this and we find
        \[f(z) = \sum_{n=0}^{\infty} (z - z_0)^n \frac{1}{2\pi i}\oint_{\gamma} \frac{f(w)}{(w - z_0)^{n+1}}\dd{w} = \sum_{n=0}^{\infty} \frac{f^{n}}{n!}(z - z_0)^n.\]
        Uniform convergence follows as the geometric series is uniformly convergent.
    \end{proof}
    Taylor series in complex analysis are very similar to the real Taylor series we are used to.
    That all analytic functions can be expressed as a Taylor series is sometimes taken as the definition of analyticity and then our definition of analyticity is referred to as being holomorphic.
    
    There are many properties we can now exploit to find Taylor series without having to compute terms individually.
    For example we can exploit the uniform convergence to find the Taylor series for \(f(z) = \log(1 + z)\).
    First note that
    \[f'(z) = \frac{1}{1 + z} = \frac{1}{1 - (-z)} = \sum_{n=0}^{\infty}(-z)^n.\]
    Integrating again and using uniform convergence to change the order of operations we have
    \[f(z) = \int \sum_{n=0}^{\infty} (-1)^nz^n\dd{z} = \sum_{n=0}^{\infty} (-1)^n \int z^n \dd{z} = \sum_{n=0}^{\infty} (-1)^n \frac{z^{n+1}}{n + 1}.\]
    Note that since \(z^n\) is a polynomial it is entire and therefore by the fundamental theorem of complex calculus has an antiderivative and the contour along which we integrate is therefore unimportant as the result depends only on its end points.
    
    Since \(\{c_n\}\) is unique for a given function and point \(z_0\) if we are expanding a function about a point in \(\reals\), most commonly 0, we can simply use the real Taylor series as we have defined functions such that restricting them to the real axis recovers the real definition.
    
    The radius of convergence, that is \(R\) as defined in the theorem, of a function which is analytic everywhere apart from at a set of singularities is simply the distance to the nearest singularity.
    For example
    \[f(z) = \frac{1}{1 + z^2}\]
    has two singularities at \(z = \pm i\).
    Therefore if we wish to expand this at \(z = 0\) then the radius of convergence is 1 as this is the distance to the nearest singularity.
    We can again exploit the geometric series and spot that
    \[f(z) = \frac{1}{1 - (-z^2)} = \sum_{n=0}^{\infty}(-z^2)^n\]
    which converges when \(\abs{z^2}< 1\) which means \(\abs{z} < 1\).
    
    \section{Laurent Series}
    \subsection{Isolated Singularities}
    Recall the definition of an isolated singularity:
    \begin{definition*}{Isolated singular point}{}
        Let \(f\colon S\to \complex\) be a function which is singular at \(z_0\in S\).
        We say \(z_0\) is an isolated singularity if there exists \(r > 0\) such that \(f\) is analytic on \(\discPunctured{z_0}{r}\).
    \end{definition*}
    For example:
    \begin{itemize}
        \item \(f(z) = 1/z\) has an isolated singularity at \(z = 0\) as \(f\) is analytic on \(\complex\setminus\{0\}\).
        \item \(f(z) = \cosec(z)\) has isolated singularities at \(z = n\pi\) for \(n\in \integers\).
        \item \(f(z) = 1/\sin(1/z)\) has a singularity at \(z = 0\) but this is not an isolated singularity.
        \(1/\sin(1/z)\) is singular whenever \(\sin(1/z) = 0\) which happens when \(1/z = n\pi\) for \(n\in \integers\).
        That is \(z = 1/2\pi n\).
        However this can be arbitrarily close to zero simply by choosing sufficiently large \(n\).
        This means that any disc centred on zero will also contain an infinite number of points of the form \(z = 1/2\pi n\).
        \item \(f(z) = \log z\) is multivalued.
        If we choose the principle branch \((-\pi\le \arg z \le\pi)\) then \(z = 0\) is not an isolated singularity as any disc centred on the origin will contain part of the branch cut.
    \end{itemize}
    
    \begin{theorem}{Laurent Series}{}
        Let \(f\colon D\to \complex\) be an analytic function on the open disc \(\discOpen{z_0}{\rho}\) except possibly at \(z = z_0\).
        Then we can expand \(f(z)\) as
        \[f(z) = \sum_{n=-\infty}^{\infty} c_n(z - z_0)^n\]
        where
        \[c_n = \frac{1}{2\pi i}\oint_{\gamma} \frac{f(w)}{(w - z_0)^{n+1}}\dd{w}\]
        for some positively orientated contour, \(\gamma\), contained in \(D\) such that the point \(z_0\) is inside \(\gamma\).
        The resulting series is called a Laurent series.
    \end{theorem}
    \begin{proof}
        The proof is similar to that of Taylor's theorem however we can't directly apply Cauchy's integral formula as we don't know if \(f\) is analytic at \(z_0\).
        Since \(\discOpen{z_0}{\rho}\) for \(z_0\ne z \in D\) we can choose \(r, R\in(0, \rho)\) such that
        \[0 < r < \abs{z - z_0} < R < \rho.\]
        Let \(\gamma_+\), \(\gamma_-\), \(\gamma_R\), and \(\gamma_r\) be the contours shown in figure~\ref{fig:laurent series proof contours}.
        By construction \(f\) is analytic inside \(\gamma_+\) and \(\gamma_-\).
        This allows us to apply Cauchy's integral formula to \(\gamma_+\) which gives us
        \[f(z) = \frac{1}{2\pi i}\oint_{\gamma_+} \frac{f(w)}{w - z}\dd{w}.\]
        Also \(f\) is analytic in \(\gamma_-\) and \(z\) is outside of \(\gamma_-\) so \(f(w)/(w - z)\) is analytic on \(\gamma_-\).
        Thus by Cauchy--Goursat's theorem
        \[0 = \frac{1}{2\pi i}\oint_{\gamma_-}\frac{f(w)}{w - z}\dd{w}.\]
        Hence
        \[f(z) = \frac{1}{2\pi i}\oint_{\gamma_+}\frac{f(w)}{w - z}\dd{w} + \frac{1}{2\pi i}\oint_{\gamma_-}\frac{f(w)}{w - z}\dd{z}.\]
        Now carefully considering these integrals and the contours they are along we see that the straight sections of the contours cancel out and we are left with an integral over the two circles.
        Notice that the integral over the inner circle is negatively orientated.
        Hence
        \[f(z) = \frac{1}{2\pi i} \int_{\gamma_R} \frac{f(w)}{w - z}\dd{w} - \int_{\gamma_r}\frac{f(w)}{w - z}\dd{w}.\]
        The contour integral around \(\gamma_R\) is the same as the integral that appears in the proof of Taylor's theorem.
        For this integral we have \(\abs{w - z_0} < \abs{z - z_0}\) and we get the following series:
        \[\frac{1}{2\pi i}\oint_{\gamma_R} \frac{f(w)}{w - z}\dd{w} = \sum_{n=0}^{\infty} \frac{(z - z_0)^n}{2\pi i} \oint_{\gamma_R}\frac{f(w)}{w - z}\dd{w}.\]
        On \(\gamma_r\) we can't do this as \(\abs{w - z_0} < \abs{z - z_0}\) so the geometric series that we used in the proof of Taylor's theorem doesn't converge.
        Instead we use the following which is valid when \(\abs{z} > \abs{w}\):
        \begin{align*}
            \frac{1}{w - z} &= \frac{1}{z(w/z - 1)}\\
            &= -\frac{1}{z} \frac{1}{1 - w/z}\\
            &= -\frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{w}{z} \right)^n\\
            &= -\frac{1}{z}\sum_{n=0}^{\infty} \left( \frac{w}{z} \right)^{-n}\\
            &= -\frac{1}{z}\sum_{n=-\infty}^{0} \left( \frac{z}{w} \right)^n\\
            &= -\sum_{n=-\infty}^{0} \frac{z^{n-1}}{w^n}\\
            &= -\sum_{n=-\infty}^{-1} \frac{z^{n}}{w^{n+1}}.
        \end{align*}
        This is still valid if we substitute \(z - z_0\) for \(z\) and \(w - z_0\) for \(w\) provided \(\abs{z - z_0} > \abs{w - z_0}\), as is the case on the contour \(\gamma_r\).
        Hence we have
        \[\frac{1}{2\pi i}\oint_{\gamma_r} \frac{f(w)}{w - z}\dd{w} = -\oint_{\gamma_r}\sum_{n=-\infty}^{-1}\frac{(z - z_0)^n}{2\pi i}\frac{f(w)}{(w - z_0)^{n+1}} \dd{w}.\]
        Since the sum is a convergent geometric series it is uniformly convergent and so we can swap the sum and the integral and we have
        \[f(z) = \sum_{n=0}^{\infty} \frac{(z - z_0)^n}{2\pi i} \oint_{\gamma_r} \frac{f(w)}{(w - z_0)^{n+1}} \dd{w} + \sum_{n = -\infty}^{-1} \oint_{\gamma_r} \frac{f(w)}{(w - z)^{n+1}}\dd{w}.\]
        By hypothesis the only possible singularity in these integrands is at \(z_0\) which is inside both contours.
        Therefore between the contours the integrands are perfectly analytic and we can use the deformation theorem to turn the integrals over \(\gamma_r\) and \(\gamma_R\) into integrals over some arbitrary contour, \(\gamma\), inside \(D\) and containing \(z_0\).
        Hence
        \[f(z) = \sum_{n=-\infty}^{\infty} \frac{(z - z_0)^n}{2\pi i} \oint_{\gamma} \frac{f(w)}{(w - z)^{n+1}} \dd{w}.\]
    \end{proof}
    
    \begin{figure}[ht]
        \centering
        \tikzsetnextfilename{laurent-series-proof-contours}
        \begin{tikzpicture}[scale=0.75]
            \tikzset{contour/.style={ultra thick}}
            \tikzset{contour arrow/.style={contour, ->, >=latex}}
            \tikzset{contour +/.style={contour arrow, red}}
            \tikzset{contour -/.style={contour arrow, blue}}
            \tikzset{contour + inverse/.style={contour, <-, >=latex, red}}
            \tikzset{contour - inverse/.style={contour, <-, >=latex, blue}}
            \tikzset{contour R/.style={contour arrow, green}}
            \tikzset{contour r/.style={contour arrow, orange}}
            \draw[contour] (0, 0) circle[radius=7cm];
            \draw[contour] (0, 0) circle[radius=3cm];
            \coordinate (A) at (0:3);
            \coordinate (B) at (0:7);
            \coordinate (C) at (150:3);
            \coordinate (D) at (150:7);
            \draw[contour] (A)  -- (B);
            \draw[contour] (C) -- (D);
            \draw[fill] (0, 0) circle[radius=0.05cm] node[below] {\(z_0\)};
            \draw[thick, ->, >=latex] (0, 0) -- (20:3) node[midway, above left] {\(r\)};
            \draw[thick, ->, >=latex] (0, 0) -- (-20:7) node[midway, above right] {\(R\)};
            \draw[contour +] ($(0:3.5) + (0, 0.2)$) -- ($(0:6.5) + (0, 0.2)$);
            \draw[contour +] ($(150:6.5) + (0, 0.25)$) -- ($(150:3.3) + (0, 0.25)$);
            \draw[contour +] (30:6.8) arc(30:60:6.8);
            \draw[contour +] (90:6.8) arc(90:120:6.8);
            \draw[contour + inverse] (30:3.2) arc(30:60:3.2);
            \draw[contour + inverse] (90:3.2) arc(90:120:3.2);
            \draw[contour -] ($(0:6.5) - (0, 0.2)$) -- ($(0:3.5) - (0, 0.2)$);
            \draw[contour -] ($(150:3.5) - (0, 0.25)$) -- ($(150:6.7) - (0, 0.25)$);
            \draw[contour -] (180:6.8) arc(180:210:6.8);
            \draw[contour -] (240:6.8) arc(240:270:6.8);
            \draw[contour -] (300:6.8) arc(300:330:6.8);
            \draw[contour - inverse] (180:3.2) arc(180:210:3.2);
            \draw[contour - inverse] (240:3.2) arc(240:270:3.2);
            \draw[contour - inverse] (300:3.2) arc(300:330:3.2);
            
            \draw[contour R] (30:7.2) arc(30:60:7.2);
            \draw[contour R] (90:7.2) arc(90:120:7.2);
            \draw[contour R] (180:7.2) arc(180:210:7.2);
            \draw[contour R] (240:7.2) arc(240:270:7.2);
            \draw[contour R] (300:7.2) arc(300:330:7.2);
            \draw[contour r] (30:2.8) arc(30:60:2.8);
            \draw[contour r] (90:2.8) arc(90:120:2.8);
            \draw[contour r] (180:2.8) arc(180:210:2.8);
            \draw[contour r] (240:2.8) arc(240:270:2.8);
            \draw[contour r] (300:2.8) arc(300:330:2.8);
            
            \node (key) at (-3.8, -8) {Key:};
            \draw[contour, red] ($(key) + (1, 0)$) -- ($(key) + (1.5, 0)$) node[right, black] (key1) {\(\gamma_+\)};
            \draw[contour, blue] ($(key1) + (1, 0)$) -- ($(key1) + (1.5, 0)$) node[right, black] (key2) {\(\gamma_-\)};
            \draw[contour, green] ($(key2) + (1, 0)$) -- ($(key2) + (1.5, 0)$) node[right, black] (key3) {\(\gamma_R\)};
            \draw[contour, orange] ($(key3) + (1, 0)$) -- ($(key3) + (1.5, 0)$) node[right, black] {\(\gamma_r\)};
            
            \draw[fill] (60:5) circle[radius=0.05cm] node[below] {\(z\)};
        \end{tikzpicture}
        \caption{The contours used to prove the validity of a Laurent series.}
        \label{fig:laurent series proof contours}
    \end{figure}
    This proof, and hence Laurent series, can be extended to an annulus of radii \(\rho_1\), \(\rho_2\), where \(f\) is analytic on \(\rho_1 < \abs{z - z_0} < \rho_2\) and the singularities inside \(\abs{z - z_0} < \rho_1\) are isolated.
    
    \subsection{Properties of Laurent Series}
    First notice that for \(n \ge 0\) the Laurent series coefficients are identical to the Taylor series coefficients.
    As well as this if \(f\) is analytic then \(c_n = 0\) for all \(n < 0\) since the integrand becomes \(f(w) (w - z)^{-n+1}\) which is analytic \((n < 0 \implies -n > 0)\).
    Thus if \(f\) is analytic its Laurent series is the same as its Taylor series.
    \begin{definition}{Principle Part}{}
        If \(f\) is a function with the Laurent series
        \[f(z) = \sum_{n=-\infty}^{\infty} c_n(z - z_0)^n\]
        then the \define{principle part} of \(f\) is
        \[\sum_{n=-\infty}^{-1}c_n(z - z_0)^n.\]
    \end{definition}
    The principle part dominates near \(z = z_0\).
    In particular very close to \(z_0\) if the Laurent series has a finite number of non-zero negative power terms, i.e.
    \[f(z) = \sum_{n=-m}^{\infty}c_n(z - z_0)^n\]
    for some \(m\in\naturals\) then the \(c_{-m}\) term dominates near \(z = z_0\).
    As with Taylor series we avoid actually using the integral definition of the coefficients wherever possible preferring to use known series and other techniques.
    \begin{example}
        \textit{Find the Laurent series of \(f(z) = e^z/z^2\) at \(z = 0\) and state its radius of convergence.}
        
        We start with the Taylor series for \(e^z\):
        \[e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}.\]
        Hence
        \begin{align*}
            f(z) &= \frac{1}{z^2}e^z\\
            &= \frac{1}{z^2} \sum_{n=0}^{\infty} \frac{z^n}{n!}\\
            &= \sum_{n=0}^{\infty} \frac{z^{n-2}}{n!}\\
            &= \sum_{n=-2}^{\infty} \frac{z^n}{(n+2)!}.
        \end{align*}
        Since the Taylor series of \(e^z\) converges for all \(z\in\complex\) this Laurent series converges for all \(z\in\complex\setminus\{0\}\).
    \end{example}
    \begin{example}
        \textit{Find the Laurent series of \(f(z) = 1/z(z - 1)^2\) at \(z = 1\) and state its radius of convergence.}
        
        There are two singularities now at \(z = 0, 1\).
        This divides \(\complex\) into two regions: \(0 < \abs{z - 1} < 1\) and \(\abs{z - 1} > 1\).
        For \(0 < \abs{z - 1} < 1\) we have
        \begin{align*}
            f(z) &= \frac{1}{z(z - 1)^2}\\
            &= \frac{1}{1 + (z - 1)}\frac{1}{(z - 1)^2}\\
            &= \frac{1}{(z - 1)^2}\sum_{n=0}^{\infty} (-1)^n(z - 1)^n\\
            &= \sum_{n=-2}^{\infty} (-1)^n(z - 1)^n\\
        \end{align*}
        where we have used the geometric series:
        \[\frac{1}{1 + \alpha} = \frac{1}{1 - (-\alpha)} = \sum_{n=0}^{\infty} (-\alpha)^n = \sum_{n=0}^{\infty} (-1)^n\alpha^n.\]
        For \(\abs{z - 1} > 1\) we have
        \begin{align*}
            f(z) &= \frac{1}{z(z - 1)^2}\\
            &= \frac{1}{(z - 1)^3}\frac{1}{1 + \frac{1}{1 - z}}\\
            &= \frac{1}{(z - 1)^3}\sum_{n=0}^{\infty} (-1)^n\frac{1}{(z - 1)^n}\\
            &= \sum_{n=-3}^{\infty} (-1)^{n+1}(z - 1)^n
        \end{align*}
        where we have used \((-1)^{n+3} = (-1)^{n+1}\) as it is only the parity of the power that is important here.
        
        The first of these Laurent series converges for \(\abs{z} < 1\) and the second for \(\abs{z} > 1\).
    \end{example}
    
    \begin{example}
        \emph{Compute the first few terms of the Laurent series of \(f(z) = \cot z\) at \(z = 0\) to first order in \(z\). State its radius of convergence.}
        
        To do this we use the Taylor series of \(\sin\) and \(\cos\):
        \begin{align*}
            f(z) &= \cot z\\
            &= \frac{1}{\tan z}\\
            &= \frac{\cos z}{\sin z}\\
            &= \frac{1 - \frac{z^2}{2!} + \frac{z^4}{4!} - \dotsb}{z - \frac{z^3}{3!} + \frac{z^5}{5!} - \dotsb}\\
            &= \frac{1}{z}\frac{1 - \frac{z^2}{2!} + \frac{z^4}{4!} - \dotsb}{1 - \frac{z^2}{3!} + \frac{z^4}{5!} - \dotsb}\\
            &= \frac{1}{z} \left( 1 - \frac{z^2}{2!} + \frac{z^4}{4} - \dotsb \right) \left( 1 + \frac{z^2}{3!} - \dotsb \right)\\
            &= \frac{1}{z} \left( 1 + z^2\left( \frac{1}{6} - \frac{1}{2} \right) + \dotsb \right)\\
            &= \frac{1}{z} - \frac{1}{3}z.
        \end{align*}
        Here we used the Binomial expansion to first order to turn the fraction of series into the product of series.
        For convergence we have two considerations.
        The first is \(f\) has singularities at \(z = n\pi\) for \(n\in\integers\), hence the maximum radius of convergence is \(\abs{z} < \pi\).
        The binomial expansion of \((1 + w)^-1\) is also only valid for \(\abs{w} < 1\), in this case we need \(\abs{z^2/3!} < 1\) which means \(\abs{z^2} < 3! = 6\).
        Hence \(\abs{z} < \sqrt{6} \approx 2.44 < \pi\) so the radius of convergence is \(\abs{z} < \sqrt{6}\).
    \end{example}
    \begin{example}
        \emph{Obtain the Laurent series of \(f(z) = \exp(1/z)\) at \(z = 0\).}
        
        Here we use the fact that if \(g\) is entire (i.e., its Taylor series converges everywhere on \(\complex\)) then the Taylor series for \(g(1/z)\) converges for all \(z \ne 0\).
        Hence
        \[f(z) = e^{1/z} = \sum_{n=0}^{\infty}\frac{1}{n!}\frac{1}{z^n} = \sum_{-\infty}^{0} \frac{z^n}{(-n)!}.\]
        Note that this method is not always valid.
        For example since the series for \(\cot\) does not converge everywhere we can't simply substitute \(1/z\) into the series to find \(\cot(1/z)\).
        We would have to redo the analysis in the previous section.
    \end{example}
    \begin{example}
        \emph{Obtain the Laurent series for \(f(z) = 1/[z^2(z -1)]\) at \(z = \infty\).}
        
        In a similar way to branch points at infinity we consider series at infinity through the substitution \(z \to 1/w\) and then take \(w\to 0\).
        Hence
        \begin{align*}
            f(z) &= f(1/w)\\
            &= \frac{1}{w^{-2}(1/w - 1)}\\
            &= \frac{w^3}{1 - w}\\
            &= w^3 \sum_{n=0}^{\infty} w^n\\
            &= \sum_{n=3}^{\infty} w^n.
        \end{align*}
        Here we have used the fact that for \(w\to 0\) surely \(\abs{w} < 1\) and so the geometric series expansion is valid.
        Converting back to \(z\) we get the final answer
        \[f(z) = \sum_{n=3}^{\infty} \frac{1}{z^n} = \sum_{n=-\infty}^{-3}z^n.\]
    \end{example}

    \section{Zeros and Singularities}
    \subsection{Classifying Singularities}
    The behaviour of many functions is almost entirely described by their behaviour at singularities and zeros.
    For this reason it is important to be able to classify these regions.
    
    \begin{definition}{Zero of Order \(N\)}{}
        If \(f(z_0) = 0\) then we can write
        \[f(z) = \sum_{n=N}^{\infty} c_n(z - z_0)^n = (z - z_0)^N\sum_{n=0}^{\infty}c_{n+N}(z - z_0)^n = (z - z_0)^Ng(z)\]
        where \(g\) is analytic at \(z_0\) and \(c_N = g(z_0) \ne 0\).
        We call \(z_0\) a \define{zero of order \(\bm{N}\)}.
    \end{definition}
    Intuitively a zero of order \(N\) allows us to factor out \(N\) copies of \(z - z_0\) before we get a function that is non-zero at \(z_0\).
    For a polynomial the order of a root is simply its multiplicity.
    For example, trivially \(z(z - 1)^2\) has two zeros, a zero of order one at \(z = 0\) and a zero of order 2 at \(z = 1\).
    
    \begin{definition}{Pole of order \(N\)}{}
        If \(f\) is singular at \(z_0\) and its Laurent series has a finite number of negative terms then we can write
        \[f(z) = \sum_{n=-N}^{\infty} c_n(z - z_0)^n = \frac{1}{(z - z_0)^N} \sum_{n=0}^{\infty} c_{n-N}(z - z_0)^n = \frac{g(z)}{(z - z_0)^N}\]
        where \(g\) is analytic at \(z_0\) and \(c_{-N} = g(z_0) \ne 0\).
        We call \(z_0\) a \define{pole of order \(\bm{N}\)}.
        In the special case of \(N = 1\) we call \(z_0\) a \define{simple pole}.
    \end{definition}
    A pole of order \(N\) is similar to a zero of order \(N\) except we can factor out \(N\) copies of \(z - z_0)^{-1}\) before we have a function that is non-singular at \(z_0\).
    
    \begin{definition}{Removable Singularity}{}
        Suppose that \(f\) is singular at \(z_0\).
        It may be possible to assign a value to \(f\) at \(z_0\) such that the resulting function is analytic.
        This can be done by defining \(f\) to be equal to it's Taylor series at \(z_0\).
        In this case the principle part of the Laurent series must be zero.
        If this can be done we call \(z_0\) a \define{removable singularity}.
    \end{definition}
    Intuitively a removable singularity is a point where the function is formally undefined but there is a logical value.
    For example \(f(z) = \sin(z)/z\) is indeterminate at \(z = 0\) but by defining \(f\) to be \(1\) at \(z = 0\) we recover a nicely behaved function.
    A removable singularity is also a pole of order zero.
    
    \begin{definition}{Essential Singularity}{}
        If \(f\) is singular at \(z_0\) and the Laurent series of \(f\) has an infinite number of negative terms then we say \(z_0\) is an \define{essential singularity}.
    \end{definition}
    
    \subsection{Picard's Theorems}
    \emph{This section is non-examinable.}
    
    The following two functions are important in complex analysis but are entirely beyond the scope of this course and are given for completeness.
    They are non-examinable and the proofs are far to involved to get into.
    \begin{theorem*}{Picard's Little Theorem}
        \emph{This theorem is non-examinable.}
        
        If \(f\colon\complex\to\complex\) is entire it is either constant or its image is either the entire complex plane or the plane minus a single point.
    \end{theorem*}
    For example \(e^z\) is entire and its image is \(\complex\setminus\{0\}\).
    \begin{theorem*}{Picard's Great Theorem}
        \emph{This theorem is non-examinable.}
        
        If \(f\colon\complex\to\complex\) is analytic and has an essential singularity at \(z_0\) then on any punctured neighbourhood of \(z_0\) the image of \(f\) is either the entire complex plane or the plane minus a single point.
    \end{theorem*}
    For example \(e^{1/z}\) achieves all values apart from 0 in a neighbourhood of \(z = 0\).
    This leads to the interesting plots seen in figure~\ref{fig:exp(1/z)}.
    Notice how as we zoom in on \(z = 0\) the colour (representing the phase) chances rapidly.
    \begin{figure}
        \centering
        \begin{subfigure}{0.48\textwidth}
            \centering
            \includegraphics[scale=0.6]{exp-1-div-z-low-zoom.pdf}
            \caption{Plotted for \(\Re(z), \Im(z)\in[-1, 1]\)}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \centering
            \includegraphics[scale=0.6]{exp-1-div-z-mid-zoom.pdf}
            \caption{Plotted for \(\Re(z), \Im(z)\in[-0.1, 0.1]\)}
        \end{subfigure}
        \begin{subfigure}{\textwidth}
            \centering
            \includegraphics[scale=0.6]{exp-1-div-z-high-zoom.pdf}
            \caption{Plotted for \(\Re(z), \Im(z)\in[-0.01, 0.01]\)}
        \end{subfigure}
        \begin{subfigure}{0.48\textwidth}
            \centering
            \includegraphics[scale=0.6]{exp-1-div-z-ultra-high-zoom.pdf}
            \caption{Plotted for \(\Re(z), \Im(z)\in[-0.001, 0.001]\)}
        \end{subfigure}
        \caption{\(f(z) = e^{1/z}\) with different levels of zoom. Brightness gives absolute value and colour gives argument. The large red regions near the centre of the two most zoomed in plots are simply a plotting artefact due to a lack of precision with floating points.}
        \label{fig:exp(1/z)}
    \end{figure}

    \subsection{Zeros and Singularities of Composite Functions}
    Often the easiest way to classify the zeros and singularities of a function is to break it apart into functions where we already know the answer.
    For this to be useful we need to know how the zeros and singularities of a function change when we combine them.
    \begin{lemma}{Combining Zeros and Singularities}{}
        Let \(f, g\colon S\to\complex\) be analytic on \(S\).
        Let \(z_0\in S\) be a zero of order \(p\) for \(f\) and of order \(q\) for \(g\).
        Then
        \begin{itemize}
            \item \(fg\) has a zero of order \(p + q\) at \(z = z_0\),
            \item \(1/f\) has a pole of order \(p\) at \(z_0\),
            \item \(f/g\) has
            \begin{itemize}
                \item a zero of order \(p - q\) at \(z_0\) if \(p > q\),
                \item a zero of order \(q - p\) at \(z_0\) if \(p < q\).
            \end{itemize}
        \end{itemize}
    \end{lemma}
    \begin{proof}
        Since \(f\) and \(g\) are analytic with zeros of order \(p\) and \(q\) respectively they have Taylor series
        \[f(z) = (z - z_0)^{p}\sum_{n=0}^{\infty} a_n(z - z_0)^n, \qquad\text{and}\qquad g(z) = (z - z_0)^q\sum_{n=0}^{\infty} b_n(z - z_0)^n.\]
        Hence
        \begin{align*}
            (fg)(z) &= \left[ (z - z_0)^{p}\sum_{n=0}^{\infty} a_n(z - z_0)^n \right] \left[ (z - z_0)^q\sum_{n=0}^{\infty} b_n(z - z_0)^n \right]\\
            &= (z - z_0)^{p+q} \left[ \sum_{n=0}^{\infty} a_n(z - z_0)^n \right] \left[ \sum_{n=0}^{\infty} b_n(z - z_0)^n \right].
            &= (z - z_0)^{p + q} \sum_{n=0}^{\infty} c_n(z - z_0)^n\\
            &= (z - z_0)^{p + q}h(z)
        \end{align*}
        where \(h\) is an analytic function with Taylor series
        \[h(z) = \sum_{n=0}^{\infty} c_n(z - z_0)^n = \sum_{n=0}^{\infty} a_n(z - z_0)^n \sum_{n=0}^{\infty} b_n(z - z_0)^n.\]
        Hence \(fg\) has a pole of order \(p + q\).
        
        Now consider
        \begin{align*}
            \frac{1}{g} &= \left[ (z - z_0)^p\sum_{n=0}^{\infty} a_n(z - z_0)^n \right]^{-1}\\
            &= \frac{1}{(z - z_0)^p} \frac{1}{\sum_{n=0}^{\infty} a_n(z - z_0)^n}\\
            &= \frac{1}{(z - z_0)^p} \frac{1}{a_0} \frac{1}{\sum_{n=0}^{\infty} \frac{a_n}{a_0}(z - z_0)^n}\\
            &= \frac{1}{(z - z_0)^p} \frac{1}{a_0} \frac{1}{1 + \frac{a_1}{a_0}(z - z_0) + \order{(z - z_0)^2}}\\
            &= \frac{1}{(z - z_0)^p} \frac{1}{a_0} \left[ 1 - \frac{a_1}{a_0}(z - z_0) + \order{(z - z_0)^2} \right]\\
            &= \frac{1}{(z - z_0)^q} \sum_{n=0}^{\infty} d_n(z - z_0)\\
            &= \frac{1}{(z - z_0)^q} \tilde{h}(z)
        \end{align*}
        where \(\tilde{h}\) is an analytic function with Taylor series
        \[\tilde{h}(z) = \sum_{n=0}^{\infty} d_n(z - z_0)^n = \frac{1}{a_0} \left[ 1 - \frac{a_1}{a_0}(z - z_0) + \order{(z - z_0)^2} \right]\]
        here we have used the fact that near \(z\) surely \(\abs{z - z_0} < 1\) and so the binomial expansion is valid.
        
        A mixture of the two arguments above suffices to prove the final point.
    \end{proof}
    \begin{example}
        {\itshape
        Characterise the zeros and singularities of the following functions:
        \begin{enumerate}
            \item \(f(z) = z(z - 1)\),
            \item \(f(z) = (z - 3)^5\sin z\),
            \item \(f(z) = \frac{\sin z}{z(z - 1)}\),
            \item \(f(z) = z\cos^2\left( \frac{\pi}{2z} \right)\).
        \end{enumerate}
        }
        \begin{enumerate}
            \item The zeros of this function are \(z = 0, 1\), both of which are order 1.
            \item \(z = 3\) is a zero of this function with order 5.
            \(z = \pi n\) for \(n\in\integers\) are zeros of order 1.
            \item \(z = n\pi\) for \(n\in\integers\setminus\{0\}\) are zeros of order 1 for this function.
            \(z = 0\) is a removable singularity and \(z = 1\) is a simple pole.
            \item The cosine part is zero when \(\frac{\pi}{2z} = \frac{(2n+1)\pi}{2}\) for \(n\in\integers\setminus\{0\}\), hence \(z = 2n + 1\) are zeros of order 2 (2 because \(\cos\) is squared).
            \(z = 0\) is an essential singularity.
            We can see this by considering the Laurent series.
            Since \(\cos\) is entire the Laurent series is simply given by inserting \(\pi/2z\) into the Taylor series for \(\cos\):
            \[z\cos^2\left( \frac{\pi}{2z} \right) = z\left[ \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}\left( -\frac{\pi}{2z} \right)^n \right]^2 = z\left[ \sum_{n=-\infty}^{0} \frac{z^n}{(-2n)!}\left( \frac{\pi}{2} \right)^{-n} \right]^2.\]
            This clearly has an infinite number of negative terms.
        \end{enumerate}
    \end{example}
    
    \section{Meromorphic Functions}
    \begin{definition}{Meromorphic Function}{}
        A function, \(f\), is called \define{meromorphic} if it is analytic in \(\complex\) except for at countably many isolated poles, that is \(f\) is analytic almost everywhere.
    \end{definition}
    Recall that countable includes a finite number of poles or infinitely many with cardinality \(\aleph_0 = \abs{\naturals}\)\footnote{The following are all countable: any finite set, \(\naturals\), \(\integers\), \(\rationals\), the set of algebraic numbers (roots of non-zero complex polynomials with rational coefficients), and the set of all constructible numbers}.
    \begin{example}
        The function \(f(z) = e^{-z^2}\) is a composition of the entire functions \(e^z\) and \(-z^2\).
        Therefore \(f\) is entire and thus by definition \(f\) is meromorphic.
        
        Let \(P_n\) and \(Q_m\) be polynomials of order \(n\) and \(m\).
        Then \(f(z) = P_n(z)/Q_m(z)\) has singularities only where \(Q_m(z) = 0\) and since this happens \(m\) times by the fundamental theorem of algebra \(f\) is meromorphic.
        
        Let \(f(z) = \tan z\).
        Then \(f\) is singular for \(z = (n + 1/2)\pi\) for \(n\in\integers\).
        Since \(\integers\) is countable \(f\) is meromorphic.
        
        Let \(f(z) = \sec(1/z)\). Then \(1/z\) is a non-isolated singularity so \(f\) is not meromorphic.
        
        Let \(f(z) = \log(z)\) with a branch cut from \(0\) to negative infinity.
        Then the set of poles is \(\reals_{\le 0} = (-\infty, 0]\) and this has the cardinality of the continuum so is uncountable meaning that \(f\) is not meromorphic.
    \end{example}
    Meromorphic functions have a Laurent series at every point in the complex plane and we can think of them as being the Laurent series analogue of an analytic function which has a Taylor series at every point in the complex plane.
    \begin{theorem}{}{}
        Let \(f\) be analytic.
        Then all of its zeros are isolated or it is identically zero.
    \end{theorem}
    \begin{proof}
        Let \(f\) be an analytic function which is not identically zero.
        Let \(z_0\) be a zero fo order \(N\).
        Then we can write
        \[f(z) = (z - z_0)^Ng(z)\]
        for some analytic function \(g\) where \(g(z_0)\ne 0\).
        Since \(g\) is analytic it is also continuous.
        This means that for all \(\varepsilon > 0\) there exists \(\delta>0\) such that
        \[\abs{z - z_0}<\delta \implies \abs{g(z) - g(z_0)} < \varepsilon.\]
        Specifically we can find \(\delta\) such that this is true for \(\varepsilon = \abs{g(z_0)}/2\).
        Suppose that \(f\) has non-isolated zeros.
        Then no matter how small \(\delta\) is we can find \(z'\in\discPunctured{z_0}{\delta}\) such that \(f(z') = 0\).
        However \(z' \ne z_0\) so for this to be the case we have
        \[0 = f(z') = (z' - z_0)^Ng(z')\]
        and so \(g(z') = 0\).
        However this means that
        \[\abs{g(z') - g(z_0)} = \abs{0 - g(z_0)} > \frac{\abs{g(z_0)}}{2}.\]
        So we have a contradiction which means that our assumption that non-isolated zeros exist is false and the theorem is proven.
    \end{proof}

    \begin{corollary}{}{}
        Let \(f\) and \(g\) be analytic in a region \(S\).
        Then if \(f = g\) in a smooth arc, \(\gamma\), then both functions are identical in \(S\).
    \end{corollary}
    \begin{proof}
        Let \(f\) and \(g\) be analytic functions on \(S\) which are equal on \(\gamma\).
        Then \(f - g\) is also an analytic function.
        Along the arc \(\gamma\) \((f - g)(z) = 0\) for all \(z\in\gamma\).
        Since \(\gamma\) is smooth we can pick two points on \(\gamma\) which are arbitrarily close.
        \(f - g\) is zero at both of these points and therefore the zeros of \(f - g\) are not isolated.
        This means that \(f - g\) must be identically zero and hence \(f = g\) on all of \(S\).
    \end{proof}

    \part{Residues}
    \section{Cauchy's Residue Theorem}
    We now have methods for computing many types of integrals.
    In example~\ref{exa:integral 1/z-a} we have seen that
    \begin{equation}\label{eqn:integral 1/z-a}
        \oint_{\gamma} \frac{1}{(z - a)^{n+1}}\dd{z} =
        \begin{cases}
            2\pi i, & \text{if}~n=0,\\
            0, & \text{if}~n\ne 0.
        \end{cases}
    \end{equation}
    From the Cauchy--Goursat theorem we know that
    \[\oint_{\gamma} f(z)\dd{z} = 0\]
    for any analytic function, \(f\).
    From Cauchy's integral formula we know that if \(f\) is analytic then
    \[f(a) = \frac{1}{2\pi i} \oint_{\gamma} \frac{f(z)}{z - a}\dd{z}\]
    and from Cauchy's generalised integral formula we have
    \[f^{(n)}(a) = \frac{n!}{2\pi i} \oint_{\gamma} \frac{f(z)}{(z - a)^{n+1}}\dd{z}.\]
    We will now use these results to find a way to integrate \emph{any} meromorphic function over a closed contour.
    
    \subsection{One Isolated Singularity}
    Let \(f\colon S\to\complex\) be analytic on \(S\setminus\{z_0\}\) and let \(z_0\) be an isolated singularity of \(f\).
    Let \(\gamma\) be a positively orientated closed contour inside \(S\) with \(z_0\) inside \(\gamma\).
    
    Since \(f\) only has isolated singularities we know that it has a Laurent series at every point in \(S\).
    Thus
    \[f(z) = \sum_{n=-\infty}^{\infty}c_n(z - z_0)^n.\]
    Hence the integral of \(f\) over \(\gamma\) is
    \[I = \oint_{\gamma} f(z) \dd{z} = \oint_{\gamma} \sum_{n=-\infty}^{\infty} c_n(z - z_0)^n \dd{z}.\]
    Since Laurent series are uniformly convergent we can exchange the integral and summation so
    \[I = \sum_{n=-\infty}^{\infty} c_n \oint_{\gamma} (z - z_0)^n \dd{z}.\]
    We now use equation~\ref{eqn:integral 1/z-a} and we see that all terms of the sum when \(n \ne -1\) vanish leaving us with
    \[I = \int_{\gamma} f(z) \dd{z} = c_{-1}\oint_{\gamma} \frac{1}{z  a} \dd{z} = 2\pi i c_{-1}.\]
    This result holds for any isolated singularity, \(z_0\), even an essential singularity.
    
    \subsection{Cauchy's Residue Theorem}
    We saw in the previous section that the integral,
    \[\oint_{\gamma} f(z) \dd{z},\]
    is entirely determined by the \(n = -1\) coefficient of the Laurent series.
    This is such a useful result that we give this coefficient a special name.
    \begin{definition}{Residue}{}
        Let \(f\colon S\to\complex\) be meromorphic on \(S\) and let \(z_0\in S\) be a singularity of \(f\).
        The \define{residue} of \(f\) at \(z_0\) is the \(c_{-1}\) coefficient of the Laurent series of \(f\) expanded around \(z_0\), which we denote
        \[c_{-1} = \Res(f, z_0).\]
    \end{definition}
    We are now ready for one of the most useful theorems of this course which will allow us to compute many integrals, both real and complex, by simply performing a summation.
    
    \begin{theorem}{Cauchy's Residue Theorem}{}
        Let \(f\colon S\to\complex\) be meromorphic and let \(\gamma\) be a positively orientated closed contour in \(S\).
        Then
        \[\oint_{\gamma} f(z) \dd{z} = 2\pi i \sum_{i} \Res(f, z_i)\]
        where \(\{z_i\}\) is the set of isolated singularities inside \(\gamma\).
    \end{theorem}
    \begin{proof}
        The singularities, \(z_i\), are isolated which allows us to create contours, \(\gamma_i\), such that each contour contains exactly one singularity, \(z_i\), and the boundaries of said contours are such that the sum of the contours is \(\gamma\).
        See figure~\ref{fig:contours for cauchy's residue theorem}
        Then
        \[\oint_{\gamma} f(z)\dd{z} = \sum_{i}\oint_{\gamma_i}f(z)\dd{z}.\]
        Since each contour, \(\gamma_i\), contains only a single isolated singularity we already saw in the previous section that
        \[\oint_{\gamma_i} f(z) \dd{z} = 2\pi ic_{-1} = 2\pi i\Res(f, z_i)\]
        and so
        \[\oint_{\gamma} f(z) \dd{z} = 2\pi i\sum_{i} \Res(f, z_i).\]
    \end{proof}
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{cauchys-residue-theorem-contours}
        \begin{tikzpicture}
            \draw[very thick] (0, 0) circle [radius=4cm];
            \node at (20:4.2) {\(\gamma\)};
            \foreach \x/\y in {-1.721/2.761, 0.772/3.342, -2.6/-1.424, 1.22/3.67, 0.181/-1.225, -2.173/1.136, 1.103/-3.27, 2.109/0.557, 2.228/3.187, 0.143/3.437} {
                \draw[red, fill=red] (\x, \y) circle[radius=0.05cm];
            }
            \draw (0, 0) -- (0:4);
            \draw (0, 0) -- (30:4);
            \draw (0, 0) -- (60:4);
            \draw (0, 0) -- (80:4);
            \draw (0, 0) -- (100:4);
            \draw (0, 0) -- (140:4);
            \draw (0, 0) -- (180:4);
            \draw (0, 0) -- (270:4);
            \draw (270:4) -- (0:4);
            \draw (80:3.8) -- (60:3.5);
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{An example of contours used to prove Cauchy's residue theorem. Notice if each closed contour is integrated around in an anticlockwise direction then each internal line is integrated along twice, once in each direction, so the net result is an integral over the external contour.}
        \label{fig:contours for cauchy's residue theorem}
    \end{figure}
    Cauchy's residue theorem gives us a way to integrate any meromorphic function.
    Simply follow these steps:
    \begin{enumerate}
        \item Find all singularities of the integrand.
        \item Find which of these singularities fall within the contour we are integrating.
        \item Compute the residues of these singularities and sum.
    \end{enumerate}
    
    \subsection{Computing Residues}
    For Cauchy's residue theorem to be useful we have to be good at computing residues.
    Fortunately this is often surprisingly easy once we have identified the type of singularity.
    Here we will discuss computation of residues for different types of singularities starting with the simplest case and progressing on to harder cases.
    The goal is to find a way to compute
    \[\Res(f, a) = \oint_{\gamma} f(z) \dd{z}\]
    where \(z = a\) is a singularity of \(f\).
    
    \subsubsection{Polynomial, Simple Poles}
    If \(f\) has a simple pole at \(a\) then we can write
    \[f(z) = \frac{g(z)}{z - a}\]
    where \(g\) is analytic at \(z = a\).
    The residue of \(f\) at \(z = a\) is then
    \[\Res(f, a) = \oint_{\gamma} \frac{g(z)}{z - a}\dd{z} = g(a)\]
    where we have used Cauchy's integral formula for the final equality.
    
    \subsubsection{Pole of Order \texorpdfstring{\(n\)}{n}}
    If \(f\) has a pole of order \(n\) at \(a\) then we can write
    \[f(z) = \frac{g(z)}{(z - a)^n}\]
    where \(g\) is analytic at \(z = a\).
    The residue of \(f\) at \(z = a\) is then
    \[\Res(f, a) = \oint_{\gamma} \frac{g(z)}{(z - a)^n} \dd{z} = \frac{1}{(n - 1)!}g^{(n-1)}(a)\]
    where we have used Cauchy's generalised integral formula for the final equality.
    
    \subsubsection{General, Simple Pole}
    If \(f\) has a simple pole at \(a\) then we can write
    \[f(z) = \frac{g(z)}{h(z)}\]
    where \(f\) and \(h\) are analytic at \(a\).
    We can write \(f\) as a Laurent series:
    \[f(z) = \frac{c_{-1}}{z - a} + c_0 + c_1(z - a) + \dotsb.\]
    Then
    \[(z - a)f(z) = c_-1 + c_0(z - a) + c_1(z - a)^2 + \dotsb.\]
    This is a Taylor series so \((z - a)f(z)\) is analytic.
    Evaluating this Taylor series at \(z = a\) we expect to get \(c_{-1}\) as this is the only term that won't be zero.
    However care has to be taken since \(f\) is not analytic at \(a\) so we take limits:
    \begin{align*}
        \Res(f, a) &= \lim_{z\to a} (z - a)f(z)\\
        &= \lim_{z\to a} \frac{(z - a)g(z)}{h(z)}\\
        &= \lim_{z\to a} \frac{\dv{z}[(z - a)g(z)]}{\dv{z}h(z)}\\
        &= \lim_{z\to a} \frac{g(z) + (z - a)g'(z)}{h'(z)}\\
        &= \frac{g(a)}{h'(a)}.
    \end{align*}
    Here we have used L'H\^opital's rule, which applies to complex functions just as it does real functions.
    In the last step we assume that \(g(a)/h'(a)\) is not indeterminate, if it is then we may need to apply L'H\^opital's rule again.
    
    \subsubsection{None of the Previous Cases}
    If none of the previous situations apply, say \(a\) is an essential singularity of \(f\), then often we can find the residue by simply computing the Laurent series from known series.
    For example if \(f(z) = e^{-2z}/z^3\) then since \(e^z\) is entire we have
    \[f(z) = \frac{1}{z^3} \sum_{n=0}^{\infty} \frac{1}{n!}\frac{1}{z^{2n}} = \frac{1}{z^3} - \frac{2}{z^2} + \frac{2}{z} - \frac{4}{3} + \dotsb\]
    and so we identify \(\Res(f, 0) = 2\).
    
    \subsubsection{General, Non-Essential Singularity}
    If \(f\) has a non-essential singularity of order \(n\) at \(a\) then expanding \(f\) as a Laurent series we have
    \[f(z) = \frac{c_{-n}}{(z - a)^n} + \frac{c_{-n+1}}{(z - a)^{n-1}} + \dotsb + \frac{c_{-1}}{(z - a)^n} + c_0 + \dotsb.\]
    Hence
    \[(z - a)^nf(z) = c_{-n} + c_{-n+1}(z - a) + \dotsb + c_{-1}(z - a)^{n - 1} + c_{0}(z - a)^{n} + \dotsb\]
    so \((z - a)^nf(z)\) is analytic.
    We can then compute \(c_{-1}\) as the \((n - 1)\)th term of the Taylor series for \((z - a)^nf(z)\).
    That is
    \[\Res(f, a) = \frac{1}{(n - 1)!}\dv[n-1]{z}[(z - a)^{n-1}f(z)]\bigg|_{z=a}.\]
    However due to being awful to compute this method should be reserved for when all other methods have failed.
    
    \begin{example}
        \emph{Find the residue of \(f(z) = e^{ika}/(z - a)\) at \(z = a\).}
        
        We can write
        \[f(z) = \frac{g(z)}{z - a}\]
        where \(g(z) = e^{ika}\).
        \(f\) has a simple pole at \(z = a\) so we have
        \[\Res(f, a) = g(a) = e^{ika}.\]
    \end{example}
    \begin{example}
        \emph{Find the residue of \(f(z) = e^{ika}/(z - a)^2\) at \(z = a\).}
        
        We can write
        \[f(z) = \frac{g(z)}{(z - a)^2}.\]
        \(f\) has a pole of order 2 at \(z = a\) so we have
        \[\Res(f, a) = \frac{1}{(2 - 1)!}g^{(2 - 1)}(a) = g'(a) = ike^{ika}.\]
    \end{example}
    \begin{example}\label{exa:residues of pi cot pi z}
        \emph{Find the residues of \(f(z) = \pi\cot(\pi z)\) at all singularities.}
        
        We can write
        \[f(z) = \pi\frac{\cos(\pi z)}{\sin(\pi z)} = \pi\frac{g(z)}{h(z)}\]
        where \(g(z) = \cos(\pi z)\) and \(h(z) = \sin(\pi z)\).
        This has simple poles at \(z = n\in\integers\).
        Hence the residue is
        \begin{align*}
            \Res(f, n) &= \lim_{z\to n} \pi \frac{(z-n)g(z)}{h(z)}\\
            &= \pi \lim_{z\to n} \frac{(z - n)g'(z) + g(z)}{h'(z)}\\
            &= \pi \frac{g(n)}{h'(n)}\\
            &= \pi \frac{\cos(\pi n)}{\pi\cos(\pi n)}\\
            &= 1.
        \end{align*}
    \end{example}
    \begin{example}
        \emph{Find the residues of \(f(z) = e^{1/z}\) at \(z = 0\).}
        
        Here \(f\) has an essential singularity at \(z = 0\).
        Since \(e^{z}\) is entire we have
        \[f(z) = \sum_{n=0}^{\infty}\frac{1}{n!}\frac{1}{z^n} = 1 + \frac{1}{z} + \frac{1}{2z^2} + \dotsb\]
        so we see that
        \[\Res(z, 0) = 1.\]
    \end{example}
    \begin{example}
        \emph{Find the singularities of the following function and state their order. Compute the residues.}
        \[f(z) = \frac{\cos z}{z^2 (z - \pi)^3}.\]
        This function has singularities at \(z = 2\) (2nd order) and \(z = \pi\) (3rd order).
        The denominator is a polynomial so we can evaluate the residues as follows:
        \begin{align*}
            \Res(f, 0) &= \dv{z} \frac{\cos z}{(z - \pi)^3}\bigg|_{z=0}\\
            &= -\frac{\sin z}{(z - \pi)^3}\bigg|_{z=0} - 3\frac{\cos z}{(z - \pi)^4}\bigg|_{z=-}\\
            &= \frac{-3}{\pi^4}.\\
            \Res(f, \pi) &= \frac{1}{2!}\dv{z}\frac{\cos z}{z^2}\bigg|_{z=\pi}\\
            &= -\frac{1}{2}\dv{z}\frac{\sin z}{z^2}\bigg|_{z=\pi} - \dv{z}\frac{\cos z}{z^3}\bigg|_{z=\pi}\\
            &= -\frac{1}{2}\frac{\cos z}{z^2}\bigg|_{z=\pi} + \frac{3}{2}\frac{\sin z}{z^3}\bigg|_{z=\pi} + \frac{\sin z}{z^3}\bigg|_{z=\pi} + 3\frac{\cos z}{z^4}\bigg|_{z=\pi}\\
            &= \frac{\pi^2 - 6}{2\pi^4}
        \end{align*}
    \end{example}
    \begin{example}
        \emph{Compute the residue of \(f(z) = 1/(z^{27} - 1)\) at \(z = 1\).}
        
        This is an example to show that case 1 is not always the best method for computing residues, even though it could be applied here.
        We would need to compute all 27 roots of \(z^27 = 1\) which is not too bad but is much slower than using L'H\^{o}pital's rule\footnote{note that although \(z\) is raised to the 27th power \(z^{27} - 1\) is only raised to the first power and therefore \(z = 1\) is a simple pole.}:
        \begin{align*}
            \Res(f, 1) &= \lim_{z\to 1} \frac{z - 1}{z^{27} - 1}\\
            &= \lim_{z\to 1} \frac{\dv{z}(z - 1)}{\dv{z}(z^{27} - 1)}\\
            &= \lim_{z\to 1} \frac{1}{27z^{26}}\\
            &= \frac{1}{27}.
        \end{align*}
    \end{example}
    
    \section{Applications of Cauchy's Residue Theorem}
    \subsection{Improper Integrals}
    One of the most common applications of Cauchy's residue theorem is to evaluate real, improper integrals.
    An improper integral is one where one (or both) of the limits is \(\pm \infty\).
    Formally this is simply short hand for a limit.
    Let \(a\in\reals\) then for an integrable function \(f\) we have
    \begin{align*}
        \int_{a}^{\infty} f(x)\dd{x} &= \lim_{R\to\infty} \int_{a}^{R} f(x)\dd{x},\\
        \int_{-\infty}^{a} f(x)\dd{x} &= \lim_{\rho\to-\infty} \int_{\rho}^{a} f(x)\dd{x},\\
        \int_{-\infty}^{\infty} f(x)\dd{x} &= \lim_{\rho, R\to\infty} \int_{-\rho}^{R} f(x) \dd{x}.
    \end{align*}
    Often these integrals can be solved using complex analysis by the following procedure:
    \begin{enumerate}
        \item Choose a suitable meromorphic function on \(\complex\).
        Often simply extending the domain of the integrand to \(\complex\) is sufficient.
        \item Choose a suitable contour such that one arc of the contour reduces to the integral we want to know.
        Often semicircles or rectangles with one side coinciding with \(\reals\) are good choices.
        \item Evaluate the integral over the entire contour using various methods from complex analysis.
        \item Evaluate the integral over each arc.
        \item Hope that the extra arcs either vanish (in the limit) or are easily computable.
        \item Rearrange to find the integral we want.
    \end{enumerate}
    \begin{example}
        \emph{Evaluate the following integral\footnote{this is just \(\arctan\) but knowing that is not really in the spirit of the example.}:}
        \[I = \int_{0}^{\infty} \frac{1}{1 + x^2}\dd{x}\]
        Let \(f(z) = 1/(1 + z^2)\) define a complex function.
        Consider the semicircle of radius \(R\) centred on \(z = 0\) with its flat side along \(\reals\).
        In the limit \(R \to \infty\) the integral along the flat side of the semicircle will be our desired integral.
        That is
        \[\lim_{R\to\infty} \int_{\gamma} f(z) \dd{z} = \lim_{R\to\infty} \int_{-R}^{R} f(z) \dd{z} + \lim_{R\to\infty}\int_{C_R} f(z) \dd{z} = 2I + \lim_{R\to\infty} \int_{C_R} f(z)\dd{z}\]
        where \(\gamma\) is the entire semicircle and \(C_{R}\) is the curved part of the semicircle.
        We have used here that \(f\) is an even function so the integral over \([-R, R]\) is twice the integral over \([0, R]\).
        We simply need to compute the integral over \(\gamma\) and \(C_R\) to find \(I\).
        
        We will start with the integral over \(\gamma\).
        \(f\) has two singularities, at \(z = \pm i\).
        Only \(z = i\) is inside \(\gamma\).
        Hence
        \[\oint_{\gamma} f(z) \dd{z} = \oint_{\gamma}\frac{1}{(z + i)(z - i)}\dd{z} = 2\pi i\frac{1}{z + i}\bigg|_{z=i} = \pi.\]
        Here we used Cauchy's integral formula.
        
        Next we bound the integral over \(C_R\).
        To do this we parametrise this arc as \(C_R(\vartheta) = Re^{i\vartheta}\) and so \(C_R'(\vartheta) = iRe^{i\vartheta} \ne 0\).
        Thus
        \begin{align*}
            \lim_{R\to\infty} \abs{\int_{C_R} \frac{1}{1 + z^2}\dd{z}} &\le \lim_{R\to\infty} \int_{C_R}\abs{\frac{1}{1 + z^2}\dd{z}}\\
            &= \lim_{R\to\infty} \int_{0}^{\pi} \abs{\frac{iRe^{i\vartheta}}{1 + R^2e^{2i\vartheta}}}\dd{\vartheta}\\
            &= \lim_{R\to\infty} \int_{0}^{\pi} \frac{R}{\abs{1 + R^2e^{2i\vartheta}}} \dd{\vartheta}\\
            &\le \lim_{R\to\infty} \int_{0}^{\pi} \frac{R}{\abs{R^2e^{2i\vartheta}} - 1} \dd{\vartheta}\\
            &= \lim_{R\to\infty} \int_{0}^{\pi} \frac{R}{R^2 - 1}\dd{\vartheta}\\
            &\le \lim_{R\to\infty}\frac{\pi R}{R^2 - 1}\\
            &= 0
        \end{align*}
        So we have
        \[\lim_{R\to\infty}\int_{C_R} f(z) \dd{z} = 0.\]
        This means that
        \[\oint_{\gamma} f(z) \dd{z} = 2I + 0 \implies I = \frac{1}{2} \oint_{\gamma}f(z)\dd{z} = \frac{\pi}{2}.\]
        This is the same result as we get by identifying
        \[\int_{0}^{\infty} \frac{1}{1 + x^2} \dd{x} = [\arctan x]_{0}^{\infty} = \frac{\pi}{2} - 0 = \frac{\pi}{2}.\]
    \end{example}
    
    \subsection{Trigonometric Integrals}
    An integral of the form
    \[I = \int_{0}^{2\pi} f(\cos\vartheta, \sin\vartheta) \dd{\vartheta}\]
    can often be computed with the substitution
    \[\cos\vartheta = \Re(z) = \frac{1}{2}\left( z + \frac{1}{z} \right), \qquad\text{and}\qquad \Im(z) = \frac{1}{2i}\left( z - \frac{1}{z} \right).\]
    We integrate along the unit circle, \(S^1 = \{z\in\complex \st \abs{z} = 1\}\), then \(\dd{z} = ie^{i\vartheta}\dd{\vartheta} = iz\dd{\vartheta}\).
    We then find that
    \[\int_{0}^{2\pi} f(\cos\vartheta, \sin\vartheta) \dd{\vartheta} = \oint_{S^1} f\left( \frac{1}{2}\left[ z + \frac{1}{z} \right], \frac{1}{2}\left[ z - \frac{1}{z} \right] \right) \frac{1}{iz} \dd{z}.\]
    This is simply a change of variables to a complex variable.
    Since this integral is over a closed contour it is often easy to evaluate.
    It does only work if we integrate all the way around the circle but it is sometimes possible to rearrange the integrand so that this is the case.
    
    \begin{example}
        \emph{Evaluate}
        \[I = \int_{0}^{2\pi} \frac{1}{\frac{5}{4} + \sin\vartheta} \dd{\vartheta}.\]
        Making the suggested variable change we have
        \begin{align*}
            I &= \int_{0}^{2\pi} \frac{1}{\frac{5}{4} + \sin\vartheta} \dd{\vartheta}\\
            &= \oint_{S^1} \frac{1}{\frac{5}{4} + \frac{1}{2i}\left(z - \frac{1}{z}\right)}\\
            &= 2\oint_{S^1} \frac{1}{(z + 2i)\left(z + \frac{i}{2}\right)} \dd{z}.\\
        \end{align*}
        The integrand has two poles and only \(z = -i/2\) is inside the unit circle.
        Therefore using Cauchy's integral formula
        \[I = 2\pi i 2\frac{1}{z + 2i}\bigg|_{z=-i/2} = \frac{8\pi}{3}.\]
    \end{example}
    
    \section{Estimating Arc Integrals}
    In this section we are interested in bounding integrals over part of a circle.
    We will introduce a lemma bounding integrals over infinite circles and the switch directions and bound integrals over infinitesimal circles.
    
    \subsection{Jordan's Lemma}
    \begin{lemma}{}{}
        Let \(f\colon\complex\to\complex\).
        Suppose that far from the origin this function goes as \(\abs{f(z)} \sim M/R^k\) for \(k\in\reals\), \(k > 1\).
        Formally what this means is that there exists \(r \in\reals\) such that for all \(z\) satisfying \(\abs{z} > r\) we have \(\abs{f(z)}\le M/R^k\).
        Then if \(C_R\) is a segment of a circle from \(\vartheta_1\) to \(\vartheta_2\) with radius \(R\) we have
        \[\lim_{R\to\infty} \int_{C_R} f(z) \dd{z} = 0.\]
    \end{lemma}
    \begin{proof}
        Let \(f\) be a function with the specified behaviour far from the origin.
        Then we can parametrise the arc \(C_R\) as \(C_R(\vartheta) = Re^{i\vartheta}\) so \(C_R'(\vartheta) = iRe^{i\vartheta}\).
        Hence
        \begin{align*}
            \lim_{R\to\infty}\abs{\int_{C_R} f(z) \dd{z}} &\le \lim_{R\to\infty} \int_{C_R} \abs{f(z) \dd{z}}\\
            &\le \lim_{R\to\infty} \int_{C_R} \frac{M}{R^k}\abs{\dd{z}}\\
            &= \lim_{R\to\infty} \int_{0}^{\pi} \frac{MR}{R^k}\dd{\vartheta}\\
            &\le \lim_{R\to\infty} \frac{M\pi}{R^{k-1}}\\
            &= 0.
        \end{align*}
    \end{proof}
    This result isn't particularly useful on its own but it allows us to prove the next lemma which is.
    \begin{lemma}{Jordan's Lemma}{}
        Let \(f\colon\complex\to\complex\) be meromorphic.
        Let \(\abs{f(z)} \le M/R^k\) for all \(\abs{z} > R_0\) for some \(R_0\in\reals\).
        Let \(C_R\) be a semicircular arc of radius \(R > R_0\) from 0 to \(\pi\) in the upper half plane.
        Let \(m\) be some positive real number.
        Then
        \[\lim_{R\to\infty} \int_{C_R} f(z)e^{imz} \dd{z} = 0.\]
    \end{lemma}
    \begin{proof}
        We start by bounding the integral.
        To do this we will use the same parametrisation as the last proof.
        \begin{align*}
            \lim_{R\to\infty} \abs{\int_{C_R} f(z)e^{imz}\dd{z}} &\le \lim_{R\to\infty} \int_{C_R} \abs{f(z)e^{imz}\dd{z}}\\
            &= \lim_{R\to\infty} \int_{C_R} \abs{f(z)} \abs{\exp[imR\cos\vartheta - mR\sin\vartheta]}\abs{\dd{z}}\\
            &\le \lim_{R\to\infty} \int_{0}^{\pi} \frac{M}{R^{k}}\exp[-mR\sin\vartheta]R\dd{\vartheta}\\
            &= \lim_{R\to\infty} \frac{2M}{R^{k-1}} \int_{0}^{\pi/2} e^{-mR\sin\vartheta}\dd{\vartheta}.
        \end{align*}
        In this last step we have used the fact that \(\sin\vartheta = \sin(\pi - \vartheta)\) and so
        \[\int_{0}^{\pi} e^{-mR\sin\vartheta} \dd{\vartheta} = 2\int_{0}^{\pi/2} e^{-mR\sin\vartheta}\dd{\vartheta}\]
        since \(\sin\) is even on the interval \([0, \pi]\).
        
        \(\sin\) is a monotonically increasing convex function on \([0, \pi/2]\).
        At \(\vartheta = 0\) we have \(\sin 0 = 0\) and at \(\vartheta = \pi/2\) we have \(\sin(\pi/2) = 1\).
        Hence at the points \(\vartheta = 0, \pi/2\) the equality \(\sin\vartheta = 2\vartheta/\pi\) holds.
        Since between these points \(\sin\) is monotonically increasing and convex it the equality between the points doesn't hold but becomes an inequality:
        \[\sin\vartheta \ge \frac{2}{\pi}\vartheta, \qquad\text{for}~\vartheta\in[0, \pi/2].\]
        This is known as \define{Jordan's inequality}.
        We can use it to further bound our integral:
        \begin{align*}
            \int_{0}^{\pi/2} e^{-mR\sin\vartheta} \dd{\vartheta} &\le \int_{0}^{\pi/2} e^{-mR2\vartheta/\pi} \dd{\vartheta}\\
            &= -\frac{\pi}{2mR}[e^{-mR2\vartheta/\pi}]_{0}^{\pi/2}\\
            &= \frac{\pi}{2mR}(1 - e^{-mR}).
        \end{align*}
        Applying this to our bound we have
        \[\lim_{R\to\infty} \abs{\int_{C_R} f(z)e^{imz}\dd{z}} \le \lim_{R\to\infty} \frac{\pi M}{mR^k}(1 - e^{-mR}) = 0\]
        since both \(k, m > 0\).
    \end{proof}
    The methods we have seen previously for bounding integrals would still work here except we would find a polynomial limit and would need \(f(z)/R^{k-1} \to 0\) instead with Jordan's lemma we only need \(f(z)/R^{k} \to 0\) which allows an extra factor of \(R\) in \(f\).
    There is an analogous limit when \(m < 0\) and the proof is similar but we integrate over a semicircle in the lower half plane.
    In the case of \(m = 0\) we can't do better than the \(R^{-k+1}\) bounding.
    
    \subsection{Indentation Lemma}
    Suppose we have a contour but at some point on the contour the function we wish to integrate is singular.
    We can sometimes get around this by deviating slightly from the contour along a circular arc.
    We then take the radius of this arc to zero and hope that the contribution from the arc vanishes.
    \begin{lemma}{Indentation Lemma}{}
        Let \(f\colon\discPunctured{z_0}{r}\to\complex\) be analytic and let \(z_0\) be a simple pole of \(f\).
        We define an indentation around \(z_0\) as the contour parametrised by \(C_{\rho} = z_0 + \rho e^{i\vartheta}\) where \(\rho \in (0, r)\) and \(\vartheta \in [\vartheta_{1}, \vartheta_{2}]\).
        Then
        \[\lim_{\rho\to 0} \int_{C_{\rho}} f(z) \dd{z} = (\vartheta_{2} - \vartheta_1) i \Res(f, z_0).\]
    \end{lemma}
    \begin{proof}
        Since \(f\) has a simple pole at \(z_{0}\) the residue is
        \[\Res(f, z_0) = \lim_{z\to z_0} (z - z_0)f(z).\]
        Then by the definition of the limit for a given \(\varepsilon > 0\) there exists \(\delta\) such that \(\abs{(z - z_0)f(z) - \Res(f, z_0)} < \delta\).
        On the arc, \(C_{\rho}\), we have \(\dd{z} = i\rho e^{i\vartheta} \dd{\vartheta} = i(z - z_0)\dd{\vartheta}\).
        It is actually simpler to consider the difference between the two sides of the equation and show that the difference is zero:
        \begin{align*}
            \abs{\int_{C_{\varepsilon}} f(z) \dd{z} - (\vartheta_2 - \vartheta_1)i\Res(f, z_0)} &= \abs{\int_{C_\varepsilon} f(z) \dd{z} - \int_{\vartheta_1}^{\vartheta_2} i\Res(f, z_0) \dd{\vartheta}}\\
            &= \abs{\int_{\vartheta_1}^{\vartheta_2} i[(z - z_0)f(z) - \Res(f, z_0)]\dd{\vartheta}}\\
            &\le \delta \abs{\vartheta_2 - \vartheta_1}
        \end{align*}
        By choosing sufficiently small \(\varepsilon\) we can make \(\delta\) arbitrarily small and so
        \[\int_{C_{\varepsilon}} f(z) \dd{z} - (\vartheta_2 - \vartheta_1)i\Res(f, z_0) = 0\]
        which proves the theorem.
    \end{proof}
    
    \subsection{Integral of \texorpdfstring{\(\sinc\)}{sinc}}
    The un-normalised \(\sinc\) function is defined as
    \[
        \sinc(x) = 
        \begin{cases}
            \frac{\sin x}{x}, & \text{if}~x\ne 0,\\
            0, & \text{if}~x = 0.
        \end{cases}
    \]
    It is common to require the integral
    \[I = \int_{-\infty}^{\infty} \sinc x \dd{x}.\]
    We can use the lemmas proved in this section to compute this value.
    
    We cannot easily integrate \(\sinc z\) for complex \(z\) as this is unbounded, in particular
    \[\lim_{y\to \infty} \abs{\sinc(iy)} = \infty\]
    Instead we consider \(f(z) = e^{iz}/z\).
    We integrate this over the contour shown in figure~\ref{fig:sinc contour}
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{sinc-contour}
        \begin{tikzpicture}
            \draw[->, >=latex] (-4, 0) -- (4, 0) node[right] {\(\Re\)};
            \draw[->, >=latex] (0, -1) -- (0, 4) node[above] {\(\Im\)};
            \draw[ultra thick] (3, 0) arc(0:180:3) -- (-0.25, 0) arc(180:0:0.25) -- (3, 0) -- cycle;
            \draw[->, >=latex, ultra thick] (44:3) arc(44:46:3);
            \draw[->, >=latex, ultra thick] (134:3) arc(134:136:3);
            \draw[->, >=latex, ultra thick] (1.49, 0) -- (1.51, 0);
            \draw[->, >=latex, ultra thick] (-1.51, 0) -- (-1.49, 0);
            \draw[red, fill=red] (0, 0) circle[radius=0.05cm];
            \node[below] at (3, 0) {\(R\)};
            \node[below] at (-3, 0) {\(-R\)};
            \node[below] at (0.25, 0) {\(\rho\)};
            \node[below] at (-0.3, 0.1) {\(-\rho\)};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The contour used to find the integral of \(\sinc x\).}
        \label{fig:sinc contour}
    \end{figure}
    Let \(C_R\) be the outer semicircle of radius \(R\) and \(C_\rho\) be the inner semicircle of radius \(\rho\).
    Let \(\gamma\) be the entire contour.
    Then we see that
    \[\oint_{\gamma} f(z) \dd{z} = \int_{\gamma_R} f(z) \dd{z} + \int_{\gamma_\rho} f(z) \dd{z} + \int_{\rho}^{R} f(z) \dd{z} + \int_{-R}^{-\rho} f(z) \dd{z}.\]
    Considering first the integrals along the real axis we can compute these together:
    \begin{align*}
        \int_{-R}^{-\rho} f(z) \dd{z} + \int_{\rho}^{R} f(z) \dd{z} &= \int_{-R}^{-\rho} \frac{e^{iz}}{z} \dd{z} + \int_{\rho}^{R} \frac{e^{iz}}{z} \dd{z}\\
        &= \int_{-R}^{-\rho} \frac{\cos x}{x} \dd{x} + \int_{\rho}^{R} \frac{\cos x}{x}\dd{x} + i\left[ \int_{-R}^{-\rho} \frac{\sin x}{x} \dd{x} + \int_{\rho}^{R} \frac{\sin x}{x} \dd{x} \right]\\
        &= -\int_{-\rho}^{-R} \frac{\cos x}{x} \dd{x} + \int_{\rho}^{R} \frac{\cos x}{x}\dd{x} + i\left[ -\int_{-\rho}^{-R} \frac{\sin x}{x} \dd{x} + \int_{\rho}^{R} \frac{\sin x}{x} \dd{x} \right]\\
        &= i\left[ \int_{\rho}^{R} \frac{\sin x}{x} \dd{x} + \int_{\rho}^{R} \frac{\sin x}{x} \dd{x} \right]\\
        &= 2i\int_{\rho}^{R} \frac{\sin x}{x}\dd{x}
    \end{align*}
    Here we have used the symmetry of \(\cos\) and \(\sin\). Since \(\cos\) is even the integral over \((-R, -\rho)\) and \(\rho, R\) are equal and so the integral cancel.
    Similarly for the \(\sin\) integrals the integrals over these intervals differ only by a sign and therefore combine together.
    Further
    \[\lim_{\rho\to 0}\lim_{R\to\infty} \left[ \int_{-R}^{-\rho} f(z) \dd{z} + \int_{\rho}^{R} f(z) \dd{z} \right] = 2i\int_{0}^{R} \frac{\sin x}{x}\dd{x} = \int_{-\infty}^{\infty} \frac{\sin x}{x} \dd{x} = iI.\]
    Here we have used the fact that \(\sin\) and \(1/x\) are odd functions so \(\sin(x)/x\) is even.
    
    For the integral over \(C_R\) we can use Jordan's Lemma which readily implies
    \[\lim_{R\to\infty} \int_{C_R} f(z) \dd{z} = \lim_{R\to\infty} \int_{C_R} \frac{e^{iz}}{z} \dd{z} = 0.\]
    For the integral over \(C_\rho\) we can use the indentation lemma as the pole at \(z = 0\) is simple.
    We transverse the small semicircle starting at \(\vartheta_1 = \pi\) and ending at \(\vartheta_2 = 0\).
    It is also simple to compute the residue:
    \[\Res(f, 0) = e^{iz}|_{z = 0} = 1\]
    and so
    \[\lim_{\rho\to 0} \int_{C_\rho} f(z) \dd{z} = i(\vartheta_2 - \vartheta_1)\Res(f, 0) = i(0 - \pi)1 = -i\pi.\]
    Since there are no singularities inside the contour we have
    \[\oint_{\gamma} f(z) \dd{z} = 0\]
    by Cauchy's theorem.
    Hence
    \[\oint_{\gamma} f(z) \dd{z} = 0 = 0 - i\pi + iI \implies I = \int_{-\infty}^{\infty} \frac{\sin x}{x} = \pi.\]
    
    \section{Integral Reinforcement and Series}
    \subsection{Integral Reinforcement}
    Most of the examples we have seen so far of real integrals computed with complex analysis have been done by finding a contour which coincides with the interval we are integrating and hoping that all other contributions to the integral are either zero or easy to compute.
    This isn't always the case.
    Sometimes the best we can do is find a contour which we can split into sections each of which results in an integral proportional to the integral we want.
    This is best shown with an example.
    
    Evaluate
    \[I = \int_{0}^{\infty} \frac{1}{x^5 + a^5}\dd{x}\]
    for some positive real number \(a\).
    To do this we consider
    \[f(z) = \frac{1}{z^5 + a^5}\]
    integrated along the contour shown in figure~\ref{fig:1/x^5 + a^5 contour}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{pie-slice-contour}
        \begin{tikzpicture}
            \draw[<->, >=latex] (4, 0) -- (0, 0) -- (0, 4);
            \draw (-2, 0) -- (0, 0) -- (0, -2);
            \node[right] at (4, 0) {\(\Re\)};
            \node[above] at (0, 4) {\(\Im\)};
            \draw[ultra thick] (0, 0) -- (3, 0) arc(0:72:3) -- cycle;
            \draw[->, >=latex, ultra thick] (1.49, 0) -- (1.51, 0);
            \draw[->, >=latex, ultra thick] (35:3) arc(35:37:3);
            \draw[->, >=latex, ultra thick] (72:1.51) -- (72:1.49);
            \foreach \x in {1,3,...,10} {
                \draw[red, fill=red] (36*\x:1) circle[radius=0.05cm];
            }
            \node[below] at (3, 0) {\(R\)};
            \node[above] at (72:3) {\(Re^{2i\pi/5}\)};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The contour used to integrate \(1/(x^5 + a^5)\).}
        \label{fig:1/x^5 + a^5 contour}
    \end{figure}
    This contour has three sections.
    The horizontal section corresponds to the integral we want.
    The function \(f\) has singularities whenever \(z_n = ae^{i\pi/5 + 2n\pi/5}\) for \(n = 0, 1, 2, 3, 4\).
    These are all simple poles as we can factorise the denominator and each only appears once.
    Hence
    \[\Res(f, z_n) = \lim_{z\to z_n} \frac{z - z_n}{z^5 + a^5} = \lim_{z\to z_n} \frac{1}{5z^4} = \frac{1}{5a^4e^{i\pi/5 + 2i\pi n/5}}.\]
    Only one of these singularities is actually inside the contour and hence
    \[\oint_{\gamma} f(z) \dd{z} = 2\pi i\Res(f, z_0) = \frac{2\pi i}{5a^4e^{4i\pi/5}}.\]
    By Jordan's lemma the integral over the circular arc vanishes as \(R\to\infty\).
    We need to consider the integral over the line from \(z = Re^{2i\pi i/5}\) to \(z = 0\).
    We can parametrise this part of the contour as \(z = xe^{2i\pi/5}\) for \(x \in (0, R)\).
    We then have \(\dd{z} = e^{2i\pi/5}\dd{x}\) and so the integral over this line is
    \[\int_{R}^{0} \frac{e^{2i\pi/5}}{x^5e^{2i\pi} + a^5}\dd{x} = -e^{2i\pi/5} \int_{0}^{R} \frac{1}{x^5 + a^5} \dd{x} \to -e^{2i\pi/5}I.\]
    Hence in the limit of \(R\to \infty\) we have
    \begin{align*}
        \oint_{\gamma} f(z) \dd{z} &= \frac{2\pi i}{5a^4 e^{4i\pi/5}}\\
        &= (1 - e^{2i\pi/5})I\\
        \implies I &= \int_{0}^{\infty} \frac{1}{x^5 + a^5} \dd{x}\\
        &= \frac{\pi}{5a^4e^{4i\pi/4}} \frac{2i}{1 - e^{2\pi i/5}}\\
        &= \frac{\pi}{5a^4 (e^{i\pi/5} - e^{-i\pi/5})}\\
        &= \frac{\pi}{5a^4\sin(\pi/5)}.
    \end{align*}

    \subsection{Series}
    We have seen that summing residues can give us the value of an integral but we can turn this on its head and use an integral to give us the value of a series.
    We simply need to find a function, \(f\), such that the residues of \(f\) in some contour of our choosing correspond to the terms of the sum (up to a factor of \(2\pi i\)) and then we hope that we can compute the integral of \(f\).
    This is best demonstrated with an example.
    
    Show that
    \[\zeta(2) = \sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^{2}}{6}.\]
    The first thing we need to do is find a function with residues equal to \(1/n^2\).
    We saw in example~\ref{exa:residues of pi cot pi z} that \(f(z) = \pi\cot(\pi z)\) has residues at \(z = n \in\integers\) and that \(\Res(f, n) = 1\).
    Consider a general function \(f\) which has a simple pole at \(z_0\) which has residue \(a\).
    Now consider a second function, \(g\), which is analytic at \(z_0\) and \(g(z_0) \ne 0\).
    We can write the product, \(fg\), using the Laurent series of \(f\):
    \[(fg)(z) = f(z)g(z) = g(z)\left[ \frac{a}{z - z_0} + \sum_{n=0}^{\infty} c_n(z - z_0)^n \right]\]
    and so
    \[\Res(fg, z_0) = g(z)(z - z_0)\left[ \frac{a}{z - z_0} + \sum_{n=0}^{\infty} c_n(z - z_0)^n \right] \Bigg|_{z = z_0} = ag(z_0). \]
    Hence for the specific case of \(f(z) = \pi\cot(\pi z)\) we have \(\Res(fg, n) = g(z_0).\)
    So we simply need to choose a function such that \(g(n) = 1/n^2\) for all \(n\in\integers\).
    The analytic function satisfying this is \(g(z) = 1/z^2\).
    Hence for \(n \ne 0\) we have
    \[\Res(fg, n) = \frac{1}{n^2}.\]
    For \(n = 0\) we have to do a little more work.
    Expanding \(fg\) as a Laurent series at the origin we have
    \begin{align*}
        (fg)(z) &= \frac{\pi}{z^2}\cot(\pi z)\\
        &= \frac{\pi}{z^2} \frac{1 - \frac{(\pi z)^2}{2!} + \frac{(\pi z)^4}{4!} + \dotsb}{\pi z - \frac{(\pi z)^3}{3!} + \frac{(\pi z)^5}{5!} + \dotsb}\\
        &= \frac{1}{z^3} \left[ 1 + (\pi z)^2\left( \frac{1}{6} - \frac{1}{2} \right) + \dotsb \right]
    \end{align*}
    so
    \[\Res(fg, 0) = -\frac{\pi^3}{3}.\]
    We now have a function that, for \(n\in\integers_{>0}\), has the required residue \(\Res(fg, n) = 1/n^2\).
    We now need to choose a contour that includes all of these residues and is also easy to integrate over.
    The contour of choice turns out to be a rectangle, shown in figure~\ref{fig:contour for zeta(2)}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{rectangular-contour-for-summing-series}
        \begin{tikzpicture}
            \draw[->, >=latex] (-4, 0) -- (4, 0) node[right] {\(\Re\)};
            \draw[->, >=latex] (0, -4) -- (0, 4) node[above] {\(\Im\)};
            \draw[ultra thick] (-3, -3) rectangle (3, 3);
            \draw[->, >=latex, ultra thick] (3, 1.49) -- (3, 1.51);
            \draw[->, >=latex, ultra thick] (-1.49, 3) -- (-1.51, 3);
            \draw[->, >=latex, ultra thick] (-3, -1.49) -- (-3, -1.51);
            \draw[->, >=latex, ultra thick] (1.49, -3) -- (1.51, -3);
            \foreach \x in {0, 0.5, 1, -0.5, -1, 2.75, 3.25, -2.75, -3.25} {
                \draw[red, fill=red] (\x, 0) circle[radius=0.05cm];
            }
            \foreach \x in {1, 2, -1, -2} {
                \node[below] at (\x/2, 0) {\(\x\)};
            }
            \node[below left] at (2.75, 0) {\(N\)};
            \node[below right] at (3.25, 0) {\(N + 1\)};
            \node[below right] at (-2.75, 0) {\(-N\)};
            \node[below left] at (-3.25, 0) {\(-N - 1\)};
            \node[above right] at (3, 3) {\(A\)};
            \node[below right] at (3, -3) {\(A^*\)};
            \node[below left] at (-3, -3) {\(-A\)};
            \node[above left] at (-3, 3) {\(-A^*\)};
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{Contour used to evaluate \(\zeta(2)\). The point \(A\) is \(A = (N + 1/2)(1 + i)\).}
        \label{fig:contour for zeta(2)}
    \end{figure}
    This contour contains all \(n\in\integers_{> 0}\) but also all \(n\in\integers_{\le 0}\).
    This integral vanishes in the limit of \(N \to \infty\), which is fairly easy to show using the ML lemma:
    \begin{align*}
        \abs{\oint_{\gamma} f(z) \dd{z}} &\le 8\left( N + \frac{1}{2} \right) \pi \max_{\gamma} \abs{\frac{\cot(\pi z)}{z^2}}\\
        &\le \frac{8\pi}{N + \frac{1}{2}} \max_{\gamma} \abs{\cot \pi z}.
    \end{align*}
    Here we have used \(N + 1/2 > 1\) and on \(\gamma\) we have \(\abs{z} \le N + 1/2\) so replacing \(\abs{1/z^2}\) with \((N + 1/2)^{-2}\) gives us the result above.
    The integral will then vanish as long as \(\max_{\gamma}\abs{\cot(\pi z)}\) is finite.
    We can show that this is the case.
    First consider the horizontal lines which we can parametrise as \(z = x \pm i(N + 1/2)\) giving
    \begin{align*}
        \abs{\cot(\pi z)} &= \abs{\frac{\cos(\pi z)}{\sin(\pi z)}}\\
        &= \abs{\frac{\exp\left[ i\pi x \mp \pi\left( N + \frac{1}{2} \right) \right] + \exp\left[ -i\pi x\pm \pi\left( N + \frac{1}{2} \right) \right]}{\exp\left[ i\pi x \mp \pi\left( N + \frac{1}{2} \right) \right] - \exp\left[ -i\pi x\pm \pi\left( N + \frac{1}{2} \right) \right]}}\\
        &\le \abs{\frac{\exp\left[ \mp \pi\left( N + \frac{1}{2} \right) \right] + \exp\left[ \pm \pi\left( N + \frac{1}{2} \right) \right]}{\exp\left[ \mp \pi\left( N + \frac{1}{2} \right) \right] - \exp\left[ \pm \pi\left( N + \frac{1}{2} \right) \right]}}\\
        &= \coth\left( \pi\left( N + \frac{1}{2} \right) \right)
    \end{align*}
    this is finite as \(\lim_{x\to\infty} \coth x = 1\).
    For the vertical lines we can parametrise \(z = \pm \pi(N + 1/2) + iy\) which, after using trig addition formulae, gives
    \begin{align*}
        \abs{\cot(\pi z)} &= \abs{\frac{\cos(\pm \pi(N + 1/2) + i\pi y)}{\sin(\pm \pi(N + 1/2) + i\pi y)}}\\
        &= \abs{\frac{(-1)^N\sin(i\pi y)}{(-1)^N\cos(i\pi y)}}\\
        &= \abs{\tanh(\pi y)}\\
        &\le 1.
    \end{align*}
    So \(\abs{\cot(\pi z)}\) is bounded on \(\gamma\) and therefore the integral vanishes.
    We then have
    \begin{align*}
        0 &= \lim_{N\to\infty} \oint_{\gamma} (fg)(z) \dd{z}\\
        &= \lim_{N \to \infty} \sum_{n=-N}^{N} \frac{1}{n^2}\\
        &= \lim_{N\to\infty} 2\pi i\left[ \Res(fg, 0) + \sum_{n=1}^{N} \Res(fg, n) + \sum_{n=-N}^{-1} \Res(fg, n) \right]\\
        &= \lim_{N\to\infty} 2\pi i\left[ \Res(fg, 0) + \sum_{n=1}^{N} \frac{1}{n^2} + \sum_{n=-N}^{-1} \frac{1}{n^2} \right]\\
        &= \lim_{N\to\infty} 2\pi i\left[ -\frac{\pi^2}{3} + \sum_{n=1}^{N} \frac{1}{n^2} + \sum_{n=1}^{N} \frac{1}{n^2} \right]\\
        &= \lim_{N\to\infty} 2\pi i\left[ -\frac{\pi^2}{3} + 2\sum_{n=1}^{N} \frac{1}{n^2} \right]\\
        &= 2\pi i\left[ -\frac{\pi^2}{3} + 2\sum_{n=1}^{\infty} \frac{1}{n^2} \right]
    \end{align*}
    \[\implies \sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}.\]
    
    The exact choice of the function to integrate depends on the series we wish to sum but there are a few common choices:
    \begin{align*}
        \sum_{n=-\infty}^{\infty} g(n) &\longleftrightarrow \oint g(z) \pi \cot(\pi z) \dd{z}\\
        \sum_{n=-\infty}^{\infty} (-1)^n g(n) &\longleftrightarrow \oint g(z) \pi \cosec(\pi z) \dd{z}\\
        \sum_{n=-\infty}^{\infty} g(n + 1/2) &\longleftrightarrow \oint g(z) \pi \tan(\pi z) \dd{z}\\
        \sum_{n=-\infty}^{\infty} (-1)^ng(n + 1/2) &\longleftrightarrow \oint g(z) \pi \sec(\pi z) \dd{z}.
    \end{align*}
    All of these will commonly be integrated over a square but make sure to choose the corners such that the square doesn't intersect any of the singularities.
    This means in the first two cases choose the vertex \(A = (N + 1/2)(1 + i)\) and in the second two \(A = N(1 + i)\).
    
    \section{Principle Values and Multivalued Functions}
    \subsection{Principle Value}
    Often it is possible to compute an integral over some interval even if parts of the integrand diverge over those limits.
    For example consider
    \[\lim_{a\to\infty} \int_{0}^{a} x \dd{x} = \infty.\]
    However since \(x\) is an odd function we have
    \[\lim_{a\to\infty} \int_{-a}^{a} x \dd{x} = 0.\]
    Normally we could split the integral into two parts over \((-a, 0)\) and \((0, a)\) but that is not the case here as these two individual integrals diverge in such a way that they just happen to cancel out.
    When this is the case we say that this is a \define{principle value integral} or a Cauchy principle value integral\footnote{because what we really need at this point in the course is something else named after Cauchy.}.
    If we are aware that an integral cannot be split in this way we denote it with one of the following notations:
    \[\mathrm{P.V.} \int_{a}^{b} f(x)\dd{x}, \qquad\text{or}\qquad \pvint_{a}^{b} f(x) \dd{x}.\]
    An example may be for some positive real numbers \(a\) and \(b\)
    \[\pvint_{-a}^{b} \frac{1}{x}\dd{x} = \log b - \log a = \log\frac{b}{a}\]
    even though \(\log\) is undefined at \(0 \in (-a, b)\).
    The way to deal with these integrals formally is by missing out the problematic points with a limit.
    For example if \(f\) has a singularity at \(x_0 \in (a, b)\) then
    \[\pvint_{a}^{b} f(x) \dd{x} = \lim_{\varepsilon\to 0^+} \left[ \int_{a}^{x_0 - \varepsilon} f(x) \dd{x} + \int_{x_0 + \varepsilon}^{b} f(x) \dd{x} \right].\]
    This notation suggests that the correct way to deal with these sorts of integrals in the complex plane is with and indentation of radius \(\varepsilon\), and this is indeed the case.
    
    \begin{example}
        \itshape
        Evaluate the following principle value integral:
        \[\pvint_{-\infty}^{\infty} \frac{1}{x^2 - 4}\dd{x}.\]
        \normalfont
        The obvious choice is to integrate \(f(z) = 1/(z^2 - 4)\) over a semicircle in the upper half plane.
        The problem with this is that \(f\) is singular at \(z = \pm 2\).
        We can avoid these problem points with indentations.
        If we choose these indentations to be semicircles in the upper half plane then there are no singularities in the contour and so the integral over the closed contour is zero.
        Hence we have
        \begin{align*}
            0 &= \oint_{\gamma} f(z) \dd{z}\\
            &= \int_{-R}^{-2-\varepsilon} \frac{1}{z^2 - 4}\dd{z} + \int_{-2+\varepsilon}^{2-\varepsilon} \frac{1}{z^2 - 4} \dd{z} + \int_{2 + \varepsilon}^{R} \frac{1}{z^2 - 4} \dd{z} + \int_{C_R} \frac{1}{z^2 - 4}\dd{z} + \int_{\gamma_{\varepsilon^-}} \frac{1}{z^2 - 4}\dd{z} + \int_{\gamma_{\varepsilon^+}} \frac{1}{z^2 - 4}\dd{z}.
        \end{align*}
        In the limit of \(R \to 0\) the first three integrals become the principle value integral we wish to compute, the integral over \(\gamma_R\) vanishes by Jordan's lemma, and the integrals over \(\gamma_{\varepsilon^{\pm}}\) can be evaluated by the indentation lemma:
        \begin{align*}
            0 &= i(0 - \pi)[\Res(f, -2) + \Res(f, 2)] \pvint_{-\infty}^{\infty} \frac{1}{x^2 - 4}\dd{x}\\
            &= -i\pi(\frac{1}{-2-2} + \frac{1}{2+2}) + \pvint_{-\infty}^{\infty} \frac{1}{x^2 - 4} \dd{x}\\
             \implies &\pvint_{-\infty}^{\infty} \frac{1}{x^2 - 4} \dd{x} = 0.
        \end{align*}
    \end{example}
    
    \subsection{Multivalued Functions}
    We saw in sections~\ref{sec:branch points} and~\ref{sec:branch cuts} that functions involving logarithms or roots lead to multivalued functions and that to have a properly defined function we need to make a branch cut.
    A branch cut joins two branch points in such a way that the function becomes singular.
    This always results in a discontinuity which means that most of the theorems we have developed so far won't work if our contour crosses or contains a branch cut/point.
    This is because branch cuts/points are non-isolated singularities and therefore do not admit a Laurent series at this point.
    The easiest way round this is simply to ensure that we never have a branch cut/point inside our contour.
    
    \begin{example}
        \itshape For \(\alpha\in(0, 1)\) evaluate
        \[I = \int_{0}^{\infty} \frac{x^{\alpha - 1}}{x + 1} \dd{x}.\]
        \normalfont
        We consider the function
        \[f(z) = \frac{z^{\alpha - 1}}{z + 1}.\]
        This has two branch points, at \(z = 0, \infty\).
        We choose a branch cut to join these two points along the positive real axis.
        This corresponds to the choice \(0 < \arg z < 2\pi\).
        The contour that we use for this problem is shown in figure~\ref{fig:keyhole contour}.
        This is commonly called a \define{keyhole contour}.
        \begin{figure}[ht]
            \centering
            \tikzexternalenable
            \tikzsetnextfilename{keyhole-contour}
            \begin{tikzpicture}
                \draw[->, >=latex] (-4, 0) -- (4, 0) node[right] {\(\Re\)};
                \draw[->, >=latex] (0, -4) -- (0, 4) node[above] {\(\Im\)};
                \draw[red, very thick] (0, 0) -- (3.8, 0);
                \coordinate (A) at (2:3);
                \coordinate (B) at (358:3);
                \coordinate (O) at (0, 0);
                % Next line extracts x and y coords from A
                \path (A); \pgfgetlastxy{\xcoord}{\ycoord};
                \draw[ultra thick] (O|-A) -- (2:3) arc(2:358:3) -- (O|-B) arc(270:90:\ycoord) -- cycle;
                \draw[blue, fill=blue] (-1, 0) circle[radius=0.04cm] node[below, black] {\(-1\)};
            \end{tikzpicture}
            \tikzexternaldisable
            \caption{A keyhole contour for a branch cut from \(0\) to \(\infty\) along the positive real axis.}
            \label{fig:keyhole contour}
        \end{figure}
        This contour, \(\gamma\), can be split into four parts.
        First the outer circle, \(\gamma_R\), second the inner indentation, \(\gamma_{\varepsilon}\), which as drawn goes from \(3\pi/2\) to \(\pi/2\) but any angle that takes us around the origin works, and the final two sections are the straight lines just above and just below the real axis.
        
        The function \(f\) has a one singularity at \(z = -1\) and the residue at this point is
        \[\Res(f, -1) = z^{\alpha - 1}|_{z = -1} = (-1)^{\alpha - 1} = e^{(\alpha - 1)\pi i}.\]
        Hence
        \[\oint_{\gamma} f(z) \dd{z} = 2\pi ie^{\pi i(\alpha - 1)}\]
        For the integral around the outer circle we have
        \begin{align*}
            \lim_{R\to\infty} \abs{\int_{\gamma_R} f(z)\dd{z}} &\le \lim_{R\to\infty} \int_{\gamma_R} \abs{f(z)\dd{z}}\\
            &= \lim_{R\to\infty} \int_{\gamma_R} \abs{\frac{z^{\alpha - 1}}{z + 1}}\abs{\dd{z}}\\
            &= \lim_{R\to\infty} \int_{0}^{2\pi} \frac{\abs{R^{(\alpha - 1)}e^{i\vartheta(\alpha - 1)}}}{\abs{Re^{i\vartheta} + 1}}\abs{iRe^{i\vartheta}}\dd{\vartheta}\\
            &\le \lim_{R\to\infty} \int_{0}^{2\pi} \frac{R^\alpha}{R - 1}\dd{\vartheta}\\
            &= \lim_{R\to\infty} 2\pi \frac{R^{\alpha}}{R - 1}\\
            &= 0
        \end{align*}
        where we have used the fact that \(\alpha < 1\) so \(R^{\alpha}/(R - 1) \sim R^{\alpha - 1}\) vanishes as does the integral around the outer circle.
        A similar treatment of the indentation gives
        \begin{align*}
            \lim_{\varepsilon\to0} \abs{\int_{\gamma_\varepsilon} f(z)\dd{z}} &= \lim_{\varepsilon\to0} \int_{\gamma_\varepsilon} \abs{f(z)\dd{z}}\\
            &= \lim_{\varepsilon\to0} \int_{\gamma_\varepsilon} \frac{\abs{z^{\alpha - 1}}}{\abs{z - 1}} \abs{\dd{z}}\\
            &= \lim_{\varepsilon\to0} \int_{\pi/2}^{3\pi/2} \frac{\abs{\varepsilon e^{i\vartheta(\alpha - 1)}}}{\abs{\varepsilon e^{i\vartheta} + 1}}\abs{i\varepsilon e^{i\vartheta}}\dd{\vartheta}\\
            &\le \lim_{\varepsilon\to0} \int_{\pi/2}^{3\pi/2} \frac{\varepsilon^{\alpha}}{1 - \varepsilon} \dd{\vartheta}\\
            &= \lim_{\varepsilon\to0} \pi \frac{\varepsilon^{\alpha}}{1 - \varepsilon}\\
            &= 0
        \end{align*}
        Note that we \emph{cannot} use the indentation lemma here as \(z = 0\) is a branch point and therefore \emph{not} a simple pole as the indentation lemma requires (it doesn't even make sense to try to compute a residue at \(z = 0\) as there is no Laurent series there).
        
        The integral over the line just above the real axis reduces to the target integral.
        For the integral just below the real axis we can parametrise this line as \(z = x - i\varepsilon \approx xe^{2\pi i}\) (technically this should be \(z = x^{i\varphi}\) and then take the limit \(\varphi \to 2\pi\) from below).
        Then we have
        \begin{align*}
            \lim_{R\to\infty} \int_{R - i\varepsilon}^{i\varepsilon} \frac{z^{\alpha - 1}}{z + 1}\dd{z} &= \int_{\infty}^{0} \frac{x^{\alpha - 1}e^{2\pi i(\alpha - 1)}}{x + 1} \dd{x}\\
            &= -e^{2\pi i(\alpha - 1)}\int_{0}^{\infty} \frac{x^{\alpha - 1}}{x + 1} \dd{x}\\
            &= -e^{2\pi i(\alpha - 1)} I.
        \end{align*}
        Combining all of these integrals we have
        \[\oint_{\gamma} f(z) \dd{z} = 2\pi ie^{\pi i(\alpha - 1)} = I(1 - e^{2\pi i(\alpha - 1)})\]
        and so
        \[I = \frac{2\pi ie^{\pi i(\alpha - 1)}}{1 - e^{2\pi i(\alpha - 1)}} = \frac{2\pi i}{e^{-\pi i(\alpha - 1)} + e^{\pi i(\alpha - 1)}} = \frac{\pi}{-\sin[\pi(\alpha - 1)]} = \frac{\pi}{\sin[\pi(1 - \alpha)]}.\]
        As a sanity check since \(x^{\alpha - 1}/(x + 1) \ge 0\) for all \(x \in (0, \infty)\) we expect that the integral is positive and real, which is indeed the case since \(\pi(1 - \alpha)\in(0, 1\pi)\) and \(\sin\) is positive on this interval.
    \end{example}
    
    \begin{example}
        \itshape
        For \(a > 0\) evaluate
        \[I = \int_{0}^{\infty} \frac{\log x}{x^2 + a^2} \dd{x}.\]
        \normalfont
        We do this by considering the function
        \[f(z) = \frac{\log z}{z^2 + a^2}.\]
        This has two simple poles, at \(z = \pm ia\).
        Further \(f\) has two branch points at \(z = 0, \infty\).
        The contour that we will use to evaluate this function is shown in figure~\ref{fig:contour for log x/x^2 + a^2}.
        \begin{figure}[ht]
            \centering
            \tikzexternalenable
            \tikzsetnextfilename{semicircle-contour-with-branch-cut}
            \begin{tikzpicture}
                \draw[->, >=latex] (-4, 0) -- (4, 0) node[right] {\(\Re\)};
                \draw[->, >=latex] (0, -2) -- (0, 4) node[above] {\(\Im\)};
                \draw[ultra thick] (0.25, 0) -- (3, 0) arc(0:180:3) -- (-0.25, 0) arc(180:0:0.25) -- cycle;
                \draw[->, >=latex, ultra thick] (1.49, 0) -- (1.51, 0);
                \draw[->, >=latex, ultra thick] (44:3) arc(44:46:3);
                \draw[->, >=latex, ultra thick] (134:3) arc(134:136:3);
                \draw[->, >=latex, ultra thick] (-1.51, 0) -- (-1.49, 0);
                \draw[blue, fill=blue] (0, 1) circle[radius=0.05cm] node[left, black] {\(ia\)};
                \draw[blue, fill=blue] (0, -1) circle[radius=0.05cm] node[left, black] {\(-ia\)};
                \draw[red, very thick] (0, 0) -- (-4,{-4*tan(15)});
            \end{tikzpicture}
            \tikzexternaldisable
            \caption{The contour used to evaluate the integral of \(\log(x)/(x^2 + a^2)\).}
            \label{fig:contour for log x/x^2 + a^2}
        \end{figure}
        Here we choose the branch cut to be the half line from \(0\) to \(\infty\) at angle \(\pi + 1/4\).
        There is nothing particularly special about this choice, any value from \((\pi, 2\pi)\) would do.
        There is only one singularity, \(z = ia\), inside the contour so
        \begin{align*}
            \oint_{\gamma f(z)}\dd{z} &= 2\pi i\Res(f, ia)\\
            &= 2\pi i \frac{\log z}{z + ia} \bigg|_{z=ia}\\
%            &= \frac{\pi}{a} \log(ia)\\
%            &= \frac{\pi}{a} \left[ \log a + i\arg(ia) \right]\\
%            &= \frac{\pi}{a} \left[ \log a + i\frac{\pi}{2} \right]
        \end{align*}
        We can also split the integral into four sections, the outer semicircle of radius \(R\), \(C_R\), the indentation of radius \(\rho\), \(C_\rho\), and the two straight segments.
        The integrals over the two semicircles vanish:
        \begin{align*}
            \lim_{R\to\infty} \abs{\int_{C_R} \frac{\log z}{z^2 + a^2} \dd{z}} &\le \lim_{R\to\infty} \int_{C_R} \abs{\frac{\log z}{z^2 + a^2}}\abs{\dd{z}}\\
            &= \lim_{R\to\infty} \int_{0}^{\pi} \frac{\abs{\log(Re^{i\vartheta})}}{\abs{R^2e^{2i\vartheta} + a^2}}\abs{iRe^{i\vartheta}}\dd{\vartheta}\\
            &\le \lim_{R\to\infty} \int_{0}^{\pi} \frac{R(\log R + \vartheta)}{R^2 - a^2}\dd{\vartheta}\\
            &= \lim_{R\to\infty} \frac{R\log R}{R^2 - a^2}\int_{0}^{\pi} \dd{\vartheta} + \lim_{R\to\infty} \frac{R}{R^2 - a^2} \int_{0}^{\pi} \vartheta \dd{\vartheta}\\
            &= \lim_{R\to\infty} \frac{\pi R\log R}{R^2 - a^2} + \lim_{R\to\infty} \frac{\pi^2 R}{2(R^2 - a^2)}\\
            &= 0,
        \end{align*}
        here we have used \(\log(Re^{i\vartheta}) = \log R + i\vartheta\) and \(\abs{\log R + i\vartheta} \le \log R + \vartheta\) for positive \(\vartheta\).
        \begin{align*}
            \lim_{\rho\to 0} \abs{\int_{C_\rho} \frac{\log z}{z^2 + a^2}\dd{z}} &\le \lim_{\rho\to 0} \int_{C_\rho} \abs{\frac{\log z}{z^2 + a^2}} \abs{\dd{z}}\\
            &= \lim_{\rho\to 0} \int_{\pi}^{0} \frac{\abs{\log(\rho e^{i\vartheta})}}{\abs{\rho^2e^{2i\vartheta} + a^2}} \abs{i\rho e^{i\vartheta}}\dd{\vartheta}\\
            &\le \lim_{\rho\to 0} \int_{\pi}^{0} \frac{\rho(\log\rho + \vartheta)}{a^2 - \rho^2} \dd{\vartheta}\\
            &= \lim_{\rho\to 0}  \frac{\rho\log \rho}{a^2 - \rho^2} \int_{\pi}^{0} \dd{\vartheta} + \lim_{\rho\to 0} \frac{\rho}{a^2 - \rho^2} \int_{\pi}^{0}\dd{\vartheta}\\
            &= \lim_{\rho\to 0} \frac{\rho\log \rho}{a^2 - \rho^2}\pi + \lim_{\rho\to 0} \frac{\rho}{a^2 - \rho^2}\frac{\pi^2}{2}\\
            &= 0.
        \end{align*}
        Hence the integrals along the semicircles vanish.
        
        The integral along the positive real axis gives us the target integral.
        The integral along the negative real axis can be found using \(z = e^{i\pi} = -x\) and \(\dd{z} = e^{i\pi}\dd{x} = -\dd{x}\) so
        \begin{align*}
            \int_{-\infty}^{0} \frac{\log z}{z^2 + a^2} \dd{z}\\
            &= -\int_{\infty}^{0} \frac{\log(x e^{i\pi})}{x^2e^{2\pi i} + a^2}\dd{x}\\
            &= \int_{0}^{\infty} \frac{\log x + i\pi}{x^2 + a^2}\dd{x}\\
            &= \int_{0}^{\infty} \frac{\log x}{x^2 + a^2} \dd{x} + i\pi \int_{0}^{\infty} \frac{1}{x^2 + a^2} \dd{x}\\
            &= I + i\pi\int_{0}^{\infty} \frac{1}{x^2 + a^2}\dd{x}.
        \end{align*}
        Hence we have
        \[\oint_{\gamma} f(z)\dd{z} = 2I + i\pi \int_{0}^{\infty} \frac{1}{x^2 + a^2} \dd{x} = \frac{\pi}{a}\left( \log a + i\frac{\pi}{2} \right).\]
        Equating the real parts we get the desired integral
        \[I = \int_{0}^{\infty} \frac{\log x}{x^2 + a^2} \dd{x} = \frac{\pi}{a}\log a.\]
        By equating the imaginary parts we get for free the integral
        \[\int_{0}^{\infty} \frac{1}{x^2 + a^2} \dd{x} = \frac{\pi}{2a}.\]
    \end{example}
    
    \part{Conformal Mapping}
    \textit{This part is non-examinable.}
    \section{Kramers--Kronig Relations}
    Consider light passing through a dielectric material.
    In general the refractive index, \(n\), and susceptibility, \(\varepsilon\), are both complex numbers.
    The real part of \(\varepsilon\) corresponds to propagation through the material and the imaginary part determines absorption.
    Conservation of energy means that light that is absorbed cannot also propagate through the material.
    This implies a connection between the real and imaginary parts of \(\varepsilon\).
    In fact this relationship turns out to be incredibly general and applies to any linear causal system.
    
    Consider a system with no time dependence other than the input.
    For example a pendulum driven by some time dependent force but with all other terms only depending on time due to this force.
    This system can be completely described by the Green's function, \(G(t - t')\) for some input \(f(t')\).
    The Greens function is related to the solution for the system by
    \[u(t) = \int_{-\infty}^{\infty} G(t - t')f(t') \dd{t'}.\]
    For the system to be causal we must have that \(G(t - t') > 0\) for \(t - t' < 0\).
    
    We can solve ordinary differential equations with a Fourier transform.
    The inverse Fourier transform of the Greens function is
    \[G(t) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} \tilde{G}(\omega) e^{-i\omega t} \dd{\omega}.\]
    It turns out that the conditions for the Fourier transform to exist, in particular vanishing at infinity, imply that Jordan's lemma applies.
    This means that we can sometime compute the Fourier transforms by considering a semicircle in the upper half plane.
    We then use \(f(z) = \tilde{G}(z)e^{-izt}\) and since \(\exp\) is entire the only singularities are those of \(\tilde{G}\) so
    \begin{align*}
        \lim_{R\to\infty} \oint_{\gamma} f(z) \dd{z} &= 2\pi i\sum_{n} \Res(\tilde{G}, \omega_n)\\
        &= \lim_{R\to\infty} \int_{C_R} f(z) \dd{z} + \lim_{R\to\infty}  \int_{-R}^{R} \tilde{G}e^{-i\omega t} \dd{\omega}\\
        &= 0 + G(t).
    \end{align*}
    We assume \(G\) has no singularities on the real axis as these would make the response non-local.
    For \(t < 0\), and hence \(G(t) = 0\), the only way the above formula can hold is if either \(\sum_{n}\Res(\tilde{G}, \omega_n) = 0\) or \(\tilde{G}\) is analytic in the upper half plane.
    In general it is unlikely that the residues happen to cancel perfectly and so most of the time \(G\) is analytic in the upper half plane.
    
    Now consider this integral over the same contour, \(\gamma\):
    \[\oint_{\gamma} \frac{\tilde{G}(\omega')}{\omega' - \omega}\dd{\omega'}\]
    where \(\omega\in\reals\).
    The integrand has a single simple pole at \(\omega' = \omega\).
    Assuming that \(G\) is analytic in the upper half plane we know by Cauchy--Goursat's theorem that
    \[\lim_{R\to\infty} \oint_{\gamma} f(z) \dd{z} = 0\]
    but we now need to split the integral over the real axis in two and treat it as a principle value integral:
    \[\lim_{R\to\infty} \oint_{\gamma}f(z) \dd{z} = \lim_{R\to\infty} \left[ \pvint_{-R}^{R} f(z)\dd{z} + \int_{C_\rho} f(z)\dd{z} + \int_{C_R} f(z) \dd{z} \right]\]
    where \(C_\rho\) is a semicircle in the upper half plane of radius \(\rho\) at \(\omega\) such that \(\omega\) is outside of the resulting contour, \(\gamma\).
    
    For the Fourier transform to converge we must have \(\abs{\tilde{G}(\omega)} \sim 1/\omega^{k}\) for \(k > 0\) and so
    \begin{align*}
        \lim_{R\to\infty} \abs{\int_{C_R} f(z) \dd{z}} &\le \lim_{R\to\infty} \int_{C_R} \abs{f(z)} \abs{\dd{z}}\\
        &\sim \lim_{R\to\infty} \int_{0}^{\pi}  \frac{R}{R - \omega} \frac{1}{R^k} \dd{\vartheta}\\
        &= \lim_{R\to\infty} \frac{R\pi}{R - \omega}\frac{1}{R^k}\\
        &= 0.
    \end{align*}
    For the integral over \(C_\rho\) we can use the indentation lemma as it is a simple pole:
    \[\int_{C_\rho} f(z) \dd{z} = i(0 - \pi)\Res\left( \frac{\tilde{G}(\omega')}{\omega - \omega'} \right) = -i\pi\tilde{G}(\omega).\]
    Splitting the principle value integral into real and imaginary parts we have
    \begin{align*}
        0 &= \oint_{\gamma} f(z) \dd{z}\\
        &= \Re\left[ \pvint_{-\infty}^{\infty} \frac{\tilde{G}(\omega')}{\omega - \omega'} \dd{\omega} \right] + i\Im\left[ \pvint_{-\infty}^{\infty} \frac{\tilde{G}(\omega')}{\omega - \omega'} \dd{\omega} \right] - i\pi\tilde{G}(\omega).
    \end{align*}
    Equating the real and imaginary parts of the principle value integrals and \(i\pi\tilde{G}(\omega)\) we find that
    \begin{align*}
        \Re[\tilde{G}(\omega)] &= \frac{1}{\pi} \pvint_{-\infty}^{\infty} \frac{\Im[\tilde{G}(\omega)]}{\omega - \omega'} \dd{\omega'}\\
        \Im[\tilde{G}(\omega)] &= \frac{1}{\pi} \pvint_{-\infty}^{\infty} \frac{\Re[\tilde{G}(\omega)]}{\omega - \omega'} \dd{\omega'}\\
    \end{align*}
    These are the \define{Kramer--Kronig relations}.
    They hold for all linear causal systems and show the relationship between absorption and dispersion.
    
    \section{Conformal Mapping}
    We have seen that we can view complex functions as maps from the complex plane to itself.
    Most of the functions we have considered have been analytic meaning the derivative exists at a given point.
    This allows us to find more properties of the map.
    Let \(f\) be analytic at \(z_0 \in\complex\).
    Then by the definition of the derivative we have
    \begin{equation}\label{eqn:derivative as linear approx}
        f(z) - f(z_0) = f'(z_0)(z - z_0) + \order{(z - z_0)^2}.
    \end{equation}
    We then take the limit of \(z \to z_0\).
    If \(f'(z_0) \ne 0\) then we have
    \[\abs{f(z) - f(z_0)} = \abs{f'(z_0)}\abs{z - z_0}\]
    and
    \[\arg(f(z) - f(z_0)) = \arg(f'(z_0)) + \arg(z - z_0).\]
    This tells us how a neighbourhood of \(z_0\) transforms.
    The distance from \(z_0\) is scaled by \(\abs{f'(z_0)}\), in particular the disc \(\discOpen{z_0}{\varepsilon}\) is transformed into the disc \(f[\discOpen{z_0}{\varepsilon}] = \discOpen{f(z_0)}{\abs{f'(z_0)}\varepsilon}\).
    
    Consider now some smooth curves passing through \(z_0\).
    In a small region each curve can be approximated as a straight line which can be parametrised as \(\gamma_i = z_0 + C_ite^{i\vartheta_i} + \order{t^2}\) where \(C_i\) and \(\vartheta_i\) are some real constants and \(t\) is the real parametric variable.
    The variable \(\vartheta_i\) represents the slope of the line.
    After the map, \(f\), is applied the same line segment has slope \(\vartheta_i'\) given by
    \[\vartheta'_i = \arg(f'(z_0)) + \arg(z - z_0) = \arg(f'(z_0)) + \vartheta_i.\]
    Suppose that the angle between two curves meeting at \(z_0\) was \(\alpha\) before the map.
    Then after the map the angle is
    \[\alpha' = \vartheta_2' - \vartheta_1' = \vartheta_2 - \vartheta_1 = \alpha.\]
    So the angle at which smooth curves cross is invariant under this map as long as \(f'(z_0) \ne 0\).
    What this means is that, locally, shapes are preserved, they are simply stretched by \(\abs{f'(z_0)}\).
    However this is only a local effect.
    Globally shapes will change as the scaling factor, \(\abs{f'(z_0)}\), needn't be the same at all points.
    Also if \(f'(z_0) = 0\) then equation~\ref{eqn:derivative as linear approx} simply says that there is some second order term that we can't ignore.
    If this is the case we call \(z_0\) a \define{critical point} of the transformation.
    \begin{definition}{Conformal Map}{}
        Let \(S, R\subseteq\complex\) be open regions.
        Then the function \(f\colon S \to R\) is called \define{conformal} at some point \(z_0\in S\) if it preserves the angle between lines passing through \(z_0\) and the orientation.
        Equivalently \(f\) is \define{conformal} if and only if it is analytic at \(z_0\) and \(f'(z_0) \ne 0\).
    \end{definition}
    
    If we consider \(f\colon\complex\to\complex\) to be \(f\colon\reals^2\to\reals^2\) then the Jacobian of \(f\) is given by
    \begin{align*}
        \pdv{(u, v)}{(x, y)} &=
        \begin{vmatrix}
            u_x & u_y\\
            v_x & v_y
        \end{vmatrix}
        \\
        &= u_xv_y - u_yv_x\\
        &= u_x^2 + v_x^2\\
        &= \abs{f'(z)}^2
    \end{align*}
    so we see that the magnitude of the derivative is exactly the Jacobian.
    This should make sense as the Jacobian of a transformation gives the scaling factor.
    We also know that a map is invertible if and only if the Jacobian is non=zero and the function and its derivatives are continuous.
    If \(f\) is analytic then certainly it, and its derivatives, are continuous and so if \(f'(z) \ne 0\) then it is invertible.
    So conformal maps have a local inverse.
    
    \subsection{Mapping Regions}
    It is often important to know how a given region transforms.
    This will be demonstrated with several examples all of which follow the following procedure:
    \begin{enumerate}
        \item Identify easy to map points at the boundary.
        \item Parametrise the boundary of the region and map it.
        \item Determine if the inside of the region maps to the inside or outside of the new region.
        \item Find any other points of interest.
    \end{enumerate}

    \subsubsection{Linear Mapping}
    The simplest conformal map is 
    \[f(z) = \alpha z + \beta\]
    for some \(\alpha, \beta\in\complex\) with \(\alpha \ne 0\).
    We have \(f'(z) = \alpha\) and so any region is scaled by \(\abs{f'(z)} = \abs{\alpha}\).
    The region is also rotated by \(\arg(\alpha)\) and finally shifted by \(\beta\).
    An example of this map mapping a square region is shown in figure~\ref{fig:linear conformal map}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{conformal-map-linear}
        \begin{tikzpicture}
            \tikzset{axis/.style={very thick, ->, >=latex}}
            \tikzset{region/.style={opacity=0.5, blue, fill=blue, fill opacity=0.25, thick}};
            % axis and arrow between
            \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
            \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \draw[very thick, ->, >=latex] (4.5, 0) -- (5.5, 0) node[midway, above] {\(z\mapsto \alpha z + \beta\)};
            \begin{scope}[xshift=10cm]
                \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \end{scope}
            
            % unmapped region
            \draw[region] (1, 1) rectangle (2, 2);
            \node[below left] at (1, 1) {\(A\)};
            \node[below right] at (2, 1) {\(B\)};
            \node[above right] at (2, 2) {\(C\)};
            \node[above left] at (1, 2) {\(D\)};
            \draw[red, ->, >=latex] (1.5, 1) -- (1.5, 1.5);
            
            % mapped region
            \begin{scope}[xshift=8cm, scale=1.3, rotate=-37]
                \draw[region] (1, 1) rectangle (2, 2);
                \node[left] at (1, 1) {\(A'\)};
                \node[below] at (2, 1) {\(B'\)};
                \node[right] at (2, 2) {\(C'\)};
                \node[above] at (1, 2) {\(D'\)};
                \draw[red, ->, >=latex] (1.5, 1) -- (1.5, 1.5);
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The map \(z\mapsto \alpha z + \beta\). In particular \(\abs{\alpha} = 1.3\), \(\arg(\alpha) = -0.645\), and \(\beta = -2\).}
        \label{fig:linear conformal map}
    \end{figure}
    Notice that straight lines map to straight lines.
    To see why this is true consider the straight line \(AB\).
    We can parametrise this as
    \[\gamma(t) = (B - A)t + A\]
    for \(t\in[0, 1]\).
    After the map we have
    \[f(\gamma(t)) = \alpha(B - A)t + \alpha A + B\]
    which is again a straight line.
    Finally since angles are preserved the red arrow starts pointing in and must end pointing in to preserve the angles and so the inside maps to the inside.
    
    \subsubsection{Quadratic Mapping}
    Consider the map \(f\colon z\mapsto z^2\).
    Since \(f'(z) = 2z\) this map is conformal with critical point \(z = 0\).
    Figure~\ref{fig:quadratic conformal map} shows the result of this mapping.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{conformal-map-quadratic}
        \begin{tikzpicture}
            \tikzset{axis/.style={very thick, ->, >=latex}}
            \tikzset{region/.style={draw=none, fill=blue, fill opacity=0.25, thick}};
            \tikzset{boundary/.style={ultra thick}}
            % axes and arrow between
            \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
            \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \draw[very thick, ->, >=latex] (4.5, 0) -- (5.5, 0) node[midway, above] {\(z\mapsto z^2\)};
            \begin{scope}[xshift=10cm]
                \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \end{scope}
            
            % unmapped region
            \draw[region] (0, 0) rectangle (3, 3);
            \draw[boundary, red] (0, 0) -- (3, 0);
            \draw[boundary, orange] (0, 0) -- (0, 3);
            \draw[boundary, green] (1.2, 0)  arc(0:90:1.2);
            \begin{scope}
                \clip (0, 0) rectangle (3, 3);
                \draw[boundary, yellow] (0, 0) -- (30:5);
            \end{scope}
            
            % mapped region
            \begin{scope}[xshift=10cm]
                \draw[region] (-3, 0) rectangle (3, 3);
                \draw[boundary, red] (0, 0) -- (3, 0);
                \draw[boundary, orange] (0, 0) -- (-3, 0);
                \draw[boundary, green] (1.2*1.2, 0)  arc(0:180:1.2*1.2);
                \begin{scope}
                    \clip (0, 0) rectangle (3, 3);
                    \draw[boundary, yellow] (0, 0) -- (60:5);
                \end{scope}
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The map \(z\mapsto z^2\) showing a region defined by \(\arg(z)\in(0, \pi/2)\), the boundaries of this region, and two interesting curves.}
        \label{fig:quadratic conformal map}
    \end{figure}
    The blue region is defined by \(\arg(z) \in (0, \pi/2)\).
    After the map this becomes
    \[\arg(z) \in (0, \pi/2) \mapsto \arg(z) \in (0, \pi)\]
    since squaring a complex number doubles its argument.
    The boundaries of this shape are the lines \(z_1 = x\) for \(x \in (0, \infty)\) and \(z_2 = iy\) for \(y \in (0, \infty)\).
    After the mapping these regions map to
    \begin{align*}
        z_1 = x \in (0, \infty) &\mapsto x^2 \in(0, \infty)\\
        z_2 = iy \in i(0, \infty) &\mapsto -y^2 \in(-\infty, 0).
    \end{align*}
    Now consider an arbitrary line through the origin.
    This can be parametrised as \(z_3 = te^{i\vartheta}\) for \(t\in(0, \infty)\).
    This line then maps to
    \[z_3 = te^{i\vartheta} \mapsto t^2e^{2i\vartheta}\]
    so a line through the origin with the argument doubled.
    Finally consider the quarter circle of radius \(R\) parametrised by \(z_4 = Re^{it}\) for \(t\in(0, \pi/2)\).
    This maps to
    \[z_4 = Re^{it} \mapsto R^2e^{2it}.\]
    So a semicircle of radius \(R^2\).
    Notice, for example, that the yellow line and green arc in figure~\ref{fig:quadratic conformal map} meet at right angles both before and after the mapping.
    However the orange and red lines meet at \(\pi/2\) before the mapping and \(\pi\) after the mapping.
    This is because they meet at \(z = 0\) which is a critical point of this mapping.
    
    \subsubsection{Exponential Mapping}
    Consider the mapping \(f\colon z\mapsto e^{z}\),
    Since \(f'(z) \ne 0\) this map is conformal for all finite \(z\).
    We saw in figure~\ref{fig:2pi stripes map to C under z->e^z} how stripes map under the exponential function.
    Instead consider the square shown in figure~\ref{fig:exponential conformal map}.
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{conformal-map-exponential}
        \begin{tikzpicture}
            \tikzset{axis/.style={very thick, ->, >=latex}}
            \tikzset{region/.style={draw=none, fill=blue, fill opacity=0.25, thick}};
            \tikzset{boundary/.style={ultra thick}}
            % axes and arrow between
            \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
            \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \draw[very thick, ->, >=latex] (4.5, 0) -- (5.5, 0) node[midway, above] {\(z\mapsto e^z\)};
            \begin{scope}[xshift=10cm]
                \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \end{scope}
            
            % unmapped region
            \draw[boundary, blue] (0.5, 0) -- (0.5, 2);
            \begin{scope}
                \clip (-1, -2) -- (0.5, 1) -- (2, -2);
                \draw[boundary, yellow] (0, 0) rectangle (1, 2);
            \end{scope}
            \begin{scope}
                \clip (2, -2) -- (0.5, 1) -- (2, 4);
                \draw[boundary, orange] (0, 0) rectangle (1, 2);
            \end{scope}
            \begin{scope}
                \clip (2, 4) -- (0.5, 1) -- (-1, 4);
                \draw[boundary, red] (0, 0) rectangle (1, 2);
            \end{scope}
            \begin{scope}
                \clip (-1, 4) -- (0.5, 1) -- (-1, -2);
                \draw[boundary, green] (0, 0) rectangle (1, 2);
            \end{scope}
            \node[below] at (1, 0) {1};
            \node[left] at (0, 2) {\(2\pi i\)};
            
            % mapped region
            \begin{scope}[xshift=10cm]
                \draw[boundary, yellow] (1, 0.025) -- (e, 0.025);
                \draw[boundary, red] (1, -0.025) -- (e, -0.025);
                \draw[boundary, green] (0, 0) circle[radius=1];
                \draw[boundary, orange] (0, 0) circle[radius=e];
                \draw[boundary, blue] (0, 0) circle[radius=e^0.5];
                \node[below right] at (1, 0) {1};
                \node[below right] at (e^0.5, 0) {\(e^{0.5}\)};
                \node[below right] at (e, 0) {\(e\)};
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The map \(z\mapsto e^z\) showing the mapping of a rectangle of side lengths 1 and \(2\pi\) to an annulus of radii \(1\) and \(e\). Note that the real and imaginary axes before the mapping do not have the same scale.}
        \label{fig:exponential conformal map}
    \end{figure}
    The unit square maps to an annulus.
    We can see this by parametrising the four sides:
    \tikzexternaldisable
    \begin{alignat*}{5}
        \tikz[baseline={-0.1cm}]{\draw[very thick, yellow] (0, 0) -- (0.5, 0)}\quad z_1 &= R, \quad && R\in (0, 1) \quad && \mapsto\quad && e^R, \quad && \text{line segment: }(1, e)\\
        \tikz[baseline={-0.1cm}]{\draw[very thick, orange] (0, 0) -- (0.5, 0)}\quad z_2 &= i\vartheta + 1, \quad && \vartheta\in(0, 2\pi) \quad && \mapsto\quad && e^{i\vartheta + 1} = ee^{i\vartheta}, \quad && \text{circle radius }e\\
        \tikz[baseline={-0.1cm}]{\draw[very thick, red] (0, 0) -- (0.5, 0)}\quad z_3 &= R + 2\pi i, \quad && R\in (0, 1) \quad && \mapsto\quad && e^{R + 2\pi i} = e^R, \quad && \text{line segment: }(1, e)\\
        \tikz[baseline={-0.1cm}]{\draw[very thick, green] (0, 0) -- (0.5, 0)}\quad z_4 &= i\vartheta, \quad && \vartheta\in(0, 2\pi) \quad && \mapsto\quad && e^{i\vartheta}, \quad &&\text{circle radius }1\\
        \tikz[baseline={-0.1cm}]{\draw[very thick, blue] (0, 0) -- (0.5, 0)}\quad z_4 &= 0.5 + i\vartheta, \quad && \vartheta\in(0, 2\pi) \quad && \mapsto\quad && e^{0.5 + i\vartheta} = e^{0.5}e^{i\vartheta}, \quad && \text{circle radius }e^{0.5}\\
    \end{alignat*}
    
    \subsubsection{Trigonometric Mapping}\label{sec:trigonometric mapping}
    Consider the map \(f\colon z \mapsto \sin z\).
    This is shown in figure~\ref{fig:trig conformal map}
    \begin{figure}[ht]
        \centering
        \tikzexternalenable
        \tikzsetnextfilename{conformal-map-sin}
        \begin{tikzpicture}
            \tikzset{axis/.style={very thick, ->, >=latex}}
            \tikzset{region/.style={draw=none, fill=blue, fill opacity=0.25, thick}};
            \tikzset{boundary/.style={ultra thick}}
            % axes and arrow between
            \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
            \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \draw[very thick, ->, >=latex] (4.5, 0) -- (5.5, 0) node[midway, above] {\(z\mapsto \sin z\)};
            \begin{scope}[xshift=10cm]
                \draw[axis] (-3, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[axis] (0, -3) -- (0, 3) node[above] {\(\Im\)};
            \end{scope}
            
            % unmapped region
            \draw[region] (0, 0) rectangle (1, 3);
            \draw[boundary, red] (0.5, 0) -- (0.5, 3);
            \draw[boundary, red!50!blue] (0, 0.5) -- (1, 0.5);
            \begin{scope}
                \clip (-1, -1) -- (0.5, 0.5) -- (2, -1);
                \draw[boundary, yellow] (0, 0)  rectangle (1, 3);
            \end{scope}
            \begin{scope}
                \clip (-1, -1) -- (0.5, 0.5) -- (0.5, 3) -- (-1, 3);
                \draw[boundary, green] (0, 3) -- (0, 0) -- (1, 0);
            \end{scope}
            \begin{scope}
                \clip (2, -1) -- (0.5, 0.5) -- (0.5, 3) -- (2, 3);
                \draw[boundary, orange] (0, 0) -- (1, 0) -- (1, 3);
            \end{scope}
            \node[below] at (1, 0) {\(\frac{\pi}{2}\)};
            \node[below] at (0.5, 0) {\(a\)};
            \node[left] at (0, 0.5) {\(b\)};
            
            % mapped region
            \begin{scope}[xshift=10cm]
                \draw[region] (0, 0) rectangle (3, 3);
                \begin{scope}
                    \clip (0, 0) rectangle (3, 3);
                    \draw[boundary, red] (0, 0) circle[x radius={cosh(3.1415926/4)}, y radius={sinh(3.1415926/4)}];
                    \draw[very thick, red!50!blue] plot[samples=1000,domain=0:75] ({0.878 * sec(\x)},{0.479 * tan(\x)});
                \end{scope}
                \begin{scope}
                    \clip (-1, -1) -- (0.5, 0.5) -- (2/3.1415926, 0.5) -- (2/3.1415926, -1);
                    \draw[boundary, yellow] (0, 0)  -- (2/3.1415926, 0);
                \end{scope}
                \begin{scope}
                    \clip (-1, -1) -- (0.5, 0.5) -- (0.5, 3) -- (-1, 3);
                    \draw[boundary, green] (0, 3) -- (0, 0)  -- (1, 0);
                \end{scope}  
                \draw[boundary, orange] (2/3.1415926, 0)  -- (3, 0);
                \node[below] at (2/3.1415926, 0) {1};
                \node[below] at ({cosh(3.1415926/4)}, 0) {\(\cosh a\)};
                \node[left] at (0, {sinh(3.1415926/4)}) {\(\sinh a\)};
            \end{scope}
        \end{tikzpicture}
        \tikzexternaldisable
        \caption{The map \(z\mapsto \sin z\) showing the region \(\Re z \in (0, \pi/2)\) and \(\Im z > 0\).}
        \label{fig:trig conformal map}
    \end{figure}
    This is best understood by expressing \(\sin\) in terms of real and imaginary parts:
    \[f(z) = \sin z = \frac{e^{iz} - e^{-iz}}{2i} = \sin(x)\cosh(y) + i \cos(x)\sinh(y).\]
    \tikzexternaldisable
    We see that line segment, \tikz[baseline={-0.1cm}]{\draw[very thick, yellow] (0, 0) -- (0.5, 0)}, which is the interval \((0, \pi/2)\), maps to the interval \((0, 1)\) since \(y = 0\) and \(\sinh 0 = 0\), \(\cosh 0 = 1\), and \(\sin x\) maps onto \((0, 1)\) for \(x \in (0, \pi/2)\).
    The positive imaginary axis, \tikz[baseline={-0.1cm}]{\draw[very thick, green] (0, 0) -- (0.5, 0)}, maps to itself since \(x = 0\) and \(\sin 0 = 0\), \(\cos 0 = 1\) and \(\sinh y\) maps onto \((0, \infty)\) for \(y \in (0, \infty)\).
    The line, \tikz[baseline={-0.1cm}]{\draw[very thick, orange] (0, 0) -- (0.5, 0)}, given by \(z = \pi/2 + iy\) maps to \((1, \infty)\) since for this line \(f\) reduces to \(\cosh y\) and \(\cosh y\) maps onto \((1, \infty)\) for \(y \in (0, \infty)\).
    Notice that the angle at \(\pi/2\) isn't conserved as \(f'(\pi/2) = \cos(\pi/2) = 0\).
    
    Now consider the line, \tikz[baseline={-0.1cm}]{\draw[very thick, red] (0, 0) -- (0.5, 0)}, which can be parametrised as \(z = t + ia\).
    This line then maps to
    \[f(z) = u(t) + iv(t) = \sin(t)\cosh(a) + i \cos(t)\sinh(a).\]
    Square the real and imaginary parts and divide by \(\cosh^2 a\) and \(\sinh^2 a\) respectively and we get
    \[\frac{u^2(t)}{\cosh^2 a} + \frac{v^2(t)}{\sinh^2 a} = \sin^2 t + \cos^2 t = 1.\]
    This is an ellipse with semimajor axis \(\cosh a\) and semiminor axis \(\sinh a\).
    Further for \(a \in [0, \infty)\) we have \(0 < \sinh a \le \cosh a < \infty\) and so the ellipse covers the whole of the first first quadrant.
    
    Now consider the line, \tikz[baseline={-0.1cm}]{\draw[very thick, red!50!blue] (0, 0) -- (0.5, 0)}, which can be parametrised by \(z = t + ib\) for \(t \in (0, \pi/2)\).
    The map reduces for this line to
    \[f(z) = u(t) + iv(t) = \sin(b)\cosh(t) - \cos(b)\sinh(t).\]
    Squaring the real and imaginary parts and dividing by \(\sin^2 b\) and \(\cos^2 b\) respectively we get
    \[\frac{u^2(t)}{\sin^2 b} - \frac{v^2(t)}{\cos^2 b} = \cosh^2t - \sinh^2 t = 1\]
    where we have used the identity
    \[\cosh^2 x - \sinh^2 x = 1.\]
    We see that the result is the formula for a hyperbola.
    
    \subsection{M\"obius Transformations}
    A \define{M\"obius transformation}, also known as a \define{bilinear map} is a map of the form
    \[f(z) = \frac{\alpha z + \beta}{\gamma z + \delta}\]
    for \(\alpha, \beta, \gamma, \delta \in \complex\).
    These are conformal provided that \(\alpha\delta - \beta\gamma \ne 0\), which is equivalent to the statement that
    \[
        \begin{pmatrix}
            \alpha & \beta\\
            \gamma & \delta
        \end{pmatrix}
        \in \mathop{\mathrm{U}}(2).
    \]
    These transformations are interesting because they map straight lines to either another straight line or a circle and circles to either another circle or a straight line.
    The set of all M\"obius transformations forms a group under function composition called the M\"obius group.
    This group acts on the Riemann sphere, \(\complex^*\), as the automorphism group of the Riemann sphere (i.e. the group is the set of isomorphisms of the Riemann sphere into itself) and so the M\"obius group is sometimes denoted \(\mathop{\mathrm{Aut}}(\complex^*)\).
    This is a Lie group.
    
    \subsection{Boundary Conditions}
    Now that we've spent all this time discussing conformal maps, why do we care?
    The most useful property of conformal maps is that they have a local inverse.
    This means that we can take a geometrically complicated problem and then map it to some less complicated problem, solve it there, and map the solution back to the original problem.
    
    This is possible for two reasons:
    \begin{enumerate}
        \item A constant valued boundary maps to the same value at a new boundary.
        \item If the derivative normal to a boundary vanishes then the derivative normal to the new boundary vanishes.
    \end{enumerate}
    \begin{example}
        \itshape
        Find a real function, \(\varphi\colon\reals^2 \to \reals\), which is harmonic on the wedge between the positive real axis and half line from \(0\) to infinity defined by \(y = x\) and \(x > 0\) such that the following are satisfied:
        \begin{itemize}
            \item On upper boundary of the wedge, \(\varphi(x, x) = 2\).
            \item On the real axis \(\varphi_y(x, 0) = 0\).
        \end{itemize}
        This problem may arise in physics, for example, as finding the equilibrium temperature on wedge with one edge at a fixed temperature and the other edge in contact with insulating material.
        
        \normalfont
        The first thing we need to do is to find a conformal map that transforms the problem into one with simpler geometry.
        The map \(w(z) = z^2\) does exactly this, transforming the wedge into a quadrant as shown in figure~\ref{fig:conformal map bc example 1}.
        Let \((u, v) = w(x, y)\).
        \begin{figure}[ht]
            \centering
            \tikzexternalenable
            \tikzsetnextfilename{conformal-map-bc-example-1}
            \begin{tikzpicture}
                \tikzset{axis/.style={very thick, ->, >=latex}}
                \tikzset{region/.style={draw=none, fill=blue, fill opacity=0.25, thick}};
                \tikzset{boundary/.style={ultra thick}}
                % axes and arrow between
                \draw[axis] (-1, 0) -- (3, 0) node[right] {\(\Re\)};
                \draw[axis] (0, -1) -- (0, 3) node[above] {\(\Im\)};
                \draw[very thick, ->, >=latex] (4.5, 0) -- (5.5, 0) node[midway, above] {\(z\mapsto z^2\)};
                \begin{scope}[xshift=8cm]
                    \draw[axis] (-1, 0) -- (3, 0) node[right] {\(\Re\)};
                    \draw[axis] (0, -1) -- (0, 3) node[above] {\(\Im\)};
                \end{scope}
                
                % unmapped region
                \draw[region] (0, 0) -- (3, 3) -- (3, 0) -- cycle;
                \begin{scope}
                    \clip (-1.5, -1) -- (0.5, 0.25) -- (3, 0.5) -- (3, -1);
                    \draw[boundary, red] (-1, 0) -- (3, 0);
                \end{scope}
                \begin{scope}
                    \clip (-1.5, -1) -- (0.5, 0.25) -- (3, 0.5) -- (3, 3) -- (-0.5, 3);
                    \draw[boundary, green] (0, 0) -- (3, 3);
                \end{scope}
                \node[below] at (1.5, 0) {\(\varphi_y = 0\)};
                \node at (1.3, 1.7) {\rotatebox{45}{\(\varphi = 2\)}};
                
                % mapped region
                \begin{scope}[xshift=8cm]
                    \draw[region] (0, 0) rectangle (3, 3);   
                    \begin{scope}
                        \clip (-1, -1) -- (0.5, 0.5) -- (3, 1) -- (3, -1);
                        \draw[boundary, red] (-1, 0) -- (3, 0);
                    \end{scope}
                    \begin{scope}
                        \clip (-1, -1) -- (0.5, 0.5) -- (0.5, 3) -- (-1, 3);
                        \draw[boundary, green] (0, -1) -- (0, 3);
                    \end{scope}
                    \node[below] at (1.5, 0) {\(\varphi_y = 0\)};
                    \node[left] at (0, 1.5) {\rotatebox{90}{\(\varphi = 2\)}};
                \end{scope}
            \end{tikzpicture}
            \tikzexternaldisable
            \caption{The map \(z \mapsto z^2\) showing how the wedge maps to a quadrant.}
            \label{fig:conformal map bc example 1}
        \end{figure}
    
        Recall that an analytic function has harmonic real and imaginary parts so we should look for an analytic function, \(f\), which has real or imaginary parts satisfying the new boundary conditions, \(f_v(u) = 0\) and \(f(iv) = 2\).
        Typical candidates for this are logarithms and harmonic polynomials.
        In this case \(\varphi(u, v) = u + 2\) satisfies these conditions.
        We could find the harmonic conjugate the long way or we can just notice that \(f(w) = w + 2\) has our solution as a real part and as a polynomial is entire.
        Hence the solution to the original problem is
        \[\varphi(x, y) = \Re[w(x, y) + 2] = x^2 - y^2 + 2\]
    \end{example}
    \begin{example}
        \itshape
        Find a function, \(\varphi\colon\reals^2 \to \reals\) which fulfils the following conditions:
        \begin{itemize}
            \item The function satisfies Laplace's equation in the region of interest, that is \(\laplacian\varphi = 0\).
            \item \(\varphi(0, y) = 0\).
            \item \(\varphi(x, 0) = 1\) for all \(x > 1\).
            \item For \(x \in (0, 1)\) \(\varphi_y(x, 0) = 0\).
        \end{itemize}
        This problem may arise in physics when finding the equilibrium temperature distribution of an infinite plate with two edges kept at fixed temperature, the \(x = 0\) edge held at \(T_y = 0\) and the \(x > 1\) and \(y = 0\) edge held at \(T_{x>1} = 1\).
        
        \normalfont
        Again the first step is to find a conformal map that simplifies the boundary conditions.
        Consider for this purpose the function \(w(z) = \arcsin z\).
        This is the inverse of the \(\sin\) transformations discussed in section~\ref{sec:trigonometric mapping}.
        The quadrant \(x, y \ge 0\) is mapped to a half-infinite strip, \(S = \{(u, v)\in\reals^2 \st u \in [0, \pi/2] \wedge v > 0\} = [0, \pi/2] \times \reals_{>0}\).
        The boundary conditions then become:
        \begin{align*}
            \laplacian\varphi(u, v) &= 0 \A u, v \in S,\\
            \varphi_v(u, 0) &= 0 \A u \in[0, \pi/2],\\
            \varphi(0, v) &= 0 \A v \in \reals_{>0},
            \shortintertext{and}
            \varphi(\pi/2, v) &= 1 \A v\in\reals_{>0}.
        \end{align*}
        These are satisfied by a simple function of \(w\).
        In particular \(\varphi(u, v) = 2u/\pi\) satisfies these boundary conditions.
        So the solution is then
        \[\varphi(x, y) = \frac{2}{\pi} u = \frac{2}{\pi}\Re w = \frac{2}{\pi}\Re(\arcsin z) = \frac{2}{\pi}\Re(\arcsin(x + iy)).\]
        We aren't quite finished as this isn't a real function since we have to be careful about branch cuts with \(\arcsin\).
        We could use a general formula for the inversion but then we would have to be careful, instead we will invert the formula explicitly:
        \[w = \arcsin z \implies z = \sin w = \sin(u)\cosh(v) + i\cos(u)\sinh(v) = x + iy\]
        and following the same procedure as we did in section~\ref{sec:trigonometric mapping} when considering the mapping \(z\mapsto \sin z\) we find
        \[\frac{x^2}{\sin^2 u} - \frac{y^2}{\cos^2 u} = 1.\]
        Multiplying by \(\sin^2(u)\cos^2(u) = \sin^2(u)[1 - \sin^2(u)]\) we end up with a quadratic equation in \(\sin^2 u\):
        \[\sin^2 u(1 - \sin^2 u) = x^2(1 - \sin^2 u) - y^2\sin^2 u \implies \sin^4 u - [1 + x^2 + y^2]\sin^2 u + x^2 = 0\]
        Solving this we find
        \[\sin^2 u = \frac{1}{2}[(1 + x^2 + y^2) \pm \sqrt{(1 + x^2 + y^2)^2 - 4x^2}].\]
        For a bounded solution we must take the negative square root.
        Completing the square a few times and doing some algebra this becomes
        \[\sin^2 u = \frac{1}{4}\left( \sqrt{(1 + x)^2 + y^2} - \sqrt{(1 - x)^2 + y^2} \right)^2.\]
        Finally square rooting and taking \(\arcsin\) on both sides we have
        \[u = \arcsin\left( \frac{1}{2}\left( \sqrt{(1 + x)^2 + y^2} - \sqrt{(1 - x)^2 + y^2} \right) \right).\]
        The boundary conditions force us to take the positive square root.
        Hence the solution is
        \[\varphi(x, y) = \frac{2}{\pi}u = \frac{2}{\pi}\arcsin\left( \frac{1}{2}\left( \sqrt{(1 + x)^2 + y^2} - \sqrt{(1 - x)^2 + y^2} \right) \right).\]
        \begin{figure}[ht]
            \centering
            \includegraphics{conformal_map_example_solution.pdf}
            \caption{The solution, \(\varphi = 2\Re(\arcsin(z))/\pi\).}
        \end{figure}
    \end{example}
    This last example was pretty complicated with some nasty algebra but the method is the same for all of these problems:
    \begin{enumerate}
        \item Find a conformal map, \(w = u + iv\), which simplifies the boundary conditions.
        \item Translate the boundary conditions to be in terms of \(u\) and \(v\).
        \item Come up with a solution in terms of \(w\) or \(u\) and \(v\).
        \item Invert the conformal map to get a solution in terms of \(x\) and \(y\).
    \end{enumerate}
    An important point is that we need \(w\) to be conformal and for all our theorems to apply, which means we need an analytic solution which means that the ansatz should be a harmonic function for \(u\) or \(v\) and then we can find the harmonic conjugate.
    Typical choices for the solution to the simplified problem are harmonic polynomials, logarithms, \(\arg w\) (which is just the imaginary part of the logarithm), and the real or imaginary parts of elementary analytic functions such as exponentials or (hyperbolic) trig.
    
    This method can be applied to many physics problems including, but not limited to
    \begin{itemize}
        \item Gravitational potentials in vacuum (i.e. \(\rho = 0\)):
        \[\laplacian \varphi = 0.\]
        \item Electrostatic potentials in vacuum (i.e. \(\rho = 0\)):
        \[\laplacian V = -\div\vv{E} = 0\]
        \item Stationary waves:
        \[\laplacian f(x, y, t) = \frac{1}{c^2}\pdv[2]{f}{t} = 0.\]
        \item Equilibrium solutions to the heat equation:
        \[\laplacian f(x, y, t) = \frac{1}{k}\pdv{f}{t} = 0.\]
        \item Irrotational, incompressible flow, in a steady state:
        \[\rho\div\vv{v} = -\pdv{\rho}{t} = 0.\]
        Since if this holds and \(\rho \ne 0\) then necessarily \(\laplacian\vv{v} = \vv{0}\).
    \end{itemize}
    Riemann showed that any non-empty, simply connected, open subset of \(\complex\) can be mapped to the unit disc, \(\discOpen{0}{1}\).
    Further this can always be done by an invertible analytic function.
    This implies that it is always possible to map such a region to the upper half plane (since we can always go via the unit disc).
    There is also a general solution, in terms of integrals, for any Dirichlet problem (fixed value boundary conditions) on the unit disc or the upper half plane.
    Therefore it is always possible to apply this method to solve Dirichlet problems (assuming a solution exists).
    However it is often non-trivial and finding the correct map can be difficult and there is no algorithmic way to do it.
\end{document}
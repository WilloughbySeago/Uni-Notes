\part{Recap}
\section{Recap Part One}
\setcounter{postulateCounter}{0}
\begin{postulate}{}{}
    Every possible physical state of a given system corresponds to some state vector, \(\ket{\Psi(t)} \in \hilbert\), from which all possible predictions of the physical properties of the system can be obtained.
\end{postulate}
The state vector can often be represented by a wave function, \(\Psi(\vv{r}, t) = \braket{\vv{r}}{\Psi(t)}\), however this is not always the case.
For example the spin of a system cannot be represented in this way and we instead represent spin with column vectors.

\begin{postulate}{}{}
    Every physical observable is represented by a Hermitian operator.
    For each observable, \(\observable{A}\), there is a Hermitian operator, \(\operator{A}\), with a complete orthonormal set of eigenfunctions, \(\{u_i\}\), or eigenvectors, \(\{\ket{u_i}\}\), or generically eigenstates, which have a corresponding set of real eigenvalues, \(\{A_i\}\), such that
    \[\operator{A}u_i(\vv{r}) = A_iu_i(\vv{r}), \qquad\text{or}\qquad \operator{A}\ket{u_i} = A_i\ket{u_i}.\]
    The set of possible values that a measurement of \(\observable{A}\) can yield is identically \(\{A_i\}\).
\end{postulate}

The Hermitian conjugate of an operator, \(\operator{O}\), is \(\operator{O}\hermit\), which is defined by
\[\left(\int\psi^*\operator{O}\varphi \dd[3]{r}\right)^* = \int \varphi^*\operator{O}\hermit\psi\dd[3]{r} \qquad\text{or}\qquad \bra{\psi}\operator{O}\ket{\varphi}^* = \bra{\varphi}\operator{O}\hermit\ket{\psi},\]
where \(\ket{\varphi}, \ket{\psi}\in\hilbert\) are arbitrary states.
The operator \(\operator{O}\) is Hermitian if \(\operator{O}\hermit = \operator{O}\).

States, \(\{u_i\}\) or \(\{\ket{u_i}\}\), are orthonormal if
\[\int u_i^*(\vv{r})u_j(\vv{r}) \dd[3]{r} = \delta_{ij}, \qquad\text{or}\qquad \braket{u_i}{u_j} = \delta_{ij}.\]
A set of states, \(\{u_i\}\) or \(\{\ket{u_i}\}\), is complete if an arbitrary state, \(\Psi(\vv{r}, t)\) or \(\ket{\Psi(t)}\), can be represented by
\[\Psi(\vv{r}, t) = \sum_{i} c_i(t)u_i(\vv{r}), \qquad\text{or}\qquad \ket{\Psi(t)} = \sum_{i} c_i(t)\ket{u_i}.\]
The coefficients \(\{c_i\}\) are given by
\[c_i(t) = \int u_i^{*}(\vv{r})\Psi(\vv{r}, t)\dd[3]{r}, \qquad\text{or}\qquad c_i(t) = \braket{u_i}{\Psi(t)}.\]
Compare this to some vector \(\vv{v}\in\reals^n\) where \(\vv{v} = \sum_i v_i\ve{i}\) with \(v_i = \ve{i}\cdot\vv{v}\).
The set of eigenfunctions, \(\{u_i\}\), or eigenvectors, \(\{\ket{u_i}\}\), is referred to as the eigenbasis of \(\operator{A}\).
Comparing the equations for \(\Psi(\vv{r}, t)\) or \(\ket{\Psi(t)}\) and \(c_i(t)\) we see that
\[\ket{\Psi(t)} = \sum_{i} \bra{u_i}\braket{u_i}{\Psi(t)}\]
and so the completeness relation,
\[\sum_{i}\ket{u_i}\bra{u_i} = \ident\]
where \(\ident\) is the identity operator defined by
\[\ident\ket{\Psi} = \ket{\Psi}\]
for all \(\ket{\Psi}\).

The spectrum of eigenvalues of \(\operator{A}\) may be discrete (which we assumed was the case above) or continuous.
For example the angular momentum operators \(\operator{L}^2\) and \(\operator{L}_z\) have discrete spectra whereas the position, \(\operator{X}\) and momenta \(\operator{P}\) have continuous spectra and the energy, \(\operator{H}\), has a spectrum that is continuous in some cases and discrete in other cases.

Observables can be represented by differential operators acting on the wave function or as Hermitian matrices acting on column vectors, for example
\[
\operator{P} \representation -i\hbar\grad, \qquad\text{and}\qquad \operator{S}_z \representation \frac{1}{2}\hbar
\begin{pmatrix}
    1 & 0\\
    0 & -1
\end{pmatrix}
\]

\begin{postulate}{}{}
    If the observable \(\observable{A}\) is measured on a system which, immediately prior to the measurement, is in the state \(\ket{\Psi(t)}\) then the strongest predictive statement we can make about the result is that the probability of measuring \(\observable{A}\) to be \(A_i\) is
    \[P(A_i) = \abs{\braket{u_i}{\Psi(t)}}^2 = \abs{c_i(t)}^2.\]
\end{postulate}
This assumes that the state \(\ket{\Psi(t)}\) is normalised so that
\[\abs{\braket{\Psi(t)}{\Psi(t)}}^2 = \sum_i \abs{\braket{u_i}{\Psi(t)}}^2 = \sum_i \abs{c_i(t)}^2 = 1.\]
We also assume that measurements are ideal and yield a single, errorless, number.

The coefficients, \(c_i(t)\), are called the probability amplitudes.
In general we cannot predict with certainty the outcome of a measurement unless \(\ket{\Psi(t)}\) happens to coincide with an eigenstate of \(\operator{A}\).

\subsection{Repeated Measurements}
Repeated measurements are measurements made on the same state, \(\ket{\Psi(t)}\).
We imagine creating an assembly of an infinite number of identical systems and performing each measurement on a different one of these systems.
The average value of this process, if all measurements are completed at time \(t\), is
\[\expected{\operator{A}}_t = \int \Psi^*(\vv{r}, t)\operator{A}\Psi(\vv{r}, t)\dd[3]{r}, \qquad\text{or}\qquad \expected{\operator{A}}_t = \bra{\Psi(t)}\operator{A}\ket{\Psi(t)}.\]
If we expand \(\ket{\Psi(t)}\) in the eigenstates of \(\operator{A}\) then we see that
\begin{align*}
    \expected{\operator{A}}_t &= \sum_{i, j} c_i^*(t)c_j(t)\bra{u_i}\operator{A}\ket{u_j}\\
    &= \sum_{i, j} c_i^*(t)c_j(t) A_j\braket{u_i}{u_j}\\
    &= \sum_{i, j} c_i^*(t)c_j(t) A_j\delta_{ij}\\
    &= \sum_{i} \abs{c_i}^2A_i\\
    &= \sum_{i} P(A_i)A_i.
\end{align*}
This is the usual definition of the mean of a discrete variable \(\observable{A}\) which can take values in \(\{A_i\}\).

\subsection{Uncertainty}
The uncertainty is the root mean square deviation about the mean of an infinite amount of repeated measurements.
It is given at time \(t\) by
\[\Delta\operator{A}_t \sqrt{\expected{\operator{A}^2}_t - \expected{\operator{A}}_t^2}.\]
This uncertainty is not due to the way the experiment is conducted or due to missing data.
It is an intrinsic limit to what we can know.

The generalised uncertainty relation states that two observables \(\observable{A}\) and \(\observable{B}\) have uncertainties \(\Delta \operator{A}_t\) and \(\Delta \operator{B}_t\) respectively which satisfy
\[\Delta \operator{A}_t \Delta \operator{B}_t \ge \frac{1}{2}\abs{[\operator{A}, \operator{B}]}\]
where
\[[\operator{A}, \operator{B}] = \operator{A}\operator{B} - \operator{B}\operator{A}\]
is the commutator.
The most important case of this relationship is
\[\Delta\operator{X}_t\Delta\operator{P} \ge \frac{\hbar}{2}.\]

\section{Recap Part Two}
\subsection{Successive Measurements}
Successive measurements refers to measurements made on the same system in quick succession.
\begin{postulate}{}{}
    A measurement of an observable, \(\observable{A}\), generally causes a drastic, uncontrollable change in the state of the system.
    Regardless of the state, \(\ket{\Psi(t)}\), before the measurement immediately after the measurement the state vector will coincide with the eigenstate \(\ket{u_k}\) corresponding to the measured value, \(A_k\), of \(\observable{A}\).
\end{postulate}
This is referred to as collapse of the wave function or reduction of state.
We say that the state is forced or projected into the eigenstate.
This assumes that there is no degeneracy.
If instead \(A_k\) is \(g\)-fold degenerate and the \(g\) eigenstates \(\{\ket{u_i^{(k)}}\}\) all have eigenvalue \(A_k\) then if a system is measured to have \(\observable{A} = A_k\) we will find immediately after this measurement that the state is a linear superposition of the degenerate states:
\[\frac{1}{\sqrt{_{i=1}^{g} \abs{c_i^{(k)}}^2}} \sum_{i=1}^{n} c_i^{(k)}\ket{u_i^{(k)}}.\]

\subsection{Compatible Observables}
If \(\observable{A}\) and \(\observable{B}\) are observables and we perform the following series of measurements,
\begin{enumerate}
    \item Measure \(\observable{A}\),
    \item Measure \(\observable{B}\),
    \item Measure \(\observable{A}\),
\end{enumerate}
then \(\observable{A}\) and \(\observable{B}\) are said to be compatible if and only if the result of the third measurement is guaranteed to be the same as the result of the first measurement.

\begin{theorem}{Compatibility Theorem}{}
    If \(\observable{A}\) and \(\observable{B}\) are observables represented by Hermitian operators \(\operator{A}\) and \(\operator{B}\) respectively then the following are equivalent:
    \begin{itemize}
        \item \(\observable{A}\) and \(\observable{B}\) are compatible observables.
        \item \(\operator{A}\) and \(\operator{B}\) have a common eigenbasis.
        \item \(\operator{A}\) and \(\operator{B}\) commute.
    \end{itemize}
\end{theorem}
A set of variables, \(\{\observable{A}^{(i)}\}\) are called a \acrfull{csco} if the eigenvalues of each observable, \(A_k^{(i)}\), uniquely identify an eigenvector in the common eigenbasis.
For example for a hydrogen atom the set energy, angular momentum squared and the \(z\) component of angular momentum are a \gls{csco} as a state \(\ket{n, \ell, m}\) is uniquely identified by the numbers \(n\), \(\ell\), and \(m\).

\subsection{Time Development}
\begin{postulate}{}{}
    The time development of a quantum system is determined by the \gls{tdse}:
    \[\operator{H}\Psi(\vv{r}, t) = i\hbar\pdv{t}\Psi(\vv{r}, t), \qquad\text{or}\qquad \operator{H}\ket{\Psi(t)} = i\hbar\pdv{t}\ket{\Psi(t)}.\]
    \(\operator{H}\) is the Hamiltonian operator which is formed from the corresponding classical Hamiltonian replacing the variables with corresponding operators.
    \(\operator{H}\) represents the total energy of the system.
\end{postulate}

The wave function can be interpreted as \(\abs{\Psi(\vv{r}, t)}^2\dd[3]{r}\) giving the probability that a measurement of position will give a result in the infinitesimal volume element \(\dd[3]{r}\) at \(\vv{r}\) where the volume element in Cartesian and spherical coordinates is \(\dd[3]{r} = \dd{x}\dd{y}\dd{z = r^2\sin\vartheta\dd{r}\dd{\vartheta}\dd{\varphi}}\).
Hence \(\abs{\Psi(\vv{r}, t)}\) is a probability density.

The classical Hamiltonian is \(H = T + V\).
When constructing the quantum Hamiltonian the momentum, \(\vv{p}\), is substituted for the momentum operator \(\vecoperator{P}\) which has the following representation:
\[\operator{P}_i \representation -i\hbar\pdv{x_i} \implies \vecoperator{P} \representation -i\hbar\grad.\]
For a single particle \(T = p^2/2m = \vv{p}\cdot\vv{p}/2m\) and therefore
\[\operator{T} = \frac{\operator{P}^2}{2m} \representation \frac{\hbar^2}{2m}\laplacian.\]
Most of the time we consider the potential, \(V\), to be a function of position only, \(V = V(\vv{r})\).
The position in the classical Hamiltonian is replaced by the position operator, \(\vecoperator{X}\), which has the following representation:
\[\operator{X}_i = x_i \implies \vecoperator{X} = \vv{r}.\]
Thus
\[\operator{V} \representation V(\vv{r}).\]
So the Hamiltonian operator is given by
\[\operator{H} = \operator{T} + \operator{V} = \frac{\operator{P}^2}{2m} + V(\vecoperator{X}) \representation -\frac{\hbar^2}{2m} + V(\vv{r}).\]
The \gls{tdse} is then
\[\left[-\frac{\hbar^2}{2m}\laplacian + V(\vv{r})\right]\Psi(\vv{r}, t) = i\hbar\pdv{t}\Psi(\vv{r}, t).\]
This has separable solutions of the form
\[\Psi_n(\vv{r}, t) = u_n(\vv{r})\exp(-iE_nt/\hbar).\]
This gives us the \acrfull{tise}:
\[\left[-\frac{\hbar^2}{2m}\laplacian + V(\vv{r})\right]u_n(\vv{r}) = E_nu_n(\vv{r}), \qquad\text{or}\qquad \operator{H}\ket{n} = E_n\ket{n}.\]
This is an eigenvalue equation for \(\operator{H}\) so we see that the stationary states, \(\{\ket{u_n}\}\), correspond to the energy levels.

It can be shown that for an observable \(\observable{A}\) represented by the Hermitian operator \(\operator{A}\)
\[\dv{t}\expected{\operator{A}}_t = \frac{i}{\hbar}\expected{[\operator{H}, \operator{A}]}_t.\]
Importantly if \(\operator{A}\) and \(\operator{H}\) commute then \(\expected{\operator{A}}_t\) is constant.

\subsection{Angular Momentum}
The classical angular momentum, \(\vv{L} = \vv{r}\times\vv{p}\), under operator substitution becomes the angular momentum operator
\[\vecoperator{L} = \vecoperator{X}\times\vecoperator{P}\]
which has components
\[\operator{L}_x \representation -i\hbar\left(y\pdv{z} - z\pdv{y}\right), \qquad \operator{L}_y \representation -i\hbar\left(z\pdv{x} - x\pdv{z}\right), \qquad\text{and}\qquad \operator{L}_z \representation -i\hbar\left(x\pdv{y} - y\pdv{x}\right).\]
More compactly:
\[\operator{L}_k \representation -i\hbar\varepsilon_{ijk}x_i\pdv{x_j}.\]
These satisfy the commutation relations
\[[\operator{L}_x, \operator{L}_y] = i\hbar\operator{L}_z, \qquad [\operator{L}_y, \operator{L}_z] = i\hbar\operator{L}_x, \qquad\text{and}\qquad [\operator{L}_z, \operator{L}_x] = i\hbar\operator{L}_y.\]
More compactly
\[[\operator{L}_i, \operator{L}_j] = i\varepsilon_{ijk}\operator{L}_k.\]
We also define
\[\operator{L}^2 = \operator{L}_x^2 + \operator{L}_y^2 + \operator{L}_z^2.\]
Which satisfies the commutation relation
\[[\operator{L}^2, \operator{L}_k] = 0.\]
This means that \(\operator{L}^2\) and \(\operator{L}_z\) have a common eigenbasis.
We denote these by \(\{\ket{\ell, m}\}\) where
\[\operator{L}^2\ket{\ell, m} = \ell(\ell + 1)\hbar^2\ket{\ell, m}, \qquad\text{and}\qquad \operator{L}_z\ket{\ell, m} = m\hbar\ket{\ell, m}.\]
As wave functions these states are represented by the spherical harmonics, \(Y_\ell^m\), so
\[\operator{L}^2Y_\ell^m(\vartheta, \varphi) = \ell(\ell + 1)\hbar^2Y_\ell^m(\vartheta, \varphi), \qquad\text{and}\qquad \operator{L}_zY_\ell^m(\vartheta, \varphi) = m\hbar Y_\ell^m(\vartheta, \varphi).\]
For angular momentum we have two quantum numbers.
The orbital angular momentum number, \(\ell = 0, 1, 2, \dotsc\) and the magnetic quantum number, \(m\), which for a particular value of \(\ell\) can take any of the \(2\ell + 1\) integer values \(-\ell, -\ell + 1, \dotsc, \ell - 1, \ell\).

\subsection{Spin}
Many particles also have an intrinsic angular momentum known as spin.
This is similar to the angular momentum but we remove the initial definition of the angular momentum operator and only consider the  algebra of the operators.
We define operators \(\operator{S}_k\) which satisfy
\[[\operator{S}_i, \operator{S}_j] = i\hbar\varepsilon_{ijk}\operator{S}_k.\]
We also define
\[\operator{S}^2 = \operator{S}_x^2 + \operator{S}_y^2 + \operator{S}_z^2\]
which has the property that
\[[\operator{S}^2, \operator{S}_k] = 0.\]
The simultaneous eigenstates of \(\operator{S}^2\) an \(\operator{S}_z\) are denoted \(\ket{s, m}\) and are such that
\[\operator{S}^2\ket{s, m} = s(s + 1)\hbar^2\ket{s, m} \qquad \text{and}\qquad \operator{S}_z\ket{s, m} = m\hbar\ket{s, m}.\]
The spin quantum number, \(s\), can be shown to take integer and half integer values, \(s = -, 1/2, 1, 3/2, 2, \dotsc\) and for a specific value of \(s\) there are \(2s + 1\) possible values of \(m\) which run in integer steps from \(-s\) to \(s\) meaning that \(m\) is an integer if \(s\) is and \(m\) is a half integer if \(s\) is.

Spin states don't have a wave function representation.
Instead we represent them by matrices with matrix elements
\[\bra{s, m'}\operator{S}_z\ket{s, m} = m\hbar\braket{s, m'}{s, m} = m\hbar\delta_{mm'}.\]
This will, for a specific value of \(s\), give a \((2s + 1)\times(2s +1)\) matrix.
In the case that \(s = 1/2\) we have two options for \(m = \pm 1/2\).
We use
\[
\ket{s=1/2, m=1/2} \representation 
\begin{pmatrix}
    1\\ 0
\end{pmatrix}
,\qquad\text{and}\qquad
\ket{s=1/2, m=-1/2} \representation
\begin{pmatrix}
    0\\ 1
\end{pmatrix}
\]
which we call spin up and down respectively.
Then the Pauli matrices, 
\[
\sigma_x = 
\begin{bmatrix}
    0 & 1\\
    1 & 0
\end{bmatrix}
, \qquad \sigma_y =
\begin{pmatrix}
    0 & -i\\
    i & 0
\end{pmatrix}
, \qquad\text{and}\qquad \sigma_z =
\begin{pmatrix}
    1 & 0\\
    0 & -1
\end{pmatrix}
,
\]
can be used to represent the spin operators, \(\operator{S}_k \representation \hbar\sigma_k/2\).

\section{Recap Part Three}
\subsection{Addition of Angular Momenta}
Suppose a system has two independent angular momenta with corresponding operators \(\vecoperator{L}\) and \(\vecoperator{S}\).
We can define the total angular momentum with the operator
\[\vecoperator{J} = \vecoperator{L} + \vecoperator{S}.\]
Similarly we can define \(\operator{J}_k\) operators with the following commutation relations
\[[\operator{J}_i, \operator{J}_j] = i\hbar\operator{J}_k.\]
We define the square of the total angular momentum through the operator
\[\operator{J}^2 = \vecoperator{J}\cdot\vecoperator{J} = \operator{J}_x^2 + \operator{J}_y^2 + \operator{J}_z^2.\]
This operator satisfies the commutation relationship
\[[\operator{J}^2, \operator{J}_k] = 0.\]
Thus we have a simultaneous basis for \(\operator{J}^2\) and \(\operator{J}_z\).
We denote this basis \(\{\ket{j, m_j}\}\) where
\begin{align*}
    \operator{J}^2\ket{j, m_j} &= j(j + 1)\hbar^2\ket{j, m_j}\\
    \operator{J}_z\ket{j, m_j} &= m\hbar\ket{j, m_j}.
\end{align*}
First note that since \(\operator{L}^2\) and \(\operator{S}^2\) act on completely different spaces they commute.
Therefore
\begin{align*}
    \operator{J}^2 &= (\vecoperator{L} + \vecoperator{S})\cdot (\vecoperator{L} + \vecoperator{S})\\
    &= \operator{L}^2 + \operator{S}^2 + 2\vecoperator{L}\cdot\vecoperator{S}.
\end{align*}
Using this we see that
\begin{align*}
    [\operator{J}^2, \operator{L}_z] &= \underbrace{[\operator{L}^2, \operator{L}_z]}_{=0} + \underbrace{[\operator{S}^2, \operator{L}_z]}_{=0} + 2[\vecoperator{L}\cdot\vecoperator{S}, \operator{L}_z]\\
    &= 2[\operator{L}_x\operator{S}_x, \operator{L}_z] + 2[\operator{L}_y\operator{S}_y, \operator{L}_z] + 2\underbrace{[\operator{L}_z\operator{S}_z, \operator{L}_z]}_{=0}\\
    &= 2\left(\operator{L}_x\operator{S}_x\operator{L}_z - \operator{L_z}\operator{L}_x\operator{S}_x + \operator{L}_y\operator{S}_y\operator{L}_z - \operator{L_z}\operator{L}_y\operator{S}_y\right)\\
    &= 2\operator{S}_x[\operator{L_x}, \operator{L_z}] + 2\operator{S_y}[\operator{L}_y, \operator{L}_z]\\
    &= -2i\hbar\operator{L}_y + 2i\hbar\operator{L}_x\\
    &\ne 0.
\end{align*}
So \(\operator{J}^2\) doesn't commute with \(\operator{L}_z\), similarly we can show that \(\operator{J}^2\) doesn't commute with \(\operator{S}_z\).

There are two sets of commuting observables that we may consider.
The first is \(\{\operator{L}^2, \operator{L}_z, \operator{S}^2, \operator{S}_z\}\), which has a common eigenbasis, \(\{\ket{\ell, m_\ell, s, m_s}\}\), called the uncoupled basis.
The second is the set \(\{\operator{L}^2, \operator{S}^2, \operator{J}^2, \operator{J}_z\}\), which has a common eigenbasis, \(\{\ket{\ell, s, j, m_j}\}\), called the coupled basis.
These two bases are linearly related and the expansion coefficients are called the Clebsch--Gordan coefficients.

The angular momentum addition theorem tells us that for given \(\ell\) and \(s\) the allowed values of \(j\) are
\[\ell + s, \ell + s - 1, \dotsc, \abs{\ell - s + 1}, \abs{\ell - s}.\]
For example an electron with \(\ell = 1\) and \(s = 1/2\) has two possible values of \(j\):
\[j = \ell + s = 1 + \frac{1}{2} =\frac{3}{2}, \qquad\text{and}\qquad j = \ell - s = 1 - \frac{1}{2} = \frac{1}{2}.\]
A two electron system where each electron has spin 1/2 will have total spin quantum number
\[s = s_1 + s_2 = \frac{1}{2} + \frac{1}{2} = 1, \qquad\text{and}\qquad s = s_1 - s_2 = \frac{1}{2} - \frac{1}{2} = 0.\]

\subsection{Degeneracy}
Up until now we have largely ignored degeneracy in this recap.
Degeneracy is when two or more eigenstates have the same eigenvalue.
For example the first excited energy state of the hydrogen atom is four fold degenerate as \(u_{200}\), \(u_{211}\), \(u_{210}\), and \(u_{21{-}1}\) all have the same energy eigenvalue, \(E_2\).
The degeneracy is the reason that we need the orbital angular momentum quantum number, \(\ell\), and even then we still have \((2\ell + 1)\)-fold degeneracy which we lift by introducing the magnetic quantum number, \(m_\ell\).

If we have degenerate states then we need to alter the third and fourth postulates.
In the following we will consider a system with an observable, \(\observable{A}\), which is associated with the operator \(\operator{A}\), which has an eigenbasis \(\{\ket{u_i}\}\) where \(\ket{u_1}\) and \(\ket{u_2}\) have a common eigenvalue \(A\).
The rest of the eigenstates have an eigenvalue other than \(A\) but may be degenerate still with these eigenvalues.

\setcounter{postulateCounter}{2}
\begin{postulate}{with degeneracy}{}
    If the observable \(\observable{A}\) is measured on a system which, immediately prior to the measurement, is in the state \(\ket{\Psi(t)} = \sum_i c_i(t)\ket{u_i}\), then the probability of getting the result \(A\) is
    \[P(A) = \abs{\braket{u_1}{\Psi(t)}}^2 + \abs{\braket{u_2}{\Psi(t)}}^2 = \abs{c_1(t)}^2 + \abs{c_2(t)}^2.\]
\end{postulate}
This generalises to \(g\)-fold degeneracy for \(A\) by summing over all \(g\) states with \(A\) as an eigenvalue of \(\operator{A}\).
Any linear combination of degenerate eigenstates is another degenerate eigenstate, for example
\[k_1\ket{u_1} + k_2\ket{u_2},\]
is an eigenstate with eigenvalue \(A\).
The set of all degenerate eigenstates spans a subspace of degenerate eigenstates.
In this case it is a two dimensional subspace.
We use this freedom to assume that \(\ket{u_1}\) and \(\ket{u_2}\) are orthonormal as if they aren't then we can always construct an orthonormal pair of states, \(\ket{u_1'}\) and \(\ket{u_2'}\), defined by
\[\ket{u_1'} = \ket{u_2'}, \qquad\text{and}\qquad \ket{u_2'} = \ket{u_2} - \frac{\braket{u_1'}{u_2}}{\braket{u_1'}{u_1'}}\ket{u_1}.\]
From now we will assume that \(\ket{u_1}\) and \(\ket{u_2}\) are orthonormal.
\begin{postulate}{}{}
    If the result of a measurement of \(\observable{A}\) is \(A\) then immediately after the measurement the state vector will coincide with the normalised eigenstate
    \[\frac{c_1(t)\ket{u_1} + c_2(t)\ket{u_2}}{\sqrt{\abs{c_1(t)}^2 + \abs{c_2(t)^2}}}.\]
\end{postulate}
Again this generalises to \(g\)-fold degeneracy simply by extending the sums to be over all \(g\) degenerate states.
Notice that, unlike the non-degenerate case, the state after measurement is not necessarily one eigenbasis vectors.

\subsection{Complete Sets of Commuting Operators}
We distinguish eigenstates by their eigenvalues.
Clearly we cannot separate \(\ket{u_1}\) and \(\ket{u_2}\) by the eigenvalue \(A\).
Instead we must introduce a new observable, \(\observable{B}\), which is compatible with \(\observable{A}\), and then we use the eigenvalue of \(\operator{B}\) to distinguish the states.
For example \(\operator{L}^2\) has \(2\ell + 1\) degenerate eigenstates for a given value of \(\ell\).
We distinguish these states by the eigenvalue of \(\operator{L}_z\) which gives us a distinct eigenvalue, \(m_\ell\), for each of the degenerate states.
We end up labelling a state with two eigenvalues, \(\ket{\ell, m_\ell}\).

We also use this to lift the degeneracy of the stationary states of the hydrogen atom.
The first operator we use is the Hamiltonian which assigns each eigenstate an energy value, \(E_n\), and we use \(n\) as a label.
We then introduce \(\operator{L}^2\) which allows some separation between states of the same energy with the extra label \(\ell\).
It isn't until we introduce \(\operator{L}_z\) with the label \(m\) that we can completely separate the states which we then label \(\ket{u_{n\ell m}}\) or \(\ket{n, \ell, m}\).

We keep introducing new compatible observables until we have a \acrfull{csco}, \(\{\observable{A}, \observable{B}, \observable{C}, \dotsc\}\), with corresponding operators, \(\{\operator{A}, \operator{B}, \operator{C}, \dotsc\}\), which have a common eigenbasis which we label \(\{\ket{A, B, C, \dotsc}\}\).
If \(\{A, B, C, \dotsc\}\) uniquely identify a state then we call them good quantum numbers.
For example one set of good quantum numbers for the hydrogen atom is \(\{n, \ell, m\}\).
A good set of quantum numbers for a two electron system is \(\{s_1, s_2, s, m_s\}\) or \(\{s_1, m_{s_1}, s_2, m_{s_2}\}\).

A central potential with no external fields and a spin 1/2 system has the Hamiltonian
\[\operator{H} = \frac{\operator{P}^2}{2m} + \operator{V}(r).\]
Any pair of \(\{\operator{H}, \operator{L}^2, \operator{L}_z, \operator{S}^2, \operator{S}_z\}\) commute and the common eigenbasis is \(\{\ket{n, \ell, m_\ell, s, m_s}\}\) with good quantum numbers \(\{n, \ell, m_\ell, s, m_s\}\).
Alternatively we could work in the coupled basis, \(\{\ket{n, \ell, s, j, m_j}\}\), with good quantum numbers \(\{n, \ell, s, j, m_j\}\).

A central potential spin 1/2 system with spin-orbit interactions has the Hamiltonian
\[\operator{H} = \frac{\operator{P}^2}{2m} + \operator{V}(r) + a(r)\vecoperator{L}\cdot\vecoperator{S}.\]
In this case \(\operator{L}_z\) and \(\operator{S}_z\) don't commute with \(\operator{H}\) due to the spin-orbit term containing \(\operator{L}_x\), \(\operator{L}_y\), \(\operator{S}_x\), and \(\operator{S}_y\).
Therefore \(m_\ell\) and \(m_s\) are no longer good quantum numbers.
However we can still use the coupled basis, \(\{\ket{n, \ell, s, j, m_j}\}\) with good quantum numbers \(\{n, \ell, s, j, m_j\}\).

To know exactly what state a system is in we must measure all of the observables in a \gls{csco}.
This is called a \define{maximal measurement}.
It enables us to know exactly which eigenstate a series of measurements forces a state into by examining the set of eigenvalues of that \gls{csco}.